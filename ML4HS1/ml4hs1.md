---
title: Machine Learning for Theory Exploration
---

# Abstract

Theory exploration investigates the deductive consequences of formal definitions. It is open-ended since there is no specific goal; eg. the aim is not to (dis)prove a particular theorem, but rather to discover new theorems.

Clearly we must provide *some* guidance to the exploration, to avoid trivial "discoveries" ($0 = 0$, $1 = 1$, etc.). Existing approaches ensure novelty using brute-force enumeration and eliminate triviality using a post-processing filter. Such approaches are limited by their inefficiency; typically fewer than 10 symbols are used and search never considers combinations is limited to a depth of to very limited depth with resulting theorems around

In this paper, we study the use of machine learning to avoid generating "uninteresting" cases, without

# Introduction

Existing approaches use computational reducibility[IsaCoSy], simplicity and entailment[QuickSpec] limit the search space to input include computational reducibility,
