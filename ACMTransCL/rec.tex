\section{Recurrent Term Clustering}\label{sec:reclemmaclustering}

The previous section introduced a method of defining statistically significant features.
It remains to define the functions
 $[.]_{term}$ and $[.]_{type}$ that will determine the feature values.
These functions must be sensitive to the structure of terms, assigning close values
to similar terms, and more distant values to unrelated terms.

A term \lstinline?t? is represented by the $300$ feature values of $[\texttt{t}]_M$.
The values of $[.]_{M}$
for  variables  and pre-defined sorts in \lstinline?t? are fixed, but the values of user-defined terms (and types!) contained in \texttt{t}
have to be computed recursively, based
on the structures of their definitions, and
using clustering to compute their feature vectors, and their representative values for $[\texttt{t}]_M$.
It is the nature of functional languages to have terms depending on other terms, and feature extraction/clustering cycle is
repeated recursively to reflect complex mutual term dependencies as feature values.
 We call this method \emph{recurrent clustering}: the function $[.]_M$ automatically (and recurrently) adapts to the given libraries and the current proof stage.
This differs from the standard machine-learning approach (and the old version of ML4PG), where the process of feature extraction is separated from running pattern-recognition algorithms. Here, one is a crucial part of another.



When Coq objects are divided into clusters, a unique integer number is assigned to each cluster. Clustering algorithms compute
a \emph{proximity value} (ranging from $0$ to $1$) to every object in a cluster to indicate the certainty of the given example belonging
to the cluster. The cluster numbers and the proximity values are used in the definitions of $[.]_{term}$ and $[.]_{type}$ below.


\begin{definition}\label{def:funterm}
Given a term  \lstinline?t? of a Coq library, the functions $[.]_{term}$ and $[.]_{type}$ are defined respectively for the term component \lstinline?t1?
and the type component \lstinline?t2? of every term-type node in the ML4PG term tree of \lstinline?t? as follows:

$-$ $[\texttt{t1}]_{term/type}=i$, if \lstinline?t1? is the $i$th distinct variable in \lstinline?t?.

$-$ $[\texttt{t1}]_{term/type}=100+\sum_{j=1}^i\frac{1}{10\times 2^{j-1}}$, if \lstinline?t1? is the $i$th element of the set\\ $\{\texttt{Set},\texttt{Prop},\texttt{Type(0)},
\texttt{Type(1)}, \texttt{Type(2)},\ldots\}$.

$-$ $[\texttt{t1}]_{term}=200+2\times j + p$, where $j$ is a number of a cluster $C_j$ computed by the latest run of term clustering,
such that $p$ is the proximity value of $\texttt{t1}$ in $C_j$.

$-$ $[\texttt{t2}]_{type}=200+2\times j + p$, where $j$ is a number of a cluster $C_j$ computed by the latest run of type clustering (i.e. term clustering restricted to types),
such that $p$ is the proximity value of $\texttt{t2}$ in $C_j$.
\end{definition}


Note the recurrent nature of the functions $[.]_{term}$ and $[.]_{type}$ where numbering of components of \lstinline?t? depends on the term definitions
and types included in the library, assuming those values are computed by iterating the process back to the basic definitions.  In addition, the function $[.]_{term}$ internally uses the function $[.]_{type}$ in the recurrent clustering
process and \emph{vice versa}.

In the above definition,
the variable encoding reflects the number and order of unique variables appearing in the term, note its similarity to the de Bruijn indexes.
In the formula for sorts, $\sum_{j=1}^i\frac{1}{10\times 2^{j-1}}$ reflects the close relation among sorts, and
$100$ is used to  distinguish sorts from variables and names.

Finally, the formula $200+2\times j + p$ assigns $[\texttt{t1}]$ (or $[\texttt{t2}]$) a value within $[200+2\times j,200+2\times j+1]$ depending on the
statistical proximity of \lstinline?t1? (or \lstinline?t2?) in cluster $j$. Thus, elements of the same cluster have closer values comparing to the values
assigned to elements of other clusters, sorts, and variables. The formula is the same for the functions $[.]_{term}$ and $[.]_{type}$, but it is computed with different
clusters and the values
occur in different cells of the term-tree matrices (cf. Definition~\ref{df:matrix}); thus, clustering algorithms distinguish terms and types on the level of features rather than feature values.

We can now state the main property of the ML4PG feature extraction.

\begin{proposition}
Let ${\cal T}$ be the set of Coq terms  whose trees have maximum depth $10$ and level index $10$.
Then, the function $[.]_{M}$ restricted to ${\cal T}$ is a one-to-one function.
\end{proposition}

Once the feature values of ML4PG term tree matrices have been computed, we can cluster these matrices and
obtain groups of similar terms. In particular, ML4PG can be used to cluster definitions, types and lemma
statements.
We finish this section with some clusters discovered among the 457 definitions of the basic infrastructure of the SSReflect
library~\cite{SSReflect}.

\begin{example}
We include here 3 of the 91 clusters discovered by ML4PG automatically in the SSReflect library of 457 terms (across 12 standard files), within 5--10 seconds.
Note that this example of cluster-search is not goal-oriented, ML4PG discovers patterns without any user guidance, and offers the user to consider term similarities of which he may
not be aware.

\begin{itemize}
 \item Cluster 1:
{\scriptsize \begin{lstlisting}
 Fixpoint eqn (m n : nat) :=
   match m, n with
   | 0, 0 => true | m'.+1, n'.+1 => eqn m' n'
   | _, _ => false end.
 Fixpoint eqseq (s1 s2 : seq T)  :=
   match s1, s2 with
   | [::], [::] => true | x1 :: s1', x2 :: s2' => (x1 == x2) && eqseq s1' s2'
   | _, _ => false end.
\end{lstlisting}}

\item  Cluster 2:
{\scriptsize
\begin{lstlisting}
 Fixpoint drop n s := match s, n with | _ :: s', n'.+1 => drop n' s' | _, _ => s end.
 Fixpoint take n s := match s, n with | x :: s', n'.+1 => x :: take n' s' | _, _ => [::] end.
\end{lstlisting}}

\item Cluster 3:
{\scriptsize
\begin{lstlisting}
 Definition flatten := foldr cat (Nil T).
 Definition sumn := foldr addn 0.
\end{lstlisting}}
\end{itemize}



\end{example}

The first cluster contains the definitions of equality for natural numbers and lists --- showing that
ML4PG can spot similarities across libraries. The second cluster discovers the relation between \lstinline?take? (takes the first $n$ elements of
a list) and \lstinline?drop? (drops the first $n$ elements of a list).
The last pattern is less trivial of the three, as it depends on
other definitions, like \lstinline?foldr?, \lstinline?cat? (concatenation of lists) and \lstinline?addn? (sum
of natural numbers).
Recurrent term clustering handles such dependencies well: it assigns close values to \lstinline?cat? and \lstinline?addn?,  since they have been discovered to belong to the same cluster.
Note the precision of ML4PG clustering. Among $457$ terms it considered, $15$ used \lstinline?foldr?, however,  Cluster 3 contained only $2$ definitions, excluding e.g.
\lstinline?Definition allpairs s t:=foldr (fun x => cat (map (f x) t)) [::] s? ; \lstinline?Definition divisors n:=foldr add_divisors [:: 1] (prime_decomp n)?  or \lstinline?Definition Poly:=foldr cons_poly 0.? --- this is due to the recurrent clustering process since functions like \lstinline?add_divisors? or \lstinline?cons_poly? are not clustered together with functions \lstinline?cat? and \lstinline?addn?.


To summarise, there are three main properties that distinguish ML4PG pattern search from standard Coq search commands:
\begin{itemize}
	\item the user does not have to know and provide any search pattern;
	\item the discovered clusters do not have to follow a \lq\lq{}pattern\rq\rq{} in a strict sense (e.g. neither exact symbol names nor their order make a pattern), but ML4PG considers structures and background information found in the library; and,
	\item working with potentially huge sets of Coq objects, ML4PG makes its own intelligent discrimination of more significant and less significant patterns,
	as example with \lstinline?foldr? has shown. This is opposed to the classic search for \lstinline?foldr? pattern that would present the user with a set of $15$ definitions.
\end{itemize}


ML4PG can also work in a goal-directed mode,
and discover only clusters of terms that are similar to the given term \lstinline?t?.
This can speed-up the proof development in two different ways.
In addition, clustering will provide definitions of terms similar to \lstinline?t?;
hence, the proofs of the theorems
involving those terms may follow similar patterns.
Clustering can also discover that a newly defined term \lstinline?t? was previously defined (perhaps in a different notation, as ML4PG works with structures across notations);
in that case, the user can use the existing library definition and all its background theory instead of defining it from scratch.
