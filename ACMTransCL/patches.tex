\section{Recurrent Proof Clustering}\label{sec:recurrent}

The method presented in the previous section can cluster similar statements of all Coq terms, including definitions and theorems. 
However, this method does not capture the interactive nature of Coq proofs.
In this section, we involve proofs into the recurrent clustering of Coq libraries.

 In~\cite{KHG13}, 
we introduced a feature extraction method for Coq proofs capturing
the user's interaction through the applied tactics. That method 
%tracks simple, 
traced 
low-level properties present in proof's subgoals, e.g. ``the
top symbol'' or ``the argument type''. Further, these features were taken
in relation to the statistics of user actions on every subgoal: how many and what
kind of tactics he applied, and what kind of arguments he provided to the
tactics. Finally, a few proof-steps were taken in relation to each other.
This method  had two drawbacks.\\ 
% (1) It only captures information 
% about the top symbol of the goal; this means that information is mainly collected 
% from symbols such as \lstinline?forall? or \lstinline?equal? (common to most proofs)
% and features from other symbols (that are likely more relevant for the proof) are never captured.
(1) It was  focused on the first
five proof-steps of a proof; therefore, some information was lost. We address this issue by implementing automatic split of each proof into proof-patches; thus, allowing ML4PG to analyse a proof by the properties
of the patches that constitute the proof. \\
(2) The method assigned most feature-values blindly; thus, being insensitive to many important parameters, such as e.g. the structure of lemmas and hypotheses used as 
tactic arguments within a proof. 
The previous section gave us the way of involving all Coq objects into recurrent feature re-evaluation.
%, and, as we have explained in the previous section, machine-learning algorithms are sensitive to 
%the assignment of feature values. These drawbacks have been overcome combining a new method called the 
%\emph{proof-patch method} and the term feature extraction method presented in the previous section. 


%We start with introducing \emph{proof-patches} to address the first drawback. The underlying idea is that 

%We start defining the notions of Coq proof and proof-patch matrices. 

\begin{definition}[Coq proof]
 Given a statement $S$ in Coq, a \emph{Coq proof} of $S$ is given by a sequence of triples $((\Gamma_i,G_i,T_i))_{0\leq i\leq n}$ where $\Gamma_i$ is a context,
 $G_i$ is a goal and $T_i$ is a sequence of tactics satisfying:

  - $G_0=S$, and for all $i$, $\Gamma_i$ is the context of the goal $G_i$,
  
  - for all $i$ with $0<i\leq n$, $\Gamma_i,G_i$ are respectively the context and goal obtained after applying $T_{i-1}$, and 
    the application of $T_n$ completes the proof.
\end{definition}

In this paper, we focus on the goals and tactics of Coq proofs; thus, we do not consider the contexts and denote the 
Coq proof $((\Gamma_i,G_i,T_i))_{0\leq i\leq n}$ by $((G_i,T_i))_{0\leq i\leq n}$. Involving contexts into proof-pattern search may be a subject for future work. 


\begin{table}[t]
\tbl{\scriptsize{\emph{Proof for the lemma of Example~\ref{example0} in SSReflect.}}\label{tab:sumfirstn}}{
 	\centering
 	\tiny{
 		\begin{tabular}{|l|l|}
 		\hline
 	Goals and Subgoals & Applied Tactics \\
 		\hline
 		\hline
 	{\scriptsize $G_0) \forall~n,\sum\limits_{i=0}^{n} (g(i+1) - g(i)) = g(n+1) - g(0)$} & \\
 			& $T_0)$ {\scriptsize \lstinline?case : n => [|n _].?} \\
        $G_1) \sum\limits_{i=0}^{0} (g(i+1) - g(i)) = g(1) - g(0)$ & \\
        & $T_1)$  {\scriptsize\lstinline?by rewrite big_nat1.?}\\
        $G_2)  \sum\limits_{i=0}^{n+1} (g(i+1) - g(i)) = g(n+2) - g(0)$ &\\
        
        & $T_2)$ {\scriptsize\lstinline?rewrite sumrB big_nat_recr big_nat_recl ?}\\
          & ~~~~~~~~{\scriptsize\lstinline?     addrC addrC -subr_sub -!addrA addrA.?} \\
        $G_3) g(n+2) + \sum\limits_{i=0}^{n} g(i+1) -  \sum\limits_{i=0}^{n} g(i+1) - g(0) =$ &\\
        $  g(n+2) - g(0)$ &\\
        &$T_3)$  {\scriptsize\lstinline?move : eq_refl.?}\\
        $G_4) \sum\limits_{i=0}^{n} g(i+1) == \sum\limits_{i=0}^{n} g(i+1) \rightarrow  $ &\\
        $g(n+2) + \sum\limits_{i=0}^{n} g(i+1) -  \sum\limits_{i=0}^{n} g(i+1) - g(0) =$ &\\
        $  g(n+2) - g(0)$ &\\
        &$T_4)$  {\scriptsize\lstinline?rewrite -subr_eq0.?}\\
        $G_5) \sum\limits_{i=0}^{n} g(i+1) - \sum\limits_{i=0}^{n} g(i+1) == 0\rightarrow  $ &\\
        $g(n+2) + \sum\limits_{i=0}^{n} g(i+1) -  \sum\limits_{i=0}^{n} g(i+1) - g(0) =$ &\\
        $  g(n+2) - g(0)$ &\\
        &$T_5)$  {\scriptsize\lstinline?move/eqP => ->.?}\\
         $G_6)  g(n+2) + 0 - g(0) = g(n+2) - g(0)$ &\\
        &$T_6)$  {\scriptsize\lstinline?by rewrite sub0r.?}\\
 		$\Box$ & \\
 		& {\scriptsize\lstinline?Qed.?}\\
 		\hline
 		\end{tabular}
 		
 		}}
 \end{table}


\begin{example}\label{example0}
Table~\ref{tab:sumfirstn} shows the Coq proof of the following statement:
 $$\forall g:\mathbb{N} \rightarrow \mathbb{Z}\implies \sum_{0\leq i \leq n} (g(i+1) - g(i)) = g(n+1) - g(0)$$
\end{example}

One small proof may potentially 
resemble a fragment of a bigger proof; also, various small ``patches'' of different big proofs may resemble. 

\begin{definition}[Proof-patch]
 Given a \emph{Coq proof} $C=((G_i,T_i))_{0\leq i\leq n}$, a \emph{proof-patch} of $C$ is a subsequence of at most $5$ consecutive 
 pairs of $C$.
\end{definition}

From proof-patches, we can construct their feature matrices. %that will be provided to the machine-learning algorithms. 
We will shortly define the feature extraction function $[.]_P=\langle[.]_M,[.]_{tac}\rangle : proof~patches \rightarrow M[\mathbb{Q}]_{5\times 6}$,
where $[.]_{tac}$ is an injective function that has been introduced to assign values to tactics.
%To be more concrete, 
We have defined two versions of  $[.]_{tac}$: one for Coq tactics and another for SSReflect tactics. 
% -- although SSReflect is an extension of Coq, this package implements a set of proof tactics designed to support the extensive
% use of small-scale reflection in formal proofs~\cite{SSReflect}. 
In the SSReflect case, we divide the tactics into 7 groups and assign similar
values to each tactic in the group, see Table~\ref{tab:tactics}. 
% If several tactics are concatenated using ``\lstinline?;?'', the value returned by
% $[.]_{tac}$ is the concatenation of the values of the individual tactics. 
Analogously for Coq tactics, cf. Appendix~\ref{sec:coqtactics}.

%These clusters in turn are used to define a new function $[.]_{term}$. The function $[.]_{term}$ assigns numbers using the 
%formula $[l]_{term}=2\times j + p$ where $C_j$ is a cluster such that $l\in C_j$ and $p$ is the proximity value of $l$ in $C_j$. This process assigns 
%closer values to statements in the same cluster, and more distant numbers across groups. This function will be used in the following section.




\begin{definition}[Proof-patch matrix]\label{def:ptm}
Given a Coq proof $C=((G_i,T_i))_{0\leq i\leq n}$, and a proof patch $p=((G_{i_0},T_{i_0}),\ldots,(G_{i_4},T_{i_4}))$ of $C$, 
the feature extraction function $[.]_P: proof~patches \rightarrow M[\mathbb{Q}]_{5\times 6}$ constructs the \emph{proof-patch matrix} $[p]_P$ 
as follows:

\begin{itemize}
 \item the $(j,0)$-th entry of $[p]_P$ is a 4-tuple $([T_{i_j}^1]_{tac}, [T_{i_j}^2]_{tac},[T_{i_j}^3]_{tac},[T_{i_j}^r]_{tac})$ 
 where $T_{i_j}^1, T_{i_j}^2$ and $T_{i_j}^3$ are the three first tactics of $T_{i_j}$, and $T_{i_j}^r$ is the list of the rest of tactics of $T_{i_j}$,
 \item the $(j,1)$-th entry of $[p]_P$ is the number of tactics appearing in $T_{i_j}$,
 \item the $(j,2)$-th entry of $[p]_P$ is a 4-tuple $([t_1]_{type},[t_2]_{type},[t_3]_{type},[t_{i_j}]_{type})$ where 
 $t_1, t_2$ and $t_3$ are the three first argument-types of $T_{i_j}$, and $t_{i_j}$ is the set of the rest of 
 the argument-types of $T_{i_j}$ (insensitive to order or repetition),
 \item the $(j,3)$-th entry of $[p]_P$ is a 4-tuple  $([l_{i_{j_1}}]_{term},[l_{i_{j_2}}]_{term},[l_{i_{j_3}}]_{term},[l_{i_j}]_{term})$
 where $l_{i_{j_1}}$, $l_{i_{j_2}}$ and $l_{i_{j_3}}$ are the three first lemmas applied in $T_{i_j}$ and $l_{i_j}$ is the list of the rest of lemmas 
used in $T_{i_j}$ (sensitive to order and repetition),
 \item the $(j,4)$-th entry of $[p]_P$ is a triple  $([s_1]_{term},[s_2]_{term},[s_3]_{term})$ where $s_1,s_2$ and $s_3$ are respectively the top, second, and third
 symbol of $G_{i_j}$,
 \item the $(j,5)$-th entry of $[p]_P$ is the number of subgoals after applying $T_{i_j}$ to $G_{i_j}$.
\end{itemize} 
\end{definition}


\begin{table}[t]
\tbl{\scriptsize{\emph{Formulas computing the value of SSReflect tactics.}
they serve to assign closer values to the tactics within each of the seven groups, and more distant numbers 
across the groups.  If a new tactic is defined, ML4PG automatically assigns a new number to it, using the next available natural number $n$ 
in the formula $n+\sum_{j=1}^i \frac{1}{10\times 2^{j-1}}$.}\label{tab:tactics}}{
\centering
{\scriptsize
\begin{tabular}{ll}
\hline
$\ast$ Bookkeeping ($b=\{$\lstinline?move:, move => ?$\}$): &$[b_i]_{tac}=1+\sum_{j=1}^i \frac{1}{10\times 2^{j-1}}$ (where $b_i$ is the $i$th element of $b$).\\
$\ast$ Case and Induction ($c=\{$\lstinline?case, elim?$\}$):& $[c_i]_{tac}=2+\sum_{j=1}^i \frac{1}{10\times 2^{j-1}}$.\\
$\ast$ Discharge ($d=\{$\lstinline?apply, exact, congr?$\}$):& $[d_i]_{tac}=3+\sum_{j=1}^i \frac{1}{10\times 2^{j-1}}$.\\
$\ast$ Simplification ($s=\{$\lstinline?//, /=, //=?$\}$):& $[s_i]_{tac}=4+\sum_{j=1}^i \frac{1}{10\times 2^{j-1}}$.\\
$\ast$ Rewrite:& $[$\lstinline?rewrite?$]_{tac} = 5$. \\
$\ast$ Forward Chaining  ($f=\{$\lstinline?have, suff, wlog?$\}$):& $[f_i]_{tac}=6+\sum_{j=1}^i \frac{1}{10\times 2^{j-1}}$.\\
$\ast$ Views and reflection  ($v=\{$\lstinline?move/, apply/, elim/, case/?$\}$):& $[v_i]_{tac}=7+\sum_{j=1}^i \frac{1}{10\times 2^{j-1}}$.\\
\hline
\end{tabular}}}
\end{table}



\begin{example}\label{example1}
Given the proof of Example~\ref{example0} and the proof-patch $((G_{i},T_{i}))_{0\leq i \leq 4}$, 
the top table of Table~\ref{tab:patches} shows their proof-patch matrix.
\end{example}


The \emph{proof-patch method} considers several proof-patches to collect information from a concrete proof. 
In particular, given a Coq proof $C=((G_i,T_i))_{0\leq i\leq n}$ , the proof $C$ can be split into patches $C_0,\ldots,C_m$ where 
$m=\lceil\frac{n}{5}\rceil+1$. The patches are defined as follows: $C_j=((G_j,T_j),\ldots,(G_{j+4},T_{j+4}))$ 
for $0\leq j < m$ (some patches might contain less than $5$ proof-steps), and $C_m=((G_{n-4},T_{n-4}),\ldots,(G_{n},T_{n}))$ --- the last patch captures 
the last five proof-steps.


\begin{example}
Using the proof-patch method, we  can split the proof presented in Example~\ref{example1} into three proof-patches $((G_i,T_i))_{0\leq i \leq 4}$, 
$((G_5,T_5),(G_6,T_6))$ and $((G_i,T_i))_{2\leq i \leq 6}$; the corresponding proof-patch matrices are given in Table~\ref{tab:patches}. 
\end{example}

The proof-patch method together with the feature function $[.]_P$ solve the two drawbacks of the old method~\cite{KHG13}: 
the new method captures information about the whole proof and the feature values are dynamically computed to assign close
values to similar terms, types, tactics and lemma statements used as tactic arguments. 


We finish this section with a case study that illustrates 
the use of the proof-patch method, and shows the differences with the results obtained with the old method~\cite{KHG13}. This case study concerns the discovery of proof patterns in mathematical proofs
across formalisations of apparently disjoint mathematical theories: Linear Algebra, Combinatorics and Persistent Homology  (across 758 lemmas and 5~libraries).
In this scenario, we use statistically discovered proof patterns to advance the proof of a given ``problematic'' lemma. 
Namely,  a few initial steps in its proof are clustered against several mathematical libraries. 
We deliberately take lemmas belonging to very different SSReflect libraries. The lemma introduced in Example~\ref{example0} is a basic fact about
summations. Lemma~\ref{lem:nilpotent} states a result about \emph{nilpotent} matrices %~\cite{BR91} 
(a square matrix $M$ is \emph{nilpotent}
if there exists an $n$ such that $M^n=0$). Finally, Lemma~\ref{lem:fundamental} is a generalisation of the \emph{fundamental lemma of 
Persistent Homology}~\cite{HCMS12}.


\begin{lemma}\label{lem:nilpotent}
 Let $M$ be a square matrix and $n$ be a natural number such that $M^n=0$, then $(1-M)\times \sum\limits_{i=0}^{n-1} M^i = 1$.
\end{lemma}


\begin{lemma}\label{lem:fundamental}
Let $\beta_n^{k,l}:\mathbb{N} \times \mathbb{N} \times \mathbb{N} \rightarrow \mathbb{Z}$, then
$$\sum_{0\leq i \leq k} \sum_{l<j\leq m} (\beta_n^{i,j-1} - \beta_n^{i,j}) - (\beta_n^{i-1,j-1} - \beta_n^{i-1,j}) = \beta_n^{k,l} - \beta_n^{k,m}.$$
\end{lemma}


\begin{table}
\tbl{\scriptsize{\emph{Proof-patch matrices for the proof of Example~\ref{example1}.} \textbf{Top.} Proof-patch matrix of the patch $((G_i,T_i))_{0\leq i\leq 4}$. 
 \textbf{Centre.} Proof-patch matrix of the patch $((G_i,T_i))_{5\leq i\leq 6}$ (rows that are not included in the table are filled with zeroes).
 \textbf{Bottom.} Proof-patch matrix of the patch $((G_i,T_i))_{2\leq i\leq 6}$.  
Where we use notation $EL$, ML4PG gathers the lemma names: (\lstinline?addrC?, \lstinline?addrC?~, \lstinline?subr_sub?, \ldots).}\label{tab:patches}}{
\centering
\tiny{
\begin{tabular}{|l||l|l|l|l|l|l|}
\hline
 & \emph{tactics} & \emph{n} & \emph{arg type} & \emph{arg} & \emph{symbols} & \emph{goals} \\
\hline
\hline
\emph{g1}& $([case]_{tac},0,0,0)$ & $1$  & $([nat]_{type},0,0,0)$  & $([Hyp]_{term},0,0,0)$ & $([\forall]_{term},[=]_{term},[sum]_{term})$ & $2$ \\
 \hline
  \emph{g2} & $([rewrite]_{tac},0,0,0)$ & $1$  & $([Prop]_{type},0,0,0)$  & $([big\_nat1]_{term},0,0,0)$ & $([=]_{term},[\sum]_{term},[-]_{term})$& $0$ \\
 \hline
  \emph{g3} & $([rewrite]_{tac},0,0,0)$ & $1$  & $([Prop]_{type},$ & $([surB]_{term},$  & $([=]_{term},[+]_{term},[-]_{term})$& $1$ \\
 & & &$[Prop]_{type},$ & $[big\_nat\_recr]_{term}$ & & \\
 & & &$[Prop]_{type},$ & $[big\_nat\_recl]_{term}$ & & \\
 & & &$[Prop]_{type})$ & $[EL]_{term})$ & & \\
 \hline
   \emph{g4} & $([move:]_{tac},0,0,0)$ & $1$  & $([Prop]_{type},0,0,0)$ &  $([eq\_refl]_{term},0,0,0)$  & $([=]_{term},[+]_{term},[-]_{term})$ & $1$ \\
 \hline 
  \emph{g5} & $([rewrite]_{tac},0,0,0)$ & $1$  & $([Prop]_{type},0,0,0)$  & $([subr\_eq0]_{term},0,0,0)$ & $([=]_{term},[+]_{term},[-]_{term})$ & $1$ \\
 \hline

 \multicolumn{7}{c}{}\\
% Second table 
\hline
 & \emph{tactics} & \emph{n} & \emph{arg type} & \emph{arg} & \emph{symbols} &  \emph{goals} \\
\hline
\hline
\emph{g1} & $([move/]_{tac},[\texttt{->}]_{tac},0,0)$ & $2$  & $([Prop]_{type},0,0,0)$ &  $([eq\_refl]_{term},0,0,0)$  & $([=]_{term},[+]_{term},[-]_{term})$ & $1$ \\
 \hline
  \emph{g2} & $([rewrite]_{tac},0,0,0)$ & $1$  & $([Prop]_{type},0,0,0)$  & $([subr\_eq0]_{term},0,0,0)$ & $([=]_{term},[+]_{term},[-]_{term})$ & $1$ \\
 \hline
%   \emph{g3} & - & -  & - & -  & - & -  \\
%  \hline
%   \emph{g4} & - & -  & - & -  & - & -  \\
%  \hline 
%   \emph{g5} & - & -  & - & -  & - & - \\
%  \hline

 \multicolumn{7}{c}{}\\
%Third table
 \hline
 & \emph{tactics} & \emph{n} & \emph{arg type} & \emph{arg} & \emph{symbols} & \emph{goals} \\
\hline
\hline
\emph{g1}&  $([rewrite]_{tac},0,0,0)$ & $1$  & $([Prop]_{type},$ & $([surB]_{term},$  & $([=]_{term},[+]_{term},[-]_{term})$& $1$ \\
 & & & $[Prop]_{type},$ & $[big\_nat\_recr]_{term}$ & & \\
 & & & $[Prop]_{type},$& $[big\_nat\_recl]_{term}$ & & \\
 & & & $[Prop]_{type})$& $[EL]_{term})$ & & \\
 \hline
  \emph{g2} & $([move:]_{tac},0,0,0)$ & $1$  & $([Prop]_{type},0,0,0)$ &  $([eq\_refl]_{term},0,0,0)$  & $([=]_{term},[+]_{term},[-]_{term})$ & $1$ \\
 \hline
  \emph{g3} & $([rewrite]_{tac},0,0,0)$ & $1$  & $([Prop]_{type},0,0,0)$  & $([subr\_eq0]_{term},0,0,0)$ & $([=]_{term},[+]_{term},[-]_{term})$ & $1$ \\
 \hline
\emph{g4}& $([move/]_{tac},[\texttt{->}]_{tac},0,0)$ & $2$  & $([Prop]_{type},0,0,0)$  & $([eqP]_{term},0,0,0)$ & $([=]_{term},[+]_{term},[-]_{term})$ & $1$ \\
 \hline
  \emph{g5} & $([rewrite]_{tac},0,0,0)$ & $1$  & $([Prop]_{type},0,0,0)$  & $([sub0r]_{term},0,0,0)$ & $([=]_{term},[+]_{term},[-]_{term})$ & $0$ \\
 \hline
  \end{tabular} 
  }}
 \end{table}


When proving Lemma~\ref{lem:nilpotent}, the user may call ML4PG after completing a few standard proof steps: apply induction and solve the base case using rewriting.
At this point it is difficult, even for an expert user, % 60 B?
to get the intuition that he could reuse the proofs from Example~\ref{example0} and Lemma~\ref{lem:fundamental}. There are several reasons for this.
First of all, the formal proofs of these lemmas are in different libraries; then, it is difficult to establish a conceptual connection among them. Moreover,
although the three lemmas involve summations,
the types of the terms of those summations are different. Therefore, search based on types or keywords would not help. Even search  % *a* search removed -- because 59B??? 
of all the lemmas involving summations does not provide a clear suggestion, since there are more than $250$ lemmas (a considerable number for handling them manually) --- a clever search-pattern will considerably reduced the number of suggested lemmas, but such a pattern is not trivial at all.

% \begin{table}
%  	\centering
%  	\tiny{
%  		\begin{tabular}{|l|l|}
%  		\hline
%  	Goals and Subgoals & Proof-Steps (Tactics) \\
%  		\hline
%  		\hline
%  	{\scriptsize $\forall~(M:M_n) (m:nat), M^m=0 \implies (1-M)\times \sum\limits_{i=0}^{m-1} M^i = 1$} & \\
%  			& {\scriptsize \lstinline?move => M m nilpotent.?} \\
%          {\scriptsize $(1-M)\times \sum\limits_{i=0}^{m-1} M^i = 1$} & \\
%         &   {\scriptsize\lstinline?rewrite big_distrr mulmxBr mul1mx.?}\\
%         {\scriptsize$   \sum\limits_{i=0}^{m-1} M^i - M^{i+1}$} &\\
%         
%         & {\scriptsize\lstinline?case : n.?}\\
%         {\scriptsize $ \forall~(M:M_0) (m:nat),M^m=0 \implies \sum\limits_{i=0}^{m-1} M^i - M^{i+1} $ }&\\
%         &  {\scriptsize\lstinline?by rewrite !thinmx0.?}\\
%          {\scriptsize$ \forall~(M:M_{n+1}) (m:nat), M^m=0 \implies \sum\limits_{i=0}^{m-1} M^i - M^{i+1} $}&\\
%  		\hline
%  		\end{tabular}
%  		
%  		}
%  	\caption{\textbf{First steps of the proof of Lemma~\ref{lem:nilpotent},} \emph{where the user stops and invokes ML4PG for a hint.}}
%  	\label{tab:sumfirstn}
%  \end{table}




However, if only the lemmas from Example~\ref{example0} and Lemma~\ref{lem:fundamental} are suggested when proving Lemma~\ref{lem:nilpotent}, the user would be able to
spot the following common proof pattern.

%\begin{IP}\label{ip:math}
%This proof pattern is followed by Lemmas~\ref{lem:nilpotent},~\ref{lem:fundamental} and~\ref{lem:lemma3}.
 
\begin{PS}\label{ps:math}
 
\emph{
%\begin{enumerate}
  %\item 
	Apply case on $n$.
  \begin{enumerate}
   \item Prove the base case (a simple task).
   \item Prove the case $0<n$:
     \begin{enumerate}
     \item expand the summation,
     \item cancel the terms pairwise,
     \item the terms remaining after the cancellation are the first and the last one. 
     \end{enumerate}
  \end{enumerate}
% \end{enumerate}
}
 
 
\end{PS}




% \begin{table}
%  	\centering
%  	\footnotesize{
%  		\begin{tabular}{|l|l|}
%  		\hline
%  	Goals and Subgoals & Proof-Steps (Tactics) \\
%  		\hline
%  		\hline
%  	{\scriptsize $\forall~(M:M_n) (m:nat), M^m=0 \implies \exists N, N \times (1-M)= 1$} & \\
%  			& {\scriptsize \lstinline?move => M m nilpotent.?} \\
%          {\scriptsize $\exists N, N \times (1-M)= 1$} & \\
%         &   {\scriptsize\lstinline?exists?}\\
%         &   {\scriptsize~~\lstinline?\sum_(0<=i<m.+1) (pot_matrix M i).?}\\
%         {\scriptsize$   (\sum\limits_{i=0}^{m-1} M^i) \times (1 - M) $} &\\
%         
%         & {\scriptsize\lstinline?rewrite big_distrl mulmxrB mulmx1.?}\\
%         {\scriptsize $ \sum\limits_{i=0}^{m-1} M^i - M^{i+1} $ }&\\
%                 & {\scriptsize\lstinline?case : n.?}\\
%         {\scriptsize $ \forall~(M:M_0) (m:nat),M^m=0 \implies \sum\limits_{i=0}^{m-1} M^i - M^{i+1} $ }&\\
%         &  {\scriptsize\lstinline?by rewrite !thinmx0.?}\\
%          {\scriptsize$ \forall~(M:M_{n+1}) (m:nat), M^m=0 \implies \sum\limits_{i=0}^{m-1} M^i - M^{i+1} $}&\\
%  		\hline
%  		\end{tabular}
%  		
%  		}
%  	\caption{\textbf{First steps of the proof of Lemma~\ref{lem:nilpotent2}.} \emph{Note the correlation between this proof and the proof of Lemma~\ref{lem:nilpotent} in Table~\ref{tab:sumfirstn}.}}
%  	\label{tab:nilpotent2}
%  \end{table}



Using the method presented in~\cite{KHG13}, if ML4PG was invoked during the proof of Lemma~\ref{lem:nilpotent}, it would suggest the lemmas from Example~\ref{example0} and 
Lemma~\ref{lem:fundamental}. However, 5 irrelevant lemmas 
 about summations would also be suggested (irrelevant in the sense that they do not follow Proof Strategy~\ref{ps:math}). The cluster containing just the two desired lemmas could be obtained after
increasing the \emph{granularity} value~\cite{KHG13} --- a statistical ML4PG parameter that can be adjusted by the user to obtain more precise clusters. The new version of ML4PG suggests four proof fragments, all following Strategy~\ref{ps:math} without needing to adjust granularity.

 
%There are two enhancements when we use the proof-patch method instead of the method presented in~\cite{KHG13}: 
The new method brings two improvements:
(1) the number of suggestions is increased, but, at the same time, (2) 
the clusters are more accurate. The proof-patch method considers fragments of proofs that are deep in the proof and were not considered before; therefore, it can find lemmas (more precisely patches of lemmas) that were not
included previously in the clusters. In our case study, ML4PG suggests two additional interesting proof fragments. The first one is an intermediate patch of the proof of 
Lemma~\ref{lem:fundamental}; then, two patches are suggested from this 
lemma: the proof-patch of the inner sum, and the proof-patch of the outer sum (both of them following Proof Strategy~\ref{ps:math}). The following lemma is also 
suggested.

\begin{lemma}\label{lem:nilpotent2}
Let $M$ be a nilpotent matrix, then there exists a matrix $N$ such that $N \times (1-M)=1$. 
\end{lemma}

At first sight, the proof of this lemma is an unlikely candidate to follow  Proof Strategy~\ref{ps:math}, since the statement of the lemma
does not involve summations. However, inspecting its proof, we can see that it uses $\sum_{i=0}^{n-1} M^i$ as witness for $N$ and 
then follows Proof Strategy~\ref{ps:math}. In this case, ML4PG suggests the patch from the last five proof-steps that correspond to 
the application of Proof Strategy~\ref{ps:math}. 


%The proof-patch method increases the number of suggestions; this could be a problem if more irrelevant lemmas were suggested. However, 
The new numbering of features produces more accurate clusters removing the irrelevant lemmas. In particular, using the default settings, 
ML4PG only suggests the lemma from Example~\ref{example0}, the two patches from Lemma~\ref{lem:fundamental} and the last patch from 
Lemma~\ref{lem:nilpotent2}. If the granularity is increased, the last patch from 
Lemma~\ref{lem:nilpotent2} is the only suggestion --- note that this is the closest lemma to Lemma~\ref{lem:nilpotent}. 

%The discovery of proof-patterns can be a challenging task, but increasing the number and precision of suggestions simplifies this problem. 
%With the same goal (facilitate the discovery of proof-pattens), we introduce a graphical representation in the next section.




















% the four lemmas given above follow the Strategy \ref{ps:math} is our next benchmarking task for ML4PG.
% Table~\ref{tab:compare0} shows the results that ML4PG will obtain, if the user varies the clustering algorithms and the size of clusters when 
% calling ML4PG within the proof environment; we also highlight the exact solution to our benchmark task, given by calling K-means algorithm with granularity $4$. 
 
% \begin{table}
% \centering
% {\scriptsize 
%    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
%      \hline
%     & $g=1$& $g=2$& $g=3$& $g=4$ & $g=5$\\
%       Algorithm: & ($n=84$) & ($n=94$) & ($n=108$) & ($n=126$) & ($n=151$)\\     \hline
%      K-means &76$^{a-d}$ &51$^{a-d}$  &16$^{a-d}$ &\textbf{4}$^{a-d}$&2$^{b,d}$  \\
%      \hline
%      E.M. &26$^{a-d}$  &51$^{a,b,d}$ &41$^{a,b,d}$  &11$^{b,c,d}$ &3$^{a,b,d}$ \\
%      \hline
%      FarthestFirst &81$^{a-d}$ &48$^{a-d}$ &31$^{a-d}$  &25$^{a-d}$  &21$^{a-d}$  \\
%      \hline
%     \end{tabular}      }
%           
%    \caption{\textbf{Clustering experiments discovering Proof Strategy~\ref{ps:math}.} \emph{When  $g$ is chosen by the user, 
%    ML4PG dynamically calculates the number of clusters $n$. Choosing Lemma~\ref{lem:nilpotent} for pattern-search,  
%   the table shows the size of the single cluster that ML4PG displays to the user for every choice of $g$.
%    The table shows sizes of clusters containing: $a)$ Lemma~\ref{lem:nilpotent}, $b)$ Lemma~\ref{lem:lemma3},  $c)$ Lemma~\ref{lem:fundamental} and
%    $d)$ Lemma~\ref{lem:nilpotent2}. Note that with all variations of the learning algorithms and parameters, ML4PG is consistently grouping the
% correct lemmas into clusters, albeit with varied degree of precision. Note also the effect of the granularity parameter, the smallest granularity value $g=1$ produces big 
% clusters that are difficult to inspect; on the contrary, the biggest value $g=5$ produces small clusters that might not contain enough elements to spot a pattern. 
% The most accurate result for this example is obtained using the K-means algorithm and 4 as granularity parameter.}}\label{tab:compare0}
%   \end{table}
%  
% 
% Table~\ref{tab:compare0} gives an insight on how granularity parameter $g$ can be used in pattern-recognition within ML4PG.
%  One can use a ``bottom-up approach'' to detect patterns starting with the granularity value of 1 and increasing that value in successive calls.
% Using the default values $g=3$ and K-means algorithm, ML4PG obtains 15 suggestions related to lemmas about summations including Lemmas~\ref{lem:lemma3} 
% and~\ref{lem:fundamental}. Increasing the granularity level to 4, ML4PG discovers that Lemma  \ref{lem:nilpotent} is similar to 
% Lemmas~\ref{lem:lemma3}, \ref{lem:fundamental} and \ref{lem:nilpotent2}. Finally, increasing the granularity level to the maximum level of $5$, 
% ML4PG just discovers that Lemmas \ref{lem:nilpotent} and  \ref{lem:nilpotent2} are similar. %and also the following lemma; 


% When the proof analogy is found (as all four proof patches taken by ML4PG follow steps $1$ and $2(a)$ of Proof Strategy \ref{ps:math}), the user can use the remaining proof steps for Lemma~\ref{lem:nilpotent2} as a template for reconstructing the remaining proof for Lemma~\ref{lem:nilpotent} (by analogy with the steps $2(b)$ and $2(c)$ in Lemma~\ref{lem:nilpotent2}). % in case of the four lemmas mentioned here, the remaining steps all follow the Strategy \ref{ps:math}. Thus, ML4PG finds patterns arising from 
% The heterogeneous cluster obtained in this scenario belongs to the category of clusters consisting of theorems that share the same proof structure and as well as an 
% auxiliary lemma (e.g. the lemma used to expand the summation). 



