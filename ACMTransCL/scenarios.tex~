\section{User scenarios}\label{sec:scenarios}

In this section, we present 3 different scenarios that illustrate how ML4PG can be used to facilitate the 
proof development by detecting patterns across libraries. It is worth mentioning that we do not have a
quantitative target when it comes to improving \emph{interactive} proof building experience -- 
unlike e.g. related work on using machine-learning for automated premise selection \cite{ku12,Mash}. 
No longer speed up in automated proof search or the number of automatically proven theorems are the main criteria of success.
We generally follow the intuition that ML4PG, being an interactive hint generator, must provide \emph{interesting and non-trivial} hints on user's demand,
and should be flexible enough to do so at \emph{any stage} of the proof, and relative to any chosen proof library.      


\subsection{User scenario 1. Detecting patterns in early-stages of the development}\label{subsec:benchssr}

Users of ITPs usually start their developments loading some libraries. Those libraries contain definitions, theorems and notations 
that will be used as background theory during the proof process. Some of those libraries are specific for concrete theories,
but other ones are common for almost every development. The common libraries contain strategies that can be extrapolated 
to other contexts; however, detecting the lemmas that follow a concrete proof-strategy can be a challenge. In the first scenario, 
we study the patterns that appear in the SSReflect library~\cite{SSReflect}.

The SSReflect library was developed as infrastructure for the formalisation of the Four Colour Theorem~\cite{FCT} and has played 
a key role in the formal proof of the Feit-Thompson theorem~\cite{FTT}. Up to version 1.4, the SSReflect library was distributed together 
with the theories about the proof of the Feit-Thompson theorem; from version 1.5, the SSReflect library can be downloaded independently
from the Mathcomp library (the one containing the proof of the Feit-Thompson theorem). 

The SSReflect library extends the Coq proof language and consists of 7 files containing basic theories 
about: natural numbers, lists, booleans, functions, finite types, choice types and types with a decidable equality. 
The library contains a total of 1404 theorems and 457 definitions; therefore, a manual inspection of these theorems and definitions to detect patterns is unfeasible. In our first scenario,
we test how ML4PG can be used to detect patterns in the SSReflect library. In particular, we consider the following two challenges:

\begin{itemize}
 \item[\textbf{C.1.}] Detect the patterns which arise in the definitions of the SSReflect library. 
 \item[\textbf{C.2.}] Detect the patterns that appear across proofs in the SSReflect library. 
\end{itemize}


Let us start with Challenge \textbf{C.1}. In general, the discovery of definitions in ITPs is a difficult task: they are distributed across 
libraries and usually they are poor-documented. Hence, non-expert users can be tempted to define their notions from scratch instead 
of searching whether that definitions are already in the libraries. This approach has a clear drawback: if a user introduces a new 
definition, he needs to develop a background theory about it; however, if he uses a definition already available, he can take advantage of the results previously
proven about it.

We consider a scenario where a user wants to define a theory about lists of natural numbers using the SSReflect library.
In this theory, the user wants to use a function which counts the number of elements of a list, but if he 
does not know the existence of the \lstinline?size? SSReflect function (it is defined in the same way as the \lstinline?length? function of 
Example~\ref{example-len} but using the notation \lstinline?seq? for the type \lstinline?list?), he could define his own function in the following way.

\begin{lstlisting}
Fixpoint mylength (l : list nat) :=
  match l with | cons x l' => mylength l' + 1 | nil => 0 end.
\end{lstlisting}

Both \lstinline?size? and \lstinline?mylength? count the number of elements of a list; however, their definitions have several differences:
different names, variable names, order of conditions and functions involved, use of notations (\lstinline?seq? is a notation for \lstinline?list?) 
and different types (\lstinline?mylength? has type 
\lstinline?list nat -> nat? and \lstinline?size? has type \lstinline?T -> seq T -> nat?). However, as can be seen in Table~\ref{tab:matrix}, there is 
a strong correlation between the term-tree feature matrices associated with \lstinline?size? and \lstinline?mylength?. Thanks to this strong correlation, 
ML4PG suggests that both definitions are similar for various granularity values and algorithms, see Table~\ref{tab:defs}.


\begin{table}
  
  
   \scriptsize{
  \begin{tabular}{|c||c|c|c|c|c|c|c|}
     \hline
    & variables & arity 0 & arity 1 & arity 2 & arity 3 \\
    \hline
    \hline
    tree depth $0$ & \textbf{0}  &\textbf{0}  &  \textbf{0}   &\textbf{0}     & \textbf{[match]}\\
    \hline
    tree depth $1$ & [l] & \textbf{0} &  \textbf{0} & \textbf{[case]::[case]}  &\textbf{0} \\
    \hline
    tree depth $2$ & \textbf{0}  & \textbf{[nil]::[0]}  & 0 & [cons]::[+]   & \textbf{-}\\
    \hline
    tree depth $3$ & [x]::[l'] & [1]  & \textbf{mylength}   & \textbf{0}  & \textbf{-}\\
    \hline
    tree depth $4$ & \textbf{l'} & \textbf{0}  &  \textbf{0} & \textbf{0}  &\textbf{0} \\
    \hline    
 \end{tabular}}
  
\caption{\textbf{Term-tree feature extraction matrix for \texttt{mylength}.} \emph{We highlight in bold the correlation between \texttt{mylength} and \
texttt{size}. There is a strong correlation between \texttt{mylength} and \texttt{size} (44 out of 49 features).}}\label{tab:matrix} 
 
\end{table}



\begin{table}
\centering
   \scriptsize{
 \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
   \hline
    & $g=1$& $g=2$& $g=3$& $g=4$ & $g=5$\\
      Algorithm: & ($n=50$) & ($n=57$) & ($n=65$) & ($n=76$) & ($n=91$)\\
   \hline
   K-means  &21  &21  &11  &8 &3  \\
   \hline
   E.M. &33  & 31  & 31 &28 &11  \\
   \hline
   FarthestFirst &75 & 63&  47 &25 &20  \\
   \hline
   
  \end{tabular} }
  \caption{\textbf{A series of clustering experiments discovering that \texttt{mylength} and \texttt{size} are similar definitions.}
  \emph{The table shows the sizes of clusters containing \texttt{mylength} and \texttt{size} -- all the clusters contain both definitions. The size of the data set is 457 lemmas and
  contains all the definitions included in the SSReflect library.}}\label{tab:defs}
\end{table}


We have empirically evaluated the usability of this new extension of ML4PG using the data set containing the 457 definitions included in the SSReflect library. To this aim,
we have redefined 100 of those definitions using different variable names, notations, considering generalisations and particular cases and also redefining some of the types
that they use. If we consider the clusters obtained with granularity 5 and using the K-means algorithm (the two values that produce the best results), in $95\%$
of the cases the clusters contain both the original definition and its variant; in addition, the mean of the size of these clusters is 6 elements; then, we only need to check 
$5$ definitions to see if a definition was previously introduced -- a simpler task than checking the whole library. If we reduce the granularity value to $4$, the success rate 
is $100\%$; however, the size of the clusters increases (they contain approximately $20$ definitions). 

This tool can be specially useful at the early stages of the development: using ML4PG the user can find if one of his definitions was previously defined and in that case 
using the \lstinline?Search? command with the name of the function as argument, he can find all the theorems about such a function and reduce the burden of proving results
that are already in the libraries.

We focus now on Challenge \textbf{C.2}: the detection of patterns in the proofs of the SSReflect library. In particular, we analyse the clusters that are produced using 
this library and using the K-means algorithm and the value $5$ as granularity parameter -- these options have produce the best results in our experiments. 

ML4PG discovers 280 clusters using those parameters. In the $45\%$ of those clusters (126 clusters), all the lemmas belong to the same library. The mean size of these
homogeneous clusters are 4 elements, and the similarities of the lemmas of a cluster can be easily spotted.  
From these 126 clusters, the $36\%$ of the clusters are lemmas about related functions: for instance, ML4PG discover cluster contains lemmas about \lstinline?leq? ($<=$) and 
\lstinline?lgt? ($<$), \lstinline?max? and \lstinline?min? functions, \lstinline?and? and \lstinline?or? operators, and \lstinline?take? and \lstinline?drop? list operators
(\lstinline?take? takes the first $n$ elements of a list and \lstinline?drop? removes the first $n$ elements of the list). The $20\%$ of clusters have lemmas that follow the 
same proof structure and that share some common auxiliary results, and a $13\%$ of clusters consists of theorems that are used in the proofs of other theorems of the 
same cluster. The $11\%$ of clusters are view lemmas, an important kind of lemmas that are used in SSReflect to apply boolean reflection~\cite{SSReflect}. 
A $5\%$ of the lemmas are equivalence lemmas that are proven just by simplification. 

In the case of heterogeneous clusters, ML4PG discovers 154 clusters. In this case, the size of the clusters is bigger than in the case of homogeneous clusters; namely, 
the mean size is 8 lemmas per cluster. $31\%$ of these clusters are lemmas that state properties that can be applied to several operators from different libraries 
(e.g. associativity for \lstinline?cat? operator -- concatenation of lists -- and \lstinline?add? function, or inner commutativity of \lstinline?or? operator and \lstinline?add?
function), the proof of all these lemmas is similar but it is adapted to the concrete library. The $27\%$ of clusters consists of lemmas related to operations over 
base case of types (e.g. the lemmas \lstinline?andTb : forall x, true && x = true? and \lstinline?mul0n: forall x, 0 * n = 0? are in the same cluster), these lemmas can be 
easily proved applying cases and simplification. The lemmas of the previous clusters are fundamental lemmas, the similarity of a $12\%$ of the clusters come from lemmas whose
proof rely on the fundamental lemmas. A $9\%$ of the clusters combine lemmas from the libraries about lists and natural numbers -- note that the definition of lists
and natural numbers is quite similar, both have one base case and a recursive one, so several lemmas are solved applying induction and using the inductive hypothesis. 


The similarity of most clusters ($79\%$ of them) can be easily discovered just inspecting the statement of the lemmas and their proofs. However, clustering is a statistical 
tool and in some cases there is not a clear correlation among the lemmas of a cluster. In most of those cases, the clusters contain more than 10 elements, and we can discover
patterns among subsets of those clusters, but it is difficult to find a common pattern followed by all lemmas. 





\subsection{User scenario 2. Detecting patterns across libraries during a proof}\label{subsec:bench1}

The second case study concerns discovery of proof patterns in mathematical proofs
across formalisations of apparently disjoint mathematical theories:
Linear Algebra, Combinatorics and Persistent Homology. In this scenario, we use statistically discovered proof patterns to 
advance the proof of a given ``problematic'' lemma. In this case,  a few initial steps in its proof are 
clustered against several mathematical libraries.  

In this section, we deliberately take lemmas belonging to very different Coq libraries.
%These lemmas come from different contexts. 
Lemma~\ref{lem:nilpotent} states a result about
\emph{nilpotent} matrices~\cite{BR91} (a square matrix $M$ is \emph{nilpotent} if there exists an $n$ such that $M^n=0$). Lemma~\ref{lem:lemma3} is a basic fact about
summations (previously presented in Example~\ref{example0}).
 Finally, 
Lemma~\ref{lem:fundamental} is a generalisation of the \emph{fundamental 
lemma of Persistent Homology}~\cite{HCMS12}.


\begin{lemma}\label{lem:nilpotent}
 Let $M$ be a square matrix and $n$ be a natural number such that $M^n=0$, then $(1-M)\times \sum\limits_{i=0}^{n-1} M^i = 1$.
\end{lemma}

\begin{lemma}\label{lem:lemma3}
If $g:\mathbb{N} \rightarrow \mathbb{Z}$, then 
$$\sum_{0\leq i \leq n} (g(i+1) - g(i)) = g(n+1) - g(0).$$
\end{lemma}


\begin{lemma}\label{lem:fundamental}
Let $\beta_n^{k,l}:\mathbb{N} \times \mathbb{N} \times \mathbb{N} \rightarrow \mathbb{Z}$, then
$$\beta_n^{k,l} - \beta_n^{k,m}= \sum_{0\leq i \leq k} \sum_{l<j\leq m} (\beta_n^{i,j-1} - \beta_n^{i,j}) - (\beta_n^{i-1,j-1} - \beta_n^{i-1,j}).$$
\end{lemma}




When proving Lemma~\ref{lem:nilpotent}, it is difficult, even for the expert user, % 60 B?
to get the intuition that he can reuse the proofs of Lemmas~\ref{lem:lemma3} and~\ref{lem:fundamental}. There are several reasons for this.
First of all, the formal proofs of these lemmas are in different libraries: the proof of Lemma~\ref{lem:nilpotent} is in the library about matrices, 
the proof of Lemma~\ref{lem:lemma3} is in the library about basic results concerning summations, and the proof
of Lemma~\ref{lem:fundamental} is in the library about Persistent Homology.  Then, it is difficult to establish a conceptual connection among them. Moreover,
although the three lemmas involve summations,
the types of the terms of those summations are different. Therefore, search based on types or keywords would not help. Even search  % *a* search removed -- because 59B??? 
of all the lemmas involving summations does not provide a clear suggestion, since there are more than $250$ lemmas -- a considerable number for handling them manually.

However, if Lemmas~\ref{lem:lemma3} and~\ref{lem:fundamental} are suggested when proving Lemma~\ref{lem:nilpotent}, the expert would be able to
spot the following common proof pattern.

%\begin{IP}\label{ip:math}
%This proof pattern is followed by Lemmas~\ref{lem:nilpotent},~\ref{lem:fundamental} and~\ref{lem:lemma3}.
 
\begin{PS}\label{ps:math}
 
\emph{
\begin{enumerate}
  \item Apply case on $n$.
  \begin{enumerate}
   \item Prove the base case (a simple task).
   \item Prove the case $0<n$:
     \begin{enumerate}
     \item expand the summation,
     \item cancel the terms pairwise,
     \item the only terms remaining after the cancellation are the first and the last one. 
     \end{enumerate}
  \end{enumerate}
 \end{enumerate}}
 
 
\end{PS}


We also include the following lemma. At first sight, the proof of this lemma does not seem to fit  Proof Strategy~\ref{ps:math}, since the statement of the lemma
does not involve summations. However, inspecting its proof, we can see that it uses $\sum_{i=0}^{n-1} M^i$ as witness for $N$ and 
then follows Proof Strategy~\ref{ps:math}. 

\begin{lemma}\label{lem:nilpotent2}
Let $M$ be a nilpotent matrix, then there exists a matrix $N$ such that $N \times (1-M)=1$. 
\end{lemma}

Discovering that, across 758 lemmas and 5~libraries, the four lemmas given above follow the Strategy \ref{ps:math} is our next benchmarking task for ML4PG.
Table~\ref{tab:compare} shows the results that ML4PG will obtain, if the user varies the clustering algorithms and the size of clusters when 
calling ML4PG within the proof environment; we also highlight the exact solution to our benchmark task. 
 
\begin{table}
\centering
{\scriptsize 
   \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
     \hline
    & $g=1$& $g=2$& $g=3$& $g=4$ & $g=5$\\
      Algorithm: & ($n=84$) & ($n=94$) & ($n=108$) & ($n=126$) & ($n=151$)\\     \hline
     K-means &76$^{a-e}$ &51$^{a-e}$  &16$^{a-e}$ &\textbf{5}$^{a-e}$&2$^{b,e}$  \\
     \hline
     E.M. &26$^{a-e}$  &51$^{a,b,d,e}$ &41$^{a,b,e}$  &11$^{b,c,d,e}$ &31$^{a,b,e}$ \\
     \hline
     FarthestFirst &81$^{a-e}$ &48$^{a-e}$ &31$^{a-e}$  &25$^{a-e}$  &21$^{a-e}$  \\
     \hline
    \end{tabular}      }
          
   \caption{\textbf{Clustering experiments discovering Proof Strategy~\ref{ps:math} using the proof-patch method.} \emph{When  $g$ is chosen by the user, 
   ML4PG dynamically calculates the number of clusters $n$; choosing Lemma~\ref{lem:nilpotent} for pattern-search,  
  the table shows the size of the single cluster that ML4PG displays to the user for every choice of $g$.
   The table shows sizes of clusters containing: $a)$ Lemma~\ref{lem:nilpotent}, $b)$ Lemma~\ref{lem:lemma3},  $c)$ Lemma~\ref{lem:fundamental} inner sum, 
   $d)$ Lemma~\ref{lem:fundamental} outer sum and $e)$ Lemma~\ref{lem:nilpotent2}.}}\label{tab:compare}
  \end{table}
  
It turns out that Proof Strategy~\ref{ps:math} can be applied twice in the proof of Lemma~\ref{lem:fundamental}, firstly in the inner summation and 
subsequently in the  remaining proof. Then, two of the suggestions provided by ML4PG in this case come from the proof of Lemma~\ref{lem:fundamental}.
This is achieved thanks to the proof-patch method, presented in Section~\ref{sec:ml4pg}, that considers small patches of proofs. 
 



\begin{example}\label{ex:gr}
As Table~\ref{tab:compare} shows,  one can use a ``bottom-up approach'' to detect patterns starting with the granularity value of 1 and increasing that value in successive calls.
Using the default value $g=3$ and e.g. K-means algorithm, ML4PG obtains 15 suggestions related to lemmas about summations including Lemmas~\ref{lem:lemma3} 
and~\ref{lem:fundamental}. Increasing the granularity level to 4, ML4PG discovers that Lemma  \ref{lem:nilpotent} is similar to 
Lemmas~\ref{lem:lemma3}, \ref{lem:fundamental} (both the inner and outer sum), and \ref{lem:nilpotent2}. Finally, increasing the granularity level to the maximum level of $5$, 
ML4PG just discovers that Lemmas \ref{lem:nilpotent} and  \ref{lem:nilpotent2} are similar. %and also the following lemma; 

\end{example}




\subsection{User scenario 3. A team-based development}

In the last scenario, we turn to team-based applications of Coq and ML4PG. For this purpose,
we translate the ACL2 proofs of correctness of the Java Virtual Machine (JVM)~\cite{M03} into Coq. 
JVM~\cite{JVM} is a stack-based abstract machine which can execute Java bytecode. We have modelled an interpreter for
JVM programs in Coq. From now on, we refer to our machine as ``CJVM'' (for Coq JVM). 

Industrial scenario of interactive theorem proving may involve distribution of work-load across a team, and a bigger proportion of 
routine or repetitive cases. Here, the inefficiency often arises when programmers use different notation to accomplish very similar tasks,
and thus a lot of work gets duplicated, see also~\cite{BHJM12}. We tested ML4PG in exactly such scenario: we assumed that a programming 
team is collectively developing proofs of \emph{a) soundness of specification, and b) correctness of implementation}
of Java bytecode for a dozen of programs computing multiplication, powers, exponentiation, and other functions about natural numbers. 

Given a specific Java method, we can translate it to Java bytecode using a tool such as
\lstinline?javac? of Sun Microsystems. Such a bytecode can be executed in CJVM 
provided a schedule, and the result will be the state of the JVM at the end of the schedule. 
Moreover, we can prove theorems about the CJVM model behaviour when interpreting that 
bytecode. 

\begin{example}
The bytecode associated with the factorial program can be seen
in Figure~\ref{fig:factorial_bytecode}.

\begin{figure}
\begin{minipage}{0.3\linewidth}
\centering
{\scriptsize
\begin{lstlisting}
static int factorial(int n)
{
  int a = 1;
  while (n != 0){
    a = a * n;
    n = n-1;
    }
  return a;
}
\end{lstlisting}}
\end{minipage}
\begin{minipage}{0.175\linewidth}
\centering
{\scriptsize
$\begin{array}{ccl}
0&:& iconst~1\\
1&:& istore~1\\
2&:& iload~0\\
3&:& ifeq~13\\
4&:& iload~1\\
5&:& iload~0\\
6&:& imul\\
7&:& istore~1\\
8&:& iload~0\\
9&:& iconst~1\\
10&:& isub\\
11&:& istore~0\\
12&:& goto~2\\
13&:& iload~1\\
14&:& ireturn\\
\end{array}$}
\end{minipage}
\hspace{0.5cm}
\begin{minipage}{0.35\linewidth}
\centering
{\scriptsize
\begin{lstlisting}
Fixpoint helper_fact (n a) :=
match n with 
| 0 => a
| S p => helper_fact p (n * a)
end.

Definition fn_fact (n : nat) := helper_fact n 1.
\end{lstlisting}}
\end{minipage}

\caption{\emph{\textbf{Factorial function}. \textbf{Left:} Java program for computing the factorial of natural numbers. \textbf{Centre:} Java bytecode
associated with the Java program. \textbf{Right:} tail recursive version of the factorial function in Coq.}}\label{fig:factorial_bytecode} 
 
\end{figure}
\end{example}


The state of the CJVM consists of 4 fields: a \emph{program counter} (a natural number), a set of registers called \emph{locals}
(implemented as a list of natural numbers), an operand \emph{stack} (a list of natural numbers), and the bytecode \emph{program}
of the method being evaluated.

Java bytecode, like the one presented in Figure~\ref{fig:factorial_bytecode}, can be executed within CJVM. However, more interesting than mere executing
Java bytecode, we can prove the correctness of the implementation of the Java bytecode programs using Coq. 
For instance, in the case of the factorial program, we can prove the following theorem, which states the correctness of the \lstinline?factorial? bytecode. 

\begin{lemma}\label{lem:factorial}
Given a natural number $n$ and the factorial program with $n$ as an input, CJVM produces a state which contains $n!$ on top of the stack
 running the bytecode associated with the program.  
\end{lemma}

The proof of theorems like the one above  always follows the same methodology adapted from ACL2 proofs about Java Virtual Machines~\cite{M03}
and which consists of the following three steps.

\begin{enumerate}
 \item[(1)] Write the specification of the function, write the algorithm, and prove that the algorithm satisfies the specification.
 \item[(2)] Write the JVM program within Coq, define the function that schedules the program (this function will make CJVM
 run the program to completion as a function of the input to the program), and prove that the resulting code implements this algorithm.
 \item[(3)] Prove total correctness of the Java bytecode.
\end{enumerate}

Using this methodology, we have proven the correctness of several programs related to arithmetic (multiplication of natural
numbers, exponentiation of natural numbers, and so on); see \cite{HK12}. The proof of each theorem was done independently from others to  model a distributed proof development.

Therefore, we simulated the following scenario.
Suppose a new developer tackles for the first time the proof of Lemma~\ref{lem:factorial}, and he knows the
general methodology to prove it and has access to the library of programs previously proven by other users. In this situation 
the different notation employed by different users obscure some common features.
ML4PG would be a good alternative to the manual search for proof patterns.

Let us focus on the first step of the methodology -- that is, the proof of the equivalence between the specification of the factorial function (which is already defined in
SSReflect) and the algorithm. The Java factorial function is an iterative function; and
the algorithm is written in Coq as a tail recursive function, see the right side of Figure~\ref{fig:factorial_bytecode}. In general, all
the tail recursive functions are defined using an auxiliary function, called the \emph{helper}, and a wrapper for such a function. The suggestions
provided by ML4PG in this case are the proofs of step $(1)$ for three iterative programs: the multiplication, the exponentiation and the power of
natural numbers. All of them follow the same proof strategy which can be also applied in the case of factorial: 

\begin{PS}\label{ps:spec}
 
\emph{Prove an auxiliary lemma about the helper considering the most general case. For example, if the helper function is defined with formal parameters
$n$, $m$, and $a$, and the wrapper calls the helper initializing $a$ at $0$, the helper theorem must be about \lstinline?(helper n m a)?, not just about the special
case \lstinline?(helper n m 0)?. Subsequently, instantiate the lemma for the concrete case.}
 
\end{PS}
	
Discovery of proofs following Proof Strategy \ref{ps:spec} among 147 JVM library lemmas is our last benchmarking task for ML4PG.

\begin{example}
ML4PG will correctly suggest similar lemmas to Lemma~\ref{lem:factorial} in the libraries for multiplication, exponentiation and power.
%, if we use the 
%following settings:  
For this, we consider 15 libraries for clustering related to formalisations of arithmetic JVM programs.
These libraries involve 147 lemmas for ML4PG to analyse. Table~\ref{tab:jvm} shows the results for different choices of algorithms and parameters, and we highlight the exact match 
between the benchmark task and the ML4PG result. In case the user is unsure of the optimal machine-learning parameters, we recommend to use  a ``top-down approach''.
The highest granularity level does not produce any result. But, if we decrease 
the granularity level to 4, ML4PG spots some interesting similarities. If  this is not enough to discover Proof Strategy~\ref{ps:spec}; one can decrease the granularity level 
to $3$, for which ML4PG discovers exactly the four benchmark lemmas presented in this section. 

\begin{table}
\centering
{\scriptsize
 \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
   \hline
    & $g=1$& $g=2$& $g=3$& $g=4$ & $g=5$\\
      Algorithm: & ($n=16$) & ($n=18$) & ($n=21$) & ($n=24$) & ($n=29$)\\
   \hline
   K-means (Weka) &30$^{a,b,d}$   &\textbf{4}$^{a-d}$  &\textbf{4}$^{a-d}$ & 2$^{c,d}$& 0 \\
   \hline
   E.M. &21$^{a-d}$  &7$^{a-d}$  & 7$^{a-d}$ &0 &0  \\
   \hline
   FarthestFirst &28$^{a-d}$ & 25$^{a-d}$&  0 &0 &0  \\
   \hline
   
  \end{tabular} }
  \caption{\textbf{A series of clustering experiments discovering Proof Strategy~\ref{ps:spec}.} \emph{The table shows the sizes of clusters containing: 
  $a)$ Lemma about JVM multiplication program, $b)$ Lemma about JVM power program, $c)$ Lemma about JVM exponentiation program, and $d)$ Lemma about JVM factorial
  program. The size of the data set is 147 lemmas, in bold is the cluster that finds exactly the four benchmark examples.}}\label{tab:jvm}
\end{table}

\end{example}

It is very encouraging that, with all variations of the learning algorithms and parameters shown in Tables~\ref{tab:defs},~\ref{tab:compare} and \ref{tab:jvm}, ML4PG is consistently 
grouping the correct definitions and lemmas into clusters, albeit with varied degree of precision. Judging by the experiments, K-means algorithm is the most reliable; 
it shows very stable results; asking the user the very minimum effort of adjusting the granularity parameter to obtain the result of required precision. ML4PG is 
very fast and give instant outputs allowing the user to have quick search/evaluation.  



