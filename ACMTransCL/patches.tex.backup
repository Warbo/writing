\section{Recurrent Proof Clustering}\label{sec:recurrent}

The method presented in the previous section can cluster similar statements of Coq theorems; 
however, this method does not capture the interactive nature of Coq proofs.
In this section, we involve proofs into the recurrent clustering of Coq libraries.

 In~\cite{KHG13}, 
we introduced a method to extract features from Coq proofs capturing
the interaction of the user through the applied tactics. That method 
tracks simple, low level properties that apply to any possible subgoal, e.g. ``the
top symbol'' or ``the argument type''. Further, these shallow features are taken
in relation to the statistics of user actions on every subgoal: how many and what
kind of tactics he applied, and what kind of arguments he provided to the
tactics. Finally, a few proof-steps are taken in relation to each other.
This method  had two drawbacks.\\ 
% (1) It only captures information 
% about the top symbol of the goal; this means that information is mainly collected 
% from symbols such as \lstinline?forall? or \lstinline?equal? (common to most proofs)
% and features from other symbols (that are likely more relevant for the proof) are never captured.
(1) The method  focused on the first
five proof-steps of a Coq proof; therefore, some information was lost. We address this issue by dividing each proof into proof-patches, and analysing a proof by the properties
of the patches that constitute the proof. \\
(2) The method assigned feature values blindly, thus being insensitive to many important parameters, such as e.g. the structure of lemmas and hypotheses used within a proof. 
Last section gave us the way of involving all Coq objects into recurrent feature re-evaluation.
%, and, as we have explained in the previous section, machine-learning algorithms are sensitive to 
%the assignment of feature values. These drawbacks have been overcome combining a new method called the 
%\emph{proof-patch method} and the term feature extraction method presented in the previous section. 


The underlying idea of \emph{proof-patches} is that one small proof may potentially 
resemble a fragment of a bigger proof; also, various small ``patches'' of different big proofs may resemble. 
%We start defining the notions of Coq proof and proof-patch matrices. 

\begin{definition}[Coq proof]
 Given a statement $S$ in Coq, a \emph{Coq proof} of $S$ is given by a sequence of triples $((\Gamma_i,G_i,T_i))_{0\leq i\leq n}$ where $\Gamma_i$ is a context,
 $G_i$ is a goal and $T_i$ is a sequence of tactics satisfying:

  - $G_0=S$,
  
  - $\forall i$, $\Gamma_i$ is the context of the goal $G_i$,
  
  - $\forall i$ with $0<i\leq n$, $\Gamma_i,G_i$ are respectively the context and goal obtained after applying $T_{i-1}$, and 
  
  - the application of $T_n$ completes the proof.

\end{definition}


\begin{table}[t]
 	\centering
 	\tiny{
 		\begin{tabular}{|l|l|}
 		\hline
 	Goals and Subgoals & Applied Tactics \\
 		\hline
 		\hline
 	{\scriptsize $G_0) \forall~n,\sum\limits_{i=0}^{n} (g(i+1) - g(i)) = g(n+1) - g(0)$} & \\
 			& $T_0)$ {\scriptsize \lstinline?case : n => [|n _].?} \\
        $G_1) \sum\limits_{i=0}^{0} (g(i+1) - g(i)) = g(1) - g(0)$ & \\
        & $T_1)$  {\scriptsize\lstinline?by rewrite big_nat1.?}\\
        $G_2)  \sum\limits_{i=0}^{n+1} (g(i+1) - g(i)) = g(n+2) - g(0)$ &\\
        
        & $T_2)$ {\scriptsize\lstinline?rewrite sumrB big_nat_recr big_nat_recl ?}\\
          & ~~~~~~~~{\scriptsize\lstinline?     addrC addrC -subr_sub -!addrA addrA.?} \\
        $G_3) g(n+2) + \sum\limits_{i=0}^{n} g(i+1) -  \sum\limits_{i=0}^{n} g(i+1) - g(0) =$ &\\
        $  g(n+2) - g(0)$ &\\
        &$T_3)$  {\scriptsize\lstinline?move : eq_refl.?}\\
        $G_4) \sum\limits_{i=0}^{n} g(i+1) == \sum\limits_{i=0}^{n} g(i+1) \rightarrow  $ &\\
        $g(n+2) + \sum\limits_{i=0}^{n} g(i+1) -  \sum\limits_{i=0}^{n} g(i+1) - g(0) =$ &\\
        $  g(n+2) - g(0)$ &\\
        &$T_4)$  {\scriptsize\lstinline?rewrite -subr_eq0.?}\\
        $G_5) \sum\limits_{i=0}^{n} g(i+1) - \sum\limits_{i=0}^{n} g(i+1) == 0\rightarrow  $ &\\
        $g(n+2) + \sum\limits_{i=0}^{n} g(i+1) -  \sum\limits_{i=0}^{n} g(i+1) - g(0) =$ &\\
        $  g(n+2) - g(0)$ &\\
        &$T_5)$  {\scriptsize\lstinline?move/eqP => ->.?}\\
         $G_6)  g(n+2) + 0 - g(0) = g(n+2) - g(0)$ &\\
        &$T_6)$  {\scriptsize\lstinline?by rewrite sub0r.?}\\
 		$\Box$ & \\
 		& {\scriptsize\lstinline?Qed.?}\\
 		\hline
 		\end{tabular}
 		
 		}
 	\caption{\emph{Proof for the lemma of Example~\ref{example0} in SSReflect.}}
 	\label{tab:sumfirstn}
 \end{table}


\begin{example}\label{example0}
Table~\ref{tab:sumfirstn} shows the Coq proof of the following statement:
 $$\forall g:\mathbb{N} \rightarrow \mathbb{Z}\implies \sum_{0\leq i \leq n} (g(i+1) - g(i)) = g(n+1) - g(0)$$
\end{example}

\begin{definition}[Proof-patch]
 Given a statement $S$ and a \emph{Coq proof} $C=((G_i,T_i))_i$ of $S$, a \emph{proof-patch} of $C$ is a subsequence of at most $5$ consecutive 
 pairs of $C$.
\end{definition}

From proof-patches, we can construct the matrices that will be provided to the machine-learning algorithms. The feature-extraction method 
uses the functions $[.]_{term}$, $[.]_{type}$ and $[.]_{stat}$ that have been defined in the previous section. In addition, the injective function $[.]_{tactic}$ has been  
introduced to assign values to tactics.

To be more concrete, we have defined two versions of the function $[.]_{tactic}$: one for Coq tactics and another one for SSReflect tactics. 
% -- although SSReflect is an extension of Coq, this package implements a set of proof tactics designed to support the extensive
% use of small-scale reflection in formal proofs~\cite{SSReflect}. 
In the SSReflect case, we divide the tactics into 7 groups and assign similar
values to each tactic in the group, see Table~\ref{tab:tactics}. If several tactics are concatenated using ``\lstinline?;?'', the value returned by
$[.]_{tactic}$ is the concatenation of the values of the individual tactics. Analogously for Coq tactics, cf. Appendix~\ref{}.

\begin{figure}[t]
\centering
\begin{lstlisting}[frame=lines,mathescape,basicstyle=\tiny,breaklines=true]  
$\ast$ Bookkeeping ($b=\{$move:, move => $\}$): $[b_i]_{tactic}=1+\sum_{j=1}^i \frac{1}{10\times 2^{j-1}}$ (where $b_i$ is the $i$th element of $b$).
$\ast$ Case and Induction ($c=\{$case, elim$\}$): $[c_i]_{tactic}=2+\sum_{j=1}^i \frac{1}{10\times 2^{j-1}}$.
$\ast$ Discharge ($d=\{$apply, exact, congr$\}$): $[d_i]_{tactic}=3+\sum_{j=1}^i \frac{1}{10\times 2^{j-1}}$.
$\ast$ Simplification ($s=\{$//, /=, //=$\}$): $[s_i]_{tactic}=4+\sum_{j=1}^i \frac{1}{10\times 2^{j-1}}$.
$\ast$ Rewrite: $[$rewrite$]_{tactic} = 5$. 
$\ast$ Forward Chaining  ($f=\{$have, suff, wlog$\}$): $[f_i]_{tactic}=6+\sum_{j=1}^i \frac{1}{10\times 2^{j-1}}$.
$\ast$ Views and reflection  ($v=\{$move/, apply/, elim/, case/$\}$): $[v_i]_{tactic}=7+\sum_{j=1}^i \frac{1}{10\times 2^{j-1}}$.
\end{lstlisting}
\caption{\emph{Formulas to compute the value of SSReflect tactics.} 
The above formulas serve to assign closer values to the tactics within each of the seven above groups, and more distant numbers 
across the groups -- thus distinguishing the groups unambiguously. If a new tactic is defined, ML4PG automatically assigns it a 
consecutive natural number starting from $8$.}\label{tab:tactics}
\end{figure}




\begin{definition}[Proof-patch matrix]\label{def:ptm}
Given a Coq proof $C=((G_i,T_i))_{i}$, and a proof patch $P=((G_{i_0},T_{i_0}),\ldots,(G_{i_4},T_{i_4}))$ of $C$, 
the \emph{proof-patch matrix} $M_P$ is a $5\times 6$ matrix that satisfies the following conditions:

\begin{itemize}
 \item the $(j,0)$-th entry of $M_P$ is $[T_{i_j}]_{tactic}$,
 \item the $(j,1)$-th entry of $M_P$ is the number of tactics appearing in $T_{i_j}$,
 \item the $(j,2)$-th entry of $M_P$ is  $[t_{i_j}]_{type}$ where $t_{i_j}$ is the set of the argument-types
 of $T_{i_j}$ --- if $t_{i_j}$ is a singleton $t$,  $[t_{i_j}]_{type}=[t]_{type}$; otherwise, the value of $[t_{i_j}]_{type}$ is 
 given by the concatenation of values of the elements of the set $t_{i_j}$,
 \item the $(j,3)$-th entry of $M_P$ is a 4-tuple  $([l_{i_{j_1}}]_{stat},[l_{i_{j_2}}]_{stat},[l_{i_{j_3}}]_{stat},[l_{i_j}]_{stat})$
 where $l_{i_{j_1}}$, $l_{i_{j_2}}$ and $l_{i_{j_3}}$ are the three first lemmas applied in $T_{i_j}$ and $l_{i_j}$ is the list of the rest of lemmas 
used in $T_{i_j}$,
 \item the $(j,4)$-th entry of $M_P$ is a triple  $([s_1]_{term},[s_2]_{term},[s_3]_{term})$ where $s_1,s_2$ and $s_3$ are respectively the top, second, and third
 symbol of $G_{i_j}$,
 \item the $(j,5)$-th entry of $M_P$ is the number of subgoals after applying $T_{i_j}$ to $G_{i_j}$.
\end{itemize} 
\end{definition}



\begin{example}\label{example1}
Given the proof of Example~\ref{example0} and the proof-patch $((G_{i},T_{i}))_{0\leq i \leq 4}$, 
the top table of Table~\ref{tab:patches} shows its proof-patch matrix.




 \begin{table}
\centering
\tiny{
\begin{tabular}{|l||l|l|l|l|l|l|}
\hline
 & \emph{tactics} & \emph{n tactics} & \emph{arg type} & \emph{arg} & \emph{symbols} & \emph{subgoals} \\
\hline
\hline
\emph{g1}& $[case]_{tactic}$ & $1$  & $[nat]_{type}$  & $([Hyp]_{stat},0,0,0)$ & $([\forall]_{term},[=]_{stat},[sum]_{stat})$ & $2$ \\
 \hline
  \emph{g2} & $[rewrite]_{tactic}$ & $1$  & $[Prop]_{type}$  & $([big\_nat1]_{stat},0,0,0)$ & $([=]_{term},[\sum]_{stat},[-]_{stat})$& $0$ \\
 \hline
  \emph{g3} & $[rewrite]_{tactic}$ & $1$  & $[Prop]_{type}$ & $([surB]_{stat},$  & $([=]_{term},[+]_{stat},[-]_{stat})$& $1$ \\
 & & & & $[big\_nat\_recr]_{stat}$ & & \\
 & & & & $[big\_nat\_recl]_{stat}$ & & \\
 & & & & $[EL]_{stat})$ & & \\
 \hline
   \emph{g4} & $[move:]_{tactic}$ & $1$  & $[Prop]_{type}$ &  $([eq\_refl]_{stat},0,0,0)$  & $([=]_{term},[+]_{stat},[-]_{stat})$ & $1$ \\
 \hline 
  \emph{g5} & $[rewrite]_{tactic}$ & $1$  & $[Prop]_{type}$  & $([subr\_eq0]_{stat},0,0,0)$ & $([=]_{term},[+]_{stat},[-]_{stat})$ & $1$ \\
 \hline
  \end{tabular}
  
  \vspace{.2cm}
  
\begin{tabular}{|l||l|l|l|l|l|l|}
\hline
 & \emph{tactics} & \emph{n tactics} & \emph{arg type} & \emph{arg} & \emph{symbols} &  \emph{subgoals} \\
\hline
\hline
\emph{g1} & $[move/;\texttt{->}]_{tactic}$ & $2$  & $[Prop]_{type}$  & $([eqP]_{stat},0,0,0)$ & $([=]_{term},[+]_{stat},[-]_{stat})$ & $1$ \\
 \hline
  \emph{g2} & $[rewrite]_{tactic}$ & $1$  & $[Prop]_{type}$  & $([sub0r]_{stat},0,0,0)$ & $([=]_{term},[+]_{stat},[-]_{stat})$ & $0$ \\
 \hline
  \emph{g3} & - & -  & - & -  & - & -  \\
 \hline
  \emph{g4} & - & -  & - & -  & - & -  \\
 \hline 
  \emph{g5} & - & -  & - & -  & - & - \\
 \hline
  \end{tabular}
  
  \vspace{.2cm}
  
\begin{tabular}{|l||l|l|l|l|l|l|}
\hline
 & \emph{tactics} & \emph{n tactics} & \emph{arg type} & \emph{arg} & \emph{symbols} & \emph{subgoals} \\
\hline
\hline
\emph{g1}&  $[rewrite]_{tactic}$ & $1$  & $[Prop]_{type}$ & $([surB]_{stat},$  & $([=]_{term},[+]_{stat},[-]_{stat})$& $1$ \\
 & & & & $[big\_nat\_recr]_{stat}$ & & \\
 & & & & $[big\_nat\_recl]_{stat}$ & & \\
 & & & & $[EL]_{stat})$ & & \\
 \hline
  \emph{g2} & $[move:]_{tactic}$ & $1$  & $[Prop]_{type}$ &  $([eq\_refl]_{stat},0,0,0)$  & $([=]_{term},[+]_{stat},[-]_{stat})$ & $1$ \\
 \hline
  \emph{g3} & $[rewrite]_{tactic}$ & $1$  & $[Prop]_{type}$  & $([subr\_eq0]_{stat},0,0,0)$ & $([=]_{term},[+]_{stat},[-]_{stat})$ & $1$ \\
 \hline
\emph{g4}& $[move/;\texttt{->}]_{tactic}$ & $2$  & $[Prop]_{type}$  & $([eqP]_{stat},0,0,0)$ & $([=]_{term},[+]_{stat},[-]_{stat})$ & $1$ \\
 \hline
  \emph{g5} & $[rewrite]_{tactic}$ & $1$  & $[Prop]_{type}$  & $([sub0r]_{stat},0,0,0)$ & $([=]_{term},[+]_{stat},[-]_{stat})$ & $0$ \\
 \hline
  \end{tabular}  
  }

 \caption{\emph{Proof-patch matrices for the proof of Example~\ref{example1}.} \textbf{Top.} Proof-patch matrix of the patch $((G_0,T_0),\ldots,(G_4,T_4))$. 
 \textbf{Centre.} Proof-patch matrix of the patch $((G_5,T_5),(G_6,T_6))$.  \textbf{Bottom.} Proof-patch matrix of the patch $((G_2,T_2),\ldots,(G_6,T_6))$.  
Where we use notation $EL$, ML4PG gathers the lemma names: (\lstinline?addrC?, \lstinline?addrC?~, \lstinline?subr_sub?, \ldots).}\label{tab:patches}
 \end{table}

\end{example}


The \emph{proof-patch method} considers several proof-patches to collect information of a concrete proof. 
In particular, given a Coq proof $C=((G_i,T_i))_{0\leq i\leq m}$ , the proof $C$ can be split into patches $C_0,\ldots,C_n$ where 
$n=\lceil\frac{m}{5}\rceil+1$. The patches are defined as follows: $C_j=((G_j,T_j),\ldots,(G_{j+4},T_{j+4}))$ 
for $0\leq j < n$ (some patches can contain less than $5$ proof-steps); and $C_n=((G_{m-4},T_{m-4}),\ldots,(G_{m},T_{m}))$ -- the last patch captures 
the last five proof-steps.


\begin{example}
Using the proof-patch method, we  can split the proof presented in Example~\ref{example1} into three proof-patches $((G_i,T_i))_{0\leq i \leq 4}$, 
$((G_5,T_5),(G_6,T_6))$ and $((G_i,T_i))_{2\leq i \leq 6}$; the corresponding proof-patch matrices are given in Table~\ref{tab:patches}. 

\end{example}

The proof-patch method together with the functions $[.]_{term},[.]_{type},[.]_{tactic}$ and $[.]_{stat}$ solve the two drawbacks of the method
presented in~\cite{KHG13}: the new method captures information about the whole proof and the feature values are dynamically computed to assign close
values to similar terms, types, tactics and lemma statements. 

We finish this section with a case study that illustrates 
the use of the proof-patch method and shows the differences with the results obtained using 
the method presented in~\cite{KHG13}. This case study concerns discovery of proof patterns in mathematical proofs
across formalisations of apparently disjoint mathematical theories: Linear Algebra, Combinatorics and Persistent Homology.
In this scenario, we use statistically discovered proof patterns to advance the proof of a given ``problematic'' lemma. 
In this case,  a few initial steps in its proof are clustered against several mathematical libraries. 
We deliberately take lemmas belonging to very different SSReflect libraries. The lemma introduced in Example~\ref{example0} is a basic fact about
summations. Lemma~\ref{lem:nilpotent} states a result about \emph{nilpotent} matrices~\cite{BR91} (a square matrix $M$ is \emph{nilpotent}
if there exists an $n$ such that $M^n=0$). Finally, Lemma~\ref{lem:fundamental} is a generalisation of the \emph{fundamental lemma of 
Persistent Homology}~\cite{HCMS12}.


\begin{lemma}\label{lem:nilpotent}
 Let $M$ be a square matrix and $n$ be a natural number such that $M^n=0$, then $(1-M)\times \sum\limits_{i=0}^{n-1} M^i = 1$.
\end{lemma}


\begin{lemma}\label{lem:fundamental}
Let $\beta_n^{k,l}:\mathbb{N} \times \mathbb{N} \times \mathbb{N} \rightarrow \mathbb{Z}$, then
$$\beta_n^{k,l} - \beta_n^{k,m}= \sum_{0\leq i \leq k} \sum_{l<j\leq m} (\beta_n^{i,j-1} - \beta_n^{i,j}) - (\beta_n^{i-1,j-1} - \beta_n^{i-1,j}).$$
\end{lemma}



When proving Lemma~\ref{lem:nilpotent}, a user can get stuck after a few standard proof steps: apply induction and solve the base case using rewriting.
At this point it is difficult, even for an expert user, % 60 B?
to get the intuition that he can reuse the proofs from Example~\ref{example0} and Lemma~\ref{lem:fundamental}. There are several reasons for this.
First of all, the formal proofs of these lemmas are in different libraries; then, it is difficult to establish a conceptual connection among them. Moreover,
although the three lemmas involve summations,
the types of the terms of those summations are different. Therefore, search based on types or keywords would not help. Even search  % *a* search removed -- because 59B??? 
of all the lemmas involving summations does not provide a clear suggestion, since there are more than $250$ lemmas -- a considerable number for handling them manually.

% \begin{table}
%  	\centering
%  	\tiny{
%  		\begin{tabular}{|l|l|}
%  		\hline
%  	Goals and Subgoals & Proof-Steps (Tactics) \\
%  		\hline
%  		\hline
%  	{\scriptsize $\forall~(M:M_n) (m:nat), M^m=0 \implies (1-M)\times \sum\limits_{i=0}^{m-1} M^i = 1$} & \\
%  			& {\scriptsize \lstinline?move => M m nilpotent.?} \\
%          {\scriptsize $(1-M)\times \sum\limits_{i=0}^{m-1} M^i = 1$} & \\
%         &   {\scriptsize\lstinline?rewrite big_distrr mulmxBr mul1mx.?}\\
%         {\scriptsize$   \sum\limits_{i=0}^{m-1} M^i - M^{i+1}$} &\\
%         
%         & {\scriptsize\lstinline?case : n.?}\\
%         {\scriptsize $ \forall~(M:M_0) (m:nat),M^m=0 \implies \sum\limits_{i=0}^{m-1} M^i - M^{i+1} $ }&\\
%         &  {\scriptsize\lstinline?by rewrite !thinmx0.?}\\
%          {\scriptsize$ \forall~(M:M_{n+1}) (m:nat), M^m=0 \implies \sum\limits_{i=0}^{m-1} M^i - M^{i+1} $}&\\
%  		\hline
%  		\end{tabular}
%  		
%  		}
%  	\caption{\textbf{First steps of the proof of Lemma~\ref{lem:nilpotent},} \emph{where the user stops and invokes ML4PG for a hint.}}
%  	\label{tab:sumfirstn}
%  \end{table}




However, if the lemma from Example~\ref{example0} and Lemma~\ref{lem:fundamental} are suggested when proving Lemma~\ref{lem:nilpotent}, the expert would be able to
spot the following common proof pattern.

%\begin{IP}\label{ip:math}
%This proof pattern is followed by Lemmas~\ref{lem:nilpotent},~\ref{lem:fundamental} and~\ref{lem:lemma3}.
 
\begin{PS}\label{ps:math}
 
\emph{
%\begin{enumerate}
  %\item 
	Apply case on $n$.
  \begin{enumerate}
   \item Prove the base case (a simple task).
   \item Prove the case $0<n$:
     \begin{enumerate}
     \item expand the summation,
     \item cancel the terms pairwise,
     \item the terms remaining after the cancellation are the first and the last one. 
     \end{enumerate}
  \end{enumerate}
% \end{enumerate}
}
 
 
\end{PS}




% \begin{table}
%  	\centering
%  	\footnotesize{
%  		\begin{tabular}{|l|l|}
%  		\hline
%  	Goals and Subgoals & Proof-Steps (Tactics) \\
%  		\hline
%  		\hline
%  	{\scriptsize $\forall~(M:M_n) (m:nat), M^m=0 \implies \exists N, N \times (1-M)= 1$} & \\
%  			& {\scriptsize \lstinline?move => M m nilpotent.?} \\
%          {\scriptsize $\exists N, N \times (1-M)= 1$} & \\
%         &   {\scriptsize\lstinline?exists?}\\
%         &   {\scriptsize~~\lstinline?\sum_(0<=i<m.+1) (pot_matrix M i).?}\\
%         {\scriptsize$   (\sum\limits_{i=0}^{m-1} M^i) \times (1 - M) $} &\\
%         
%         & {\scriptsize\lstinline?rewrite big_distrl mulmxrB mulmx1.?}\\
%         {\scriptsize $ \sum\limits_{i=0}^{m-1} M^i - M^{i+1} $ }&\\
%                 & {\scriptsize\lstinline?case : n.?}\\
%         {\scriptsize $ \forall~(M:M_0) (m:nat),M^m=0 \implies \sum\limits_{i=0}^{m-1} M^i - M^{i+1} $ }&\\
%         &  {\scriptsize\lstinline?by rewrite !thinmx0.?}\\
%          {\scriptsize$ \forall~(M:M_{n+1}) (m:nat), M^m=0 \implies \sum\limits_{i=0}^{m-1} M^i - M^{i+1} $}&\\
%  		\hline
%  		\end{tabular}
%  		
%  		}
%  	\caption{\textbf{First steps of the proof of Lemma~\ref{lem:nilpotent2}.} \emph{Note the correlation between this proof and the proof of Lemma~\ref{lem:nilpotent} in Table~\ref{tab:sumfirstn}.}}
%  	\label{tab:nilpotent2}
%  \end{table}



Using the method presented in~\cite{KHG13}, if ML4PG is invoked during the proof of Lemma~\ref{lem:nilpotent}, it suggests the lemma from Example~\ref{example0} and 
Lemma~\ref{lem:fundamental} (across 758 lemmas and 5~libraries). However, 5 irrelevant lemmas -- irrelevant meaning that they do not follow Proof Strategy~\ref{ps:math}
-- about summations are also suggested. The cluster containing just the two desired lemmas is obtained after
increasing the \emph{granularity} value~\cite{KHG13} -- an ML4PG parameter that can be adjusted by the user to obtain more precise clusters.

 
There are two enhancements when we use the proof-patch method instead of the method presented in~\cite{KHG13}: (1) the number of suggestions is increased and (2) 
the clusters are more accurate. 

The proof-patch method considers fragments of proofs that were not studied before; therefore, it can find lemmas (more precisely patches of lemmas) that were not
included in the clusters previously. In our case study, two new interesting lemmas are suggested. The first one is a intermediate patch of the proof of 
Lemma~\ref{lem:fundamental}; then, two patches are suggested from this 
lemma: the proof-patch of the inner sum, and the proof-patch of the outer sum (both of them following Proof Strategy~\ref{ps:math}). The following lemma is also 
suggested.

\begin{lemma}\label{lem:nilpotent2}
Let $M$ be a nilpotent matrix, then there exists a matrix $N$ such that $N \times (1-M)=1$. 
\end{lemma}

At the first sight, the proof of this lemma is an unlikely candidate to follow  Proof Strategy~\ref{ps:math}, since the statement of the lemma
does not involve summations. However, inspecting its proof, we can see that it uses $\sum_{i=0}^{n-1} M^i$ as witness for $N$ and 
then follows Proof Strategy~\ref{ps:math}. In this case, ML4PG suggests the patch from the last five proof-steps that correspond to 
the application of Proof Strategy~\ref{ps:math}. 


The proof-patch method increases the number of suggestions; this could be a problem if more irrelevant lemmas were suggested. However, 
the new numbering of features produces more accurate clusters removing the irrelevant lemmas. In particular, using the default settings, 
ML4PG only suggests the lemma from Example~\ref{example0}, the two patches from Lemma~\ref{lem:fundamental} and the last patch from 
Lemma~\ref{lem:nilpotent2}. If the granularity is increased, the only suggestion is given by the last patch from 
Lemma~\ref{lem:nilpotent2} -- i.e. the closest lemma involving types, terms and lemmas involved in the proof. 

The discovery of proof-patterns can be a challenging task, but increasing the number and precision of suggestions simplifies this problem. 
With the same goal (facilitate the discovery of proof-pattens), we introduce a graphical representation in the next section.




















% the four lemmas given above follow the Strategy \ref{ps:math} is our next benchmarking task for ML4PG.
% Table~\ref{tab:compare0} shows the results that ML4PG will obtain, if the user varies the clustering algorithms and the size of clusters when 
% calling ML4PG within the proof environment; we also highlight the exact solution to our benchmark task, given by calling K-means algorithm with granularity $4$. 
 
% \begin{table}
% \centering
% {\scriptsize 
%    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
%      \hline
%     & $g=1$& $g=2$& $g=3$& $g=4$ & $g=5$\\
%       Algorithm: & ($n=84$) & ($n=94$) & ($n=108$) & ($n=126$) & ($n=151$)\\     \hline
%      K-means &76$^{a-d}$ &51$^{a-d}$  &16$^{a-d}$ &\textbf{4}$^{a-d}$&2$^{b,d}$  \\
%      \hline
%      E.M. &26$^{a-d}$  &51$^{a,b,d}$ &41$^{a,b,d}$  &11$^{b,c,d}$ &3$^{a,b,d}$ \\
%      \hline
%      FarthestFirst &81$^{a-d}$ &48$^{a-d}$ &31$^{a-d}$  &25$^{a-d}$  &21$^{a-d}$  \\
%      \hline
%     \end{tabular}      }
%           
%    \caption{\textbf{Clustering experiments discovering Proof Strategy~\ref{ps:math}.} \emph{When  $g$ is chosen by the user, 
%    ML4PG dynamically calculates the number of clusters $n$. Choosing Lemma~\ref{lem:nilpotent} for pattern-search,  
%   the table shows the size of the single cluster that ML4PG displays to the user for every choice of $g$.
%    The table shows sizes of clusters containing: $a)$ Lemma~\ref{lem:nilpotent}, $b)$ Lemma~\ref{lem:lemma3},  $c)$ Lemma~\ref{lem:fundamental} and
%    $d)$ Lemma~\ref{lem:nilpotent2}. Note that with all variations of the learning algorithms and parameters, ML4PG is consistently grouping the
% correct lemmas into clusters, albeit with varied degree of precision. Note also the effect of the granularity parameter, the smallest granularity value $g=1$ produces big 
% clusters that are difficult to inspect; on the contrary, the biggest value $g=5$ produces small clusters that might not contain enough elements to spot a pattern. 
% The most accurate result for this example is obtained using the K-means algorithm and 4 as granularity parameter.}}\label{tab:compare0}
%   \end{table}
%  
% 
% Table~\ref{tab:compare0} gives an insight on how granularity parameter $g$ can be used in pattern-recognition within ML4PG.
%  One can use a ``bottom-up approach'' to detect patterns starting with the granularity value of 1 and increasing that value in successive calls.
% Using the default values $g=3$ and K-means algorithm, ML4PG obtains 15 suggestions related to lemmas about summations including Lemmas~\ref{lem:lemma3} 
% and~\ref{lem:fundamental}. Increasing the granularity level to 4, ML4PG discovers that Lemma  \ref{lem:nilpotent} is similar to 
% Lemmas~\ref{lem:lemma3}, \ref{lem:fundamental} and \ref{lem:nilpotent2}. Finally, increasing the granularity level to the maximum level of $5$, 
% ML4PG just discovers that Lemmas \ref{lem:nilpotent} and  \ref{lem:nilpotent2} are similar. %and also the following lemma; 


% When the proof analogy is found (as all four proof patches taken by ML4PG follow steps $1$ and $2(a)$ of Proof Strategy \ref{ps:math}), the user can use the remaining proof steps for Lemma~\ref{lem:nilpotent2} as a template for reconstructing the remaining proof for Lemma~\ref{lem:nilpotent} (by analogy with the steps $2(b)$ and $2(c)$ in Lemma~\ref{lem:nilpotent2}). % in case of the four lemmas mentioned here, the remaining steps all follow the Strategy \ref{ps:math}. Thus, ML4PG finds patterns arising from 
% The heterogeneous cluster obtained in this scenario belongs to the category of clusters consisting of theorems that share the same proof structure and as well as an 
% auxiliary lemma (e.g. the lemma used to expand the summation). 



