\section{Future Work}
\label{sec:future}

Our use of clustering to pre-process \qspec{} signatures has required many decisions and tradeoffs to be made. Hence our approach is just one possibility out of many alternatives which could be investigated to push this work further. In addition, there are other ways in which machine learning could aid theory exploration besides our relevance filter technique. The Gantt chart in Figure \ref{fig:gantt} shows how these relate to the short- and long-term direction being taken by this research. Below, we elaborate on the details, background and motivation for these choices.

\subsection{Clustering Extensions}
\label{sec:preprocessing}

The most glaring omission in our algorithm is its disregard for types. By ignoring types, not only are we losing valuable information about expressions, but we also lose the ability to distinguish between constructors. This is because a constructor, like \hs{True} or \hs{Just}, has no internal structure; it is just a token. The distinguishing features of constructors are their types, which not only tell us which data type they construct, but also their arity, the types of their arguments, etc.

Our algorithm closely follows that of ML4PG, which \emph{does} support types. This is handled by populating matrix cells with tokens \emph{and} their types. Unfortunately this is more complicated in Haskell than it is in Coq, since types form a separate part of the language from terms, and we do not have an interactive Core environment to query for types (unlike ML4PG, which runs inside the Proof General environment).

One partial solution would be leave most Core expressions without types, but to include them for non-local identifiers (i.e. globals and constructors), which we can look up in a database. In fact, our ML4HS framework already includes such type information in its database, alongside the Core syntax trees. Integrating this information into our algorithm is the next logical step.

We can also compare the performance of our hand-selected features with \emph{learned} representations, like those reviewed in \citep{bengio2013representation}. This may provide an indication of how important it is to understand the language when identifying salient aspects of expressions, and how difficult various aspects of it might be to learn.

With more expressive features, it may also be useful to experiment with more powerful learning algorithms. An interesting possibility is to add a feedback loop between the theory exploration phase and the clustering phase, to more directly base the similarity of expressions on whether they (are predicted to) occur together in equations.

\subsection{Theory Exploration Extensions}

Our current approach is a rather conservative change to the existing theory exploration approaches, as it is essentially a wrapper around \qspec{}. There is potential for more radical changes to be made, which alter the search process itself.

\subsubsection{Variable Instantiation}

\qcheck{} is certainly the most popular property checker for Haskell, which motivates its use in \qspec{} to instantiate variables to random values. However, this task of finding type inhabitants has also been solved in many other ways, which may be worth investigating in place of \qcheck{} (or perhaps even as part of an ensemble).

The \textsc{SmallCheck} system \citep{runciman2008smallcheck} \emph{enumerates} values rather than sampling them randomly. Whilst this does not make \textsc{SmallCheck} objectively ``better'' than \qcheck{}, one major advantage is that it may use much less memory, as the generated values are built up incrementally. In contrast, \qcheck{} may generate very large values; in particular, generating tree structures na\"{\i}vely can cause them to grow exponentially. For example, here is a potential generator for \hs{RoseTree}s:

\begin{lstlisting}[language=Haskell, xleftmargin=0.1\textwidth, xrightmargin=0.1\textwidth]
genRoseTree = do f        <- arbitrary
                 subtrees <- listOf genRoseTree
                 return (Node f subtrees)
\end{lstlisting}

The \hs{listOf genRoseTree} call will return a list of arbitrary length, where each element is generated by \hs{genRoseTree}. This allows an arbitrary number of recursive calls to be made for each invocation of \hs{genRoseTree}, which will quickly exhaust the resources of any machine. Whilst such problems may be anticipated, or quickly spotted, in a property checking setting, this can be more difficult for our automated approach. For example, if a type does not have a generator available, we cannot use a library like \hs{derive} to create one automatically, as it suffers from this na\"{\i}vity problem.

A relative of \textsc{SmallCheck} is \textsc{Lazy SmallCheck} \citep{reich2013advances}, which uses laziness to only produce parts of a datastructure as they are demanded. This may narrow down our search procedures greatly, especially when predicates are involved. \qcheck{} allows predicates to restrict the values it tests with, and hence allows \emph{conditional} equations to be discovered. However, its implementation uses a simple rejection sampling technique: values are generated just as if the predicate were not there, and afterwards are filtered to reject any which do not satisfy the predicate. This makes it difficult to use very specific predicates, as it is unlikely that many of our random samples will exactly match our criteria. On the other hand, \textsc{Lazy SmallCheck} will focus its search on exactly those parts of the datastructure which are checked by the predicate, as those are the parts being forced to evaluate. This makes it much more likely that we will find values which satisfy the predicate, allowing us to effectively explore more specific conditional properties.

Other approaches to generating inhabitants include \textsc{Djinn} \citep{augustsson2005djinn}, which uses a decision procedure for a sub-set of Haskell types which in particular can generate and apply functions (unlike the above tools, which generate values ``bottom-up'' from constructors, and only use functions when they have been explicitly written in a generator). \textsc{MuCheck} \citep{le2014mucheck} is designed for \emph{mutation testing}, and contains combinators for altering functions in common ways (e.g. changing the order of pattern match clauses); whilst not as exhaustive as the other approaches, mutating existing values in this way is claimed to yield values which correspond more closely to what a programmer might write. This is an interesting possibility for focusing theory exploration on to more ``realistic'' areas of the search space, and hence avoiding some of the more useless or bizarre expressions that random search and enumeration may produce.

In fact, the database generated by our \textsc{AstPlugin} may prove helpful in generating values, since its type information can be fed to a tool like \textsc{Djinn} to discover chains of function applications for building values, which would be particularly useful in cases where constructors are private, like in our email example. This is similar to the \textsc{Hoogle} tool, but also offers the ability to use dependency information to avoid potentially infinite recursion.

The Core syntax trees in our database could also be used to generate theories for automated theorem provers. \hspec{} currently uses the GHC API to transform Core within its own process, however that approach suffers from the problems described in \S \ref{sec:astplugin}.

\subsubsection{Interestingness}
\label{sec:interestingness}

If we do succeed in producing a fast theory exploration system, which chooses productive combinations of terms and finds a large number of properties, we encounter the problem of managing the output: finding the needles we are interested in among the haystack of trivialities and coincidences.

This is governed by the ``interestingness'' criteria of the theory exploration system: what to keep and what to discard, and even what areas of the search space to prioritise. \qspec{}'s approach, briefly mentioned in \S \ref{sec:theoryexploration}, is very simple: we discard equations which are direct consequences of others, and keep all the rest. Different, and more sophisticated notions of interestingness have been widely studied in other fields, which may be applied in the context of theory exploration.
