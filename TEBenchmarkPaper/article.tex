% Derived from the template file for the LaTeX package SVJour3
% for Springer journals.          Springer Heidelberg 2010/09/16
%
% This template includes a few options for different layouts and
% content for various journals. Please consult a previous issue of
% your journal as needed.
%
% First comes an example EPS file -- just ignore it and
% proceed on the \documentclass line
% your LaTeX will extract the file if required
\begin{filecontents*}{example.eps}
%!PS-Adobe-3.0 EPSF-3.0
%%BoundingBox: 19 19 221 221
%%CreationDate: Mon Sep 29 1997
%%Creator: programmed by hand (JK)
%%EndComments
gsave
newpath
  20 20 moveto
  20 220 lineto
  220 220 lineto
  220 20 lineto
closepath
2 setlinewidth
gsave
  .4 setgray fill
grestore
stroke
grestore
\end{filecontents*}
%
\RequirePackage{fix-cm}
%
%\documentclass{svjour3}                     % onecolumn (standard format)
%\documentclass[smallcondensed]{svjour3}     % onecolumn (ditto)
\documentclass[smallextended]{svjour3}       % onecolumn (second format)
%\documentclass[twocolumn]{svjour3}          % twocolumn
%
\smartqed  % flush right qed marks, e.g. at end of proof
%
\usepackage{graphicx}
%
% \usepackage{mathptmx}      % use Times fonts if available on your TeX system
%
% insert here the call for the packages your document requires
%\usepackage{latexsym}
% etc.

\usepackage{attrib}
\usepackage{csquotes}

\usepackage{graphicx}
\graphicspath{ {support/} }

% please place your own definitions here and don't use \def but
% \newcommand{}{}
%
% Insert the name of "your journal" with
% \journalname{myjournal}
%
\begin{document}

\title{Quantitative Benchmarking for Theory Exploration%\thanks{Grants or other notes
%about the article that should go on the front page should be
%placed here. General acknowledgments should be placed at the end of the article.}
}
% \subtitle{Do you have a subtitle?\\ If so, write it here}

% \titlerunning{Short form of title}        % if too long for running head

\author{Chris Warburton% \and
                %Second Author % etc
}

% \authorrunning{Short form of author list} % if too long for running head

\institute{C. Warburton \at
              University of Dundee \\
              \email{cmwarburton@dundee.ac.uk}           %  \\
%             \emph{Present address:} of F. Author  %  if needed
           %\and
           %S. Author \at
           %   second address
}

\date{Received: date / Accepted: date}
% The correct dates will be entered by the editor


\maketitle

\begin{abstract}
Insert your abstract here. Include keywords, PACS and mathematical
subject classification numbers as needed.
\keywords{First keyword \and Second keyword \and More}
% \PACS{PACS code1 \and PACS code2 \and more}
% \subclass{MSC code1 \and MSC code2 \and more}
\end{abstract}

\section{Introduction}
\label{intro}
The field of mathematics has been transformed by the introduction of computers:
calculations are now routinely automated, allowing humans to focus their efforts
on higher-level, more creative activities like proving theorems; \emph{automated
theorem proving} (ATP) seeks to automate this process too, and was one of the
first tasks studied in the field of artificial intelligence
\cite{newell1956logic,sutcliffe2001evaluating}. Despite this effort, ATP
methods are not widely used by traditional mathematicians, although they have
seen use in applied areas such as hardware and software verification
\cite{Moore:2003}.

Even if ATP became widespread, the automation of theorem proving would still
leave an important aspect of mathematics inaccessible to computers: conjecturing
those theorems (and the definitions they involve) in the first place. Automated
methods for posing good conjectures have obvious applications for those who must
invent a constant stream of novel questions, e.g. for examinations or research.
A larger impact may be found in areas such as computer programming, security and
verification, where the benefits of formal methods are hindered by the
difficulty of their application; tools to aid this process, e.g. by proposing
test cases, can reduce this cost.

Many automated systems and algorithms have been developed to generate
conjectures, but it is difficult to judge or compare their performance in a
quantitative way. There are many aspects to consider when judging the quality of
a conjecture: how likely it is to be true, how difficult it is to prove, its
implications, and so on.

One way to make these subjective, ambiguous properties more concrete is to
choose a well-studied theory, with a set of existing theorems that are deemed to
be useful or important in some way, and treat these as a \emph{ground truth}
against which we can compare conjectures generated from the same theory.

A common choice of ground truth is the standard library of a theorem prover,
such as Isabelle/HOL; the library authors have gone to the effort of stating,
proving and including these theorems in every copy of their software, which is a
good indication that they are useful or important.

One problem with this approach is the small size of these libraries. For
example, a benchmark based on Isabelle/HOL's theory of natural numbers contains
only FIXME definitions and FIXME theorems. Whilst such benchmarks allow
comparison between different approaches, their narrow scope doesn't provide much
indication of performance in different, especially \emph{novel}, domains.

We propose that the extensive test suites which are already used to benchmark
automated theorem provers can be repurposed to create benchmarks for conjecture
generation systems. We provide a benchmark suite, automatically derived from the
Tons of Inductive Problems (TIP) benchmark suite, as well as software to convert
other benchmarks written in the same TIP format (an extension of the SMT-LIB
format \cite{BarFT-SMTLIB}).

\section{Existing Evaluations}
\label{sec:previous}

Theory exploration tools such as
IsaCoSy~\cite{Johansson.Dixon.Bundy:conjecture-generation}, QuickSpec and
IsaScheme have been evaluated using the standard library of the Isabelle theorem
prover as their ground truth.

ALGORITHM:

Concatenate all definitions from all files together.
For each definition, prefix its name with the filename it came from and update all references.
Normalise all local variable names.
Remove any identical definitions, leaving the first one in place and updating any references to the removed definitions to use this one.
Repeat, until no further removals are possible.

\section{Evaluation}
\label{sec:evaluation}

%\includegraphics{bucketing-graph}

\begin{acknowledgements}
We are grateful for Jianguo Zhang
\end{acknowledgements}

\bibliographystyle{plain}
\bibliography{./Bibtex}

\end{document}
