% Based on the LLNCS.DEM demonstration file of
% the LaTeX macro package from Springer-Verlag
% for Lecture Notes in Computer Science,
% version 2.4 for LaTeX2e as of 16. April 2010
%
\documentclass{llncs}
%
\usepackage{makeidx}  % allows for indexgeneration
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{enumitem}
%
\begin{document}
%
\pagestyle{headings}  % switches on printing of running heads

\mainmatter              % start of the contributions
%
\title{Scaling Automated Theory Exploration}
%
\author{Chris Warburton \and Ekaterina Komendantskaya}
%
\institute{University of Dundee,\\
\texttt{http://tocai.computing.dundee.ac.uk}}

\maketitle              % typeset the title of the contribution

\begin{abstract}
We investigate the \textbf{theory exploration} (TE)
paradigm for computer-assisted Mathematics and identify limitations and
improvements for current approaches. Unlike the theorem-proving paradigm,
which requires user-provided conjectures, TE performs an open-ended
search for theorems satisfying given criteria. We see promise in TE for
identifying new abstractions and connections in libraries of software
and proofs, but realising this potential requires more scalable
algorithms than presently used.
\end{abstract}
%
\section{Introduction}

Given a signature $\Sigma$ and a set of variables $V$, we call the pair
$(\Sigma, V)$ a \emph{theory} and use \emph{theory exploration} (TE) to refer
to any process $(\Sigma, V) \overset{TE}{\rightarrow} \text{Terms}(\Sigma, V)$
for producing terms of the theory which are well-formed, provable and satisfy
some criterion referred to as ``interesting''. These conditions give rise to the
following questions, which we use to characterise TE systems:
\begin{description}
\item [Q1] \label{Q1} How do we generate terms?
\item [Q2] \label{Q2} How do we guarantee well-formedness?
\item [Q3] \label{Q3} How do we prove terms?
\item [Q4] \label{Q4} What is considered ``interesting''?
\end{description}

Early implementations like \textsc{Theorema} \cite{buchberger2000theory}
provided interactive environments, similar to computer algebra systems and
interactive theorem provers, to assist the user in finding theorems. In this
setting, terms are formed by the user in whichever way they find interesting,
whilst the software provides support for \textbf{Q2} and \textbf{Q3}.

Subsequent systems have investigated \emph{automated} theory exploration, for
tasks such as lemma discovery \cite{Hipster}. By removing user interaction,
\textbf{Q1} and \textbf{Q4} must be solved by algorithms. In existing
systems these are tightly coupled to improve efficiency, which makes it
difficult to try different approaches independently.

As an example, \textsc{QuickSpec} \cite{QuickSpec} discovers equations about
Haskell code, which are defined as ``interesting'' if they cannot be simplified
using previously discovered equations. The intuition for such criteria is to
avoid special cases of known theorems, such as $0 + 0 = 0$, $0 + 1 = 1$, etc.
when we already know $0 + x = x$. Whilst \textbf{Q4} is elegantly implemented
with a congruence closure relation (version 1) and a term rewriting system
(version 2), the term generation for \textbf{Q1} is performed by brute-force.

Although \textsc{QuickSpec} only \emph{tests} its equations rather than
proving them, it is still used as the exploration component of more rigorous
systems like \textsc{HipSpec} and \textsc{Hipster}.

In the following, we give an overview of the state of the art in automated
theory exploration, then present potential improvements and our initial attempts
at implementation.

\section{Theory Exploration in Haskell}\label{haskell}

Automated theory exploration has been applied to libraries in Isabelle
and Haskell, although we focus on the latter as its implementations are
the most mature (demonstrated by the fact that \textsc{Hipster} explores
Isabelle by first translating it to Haskell). Haskell is interesting to target,
since its use of pure functions and algebraic datatypes causes many programs to
follow algebraic laws. However, since Haskell's type system cannot easily
encode such laws, less effort is given to finding and stating them; compared to
full theorem provers like Isabelle. Hence we imagine even a shallow exploration
of code repositories such as \textsc{Hackage} could find many interesting
theorems.

Currently, the most powerful TE system for Haskell is \textsc{HipSpec}, which
uses off-the-shelf automated theorem provers (ATPs) to verify the conjectures of
\textsc{QuickSpec}. \textsc{QuickSpec}, in turn, enumerates all type-correct combinations
of the terms in the theory up to some depth, groups them into equivalence
classes using the \textsc{QuickCheck} counterexample finder, then conjectures
equations relating the members of these classes. This approach works well as a
lemma generation system, making \textsc{HipSpec} a capable inductive theorem
prover as well as a theory exploration system \cite{claessen2013automating}.

\section{The \textsc{ML4HS} Framework}\label{ml4hs}

We consider \textbf{Q2} and \textbf{Q3} to be adequately solved by the existing
use of type systems and ATPs, respectively. We identify the following potential
improvements for the other questions:

\begin{description}
\item [Q1]
  Enumerating all type-correct terms is a brute-force solution to this question.
  Scalable alternatives to brute-force algorithms are a well-studied area of
  Artificial Intelligence and Machine Learning. In particular, heuristic
  search algorithms like those surveyed in \cite{blum2011hybrid} could be used.
  We could also use Machine Learning methods to identify some sub-set of a given
  theory, to prioritise over the rest.
\item [Q4]
  Various alternative ``interestingness'' criteria have been proposed, for
  example those surveyed in \cite{geng2006interestingness}. Augmenting or
  replacing the criteria may be useful, for example to distinguish useful
  relationships from incidental coincidences; or to prevent surprising,
  insightful equations from being discarded because they can be simplified.
\end{description}

We are implementing a system called \textsc{ML4HS} to investigate these ideas.
Its current form is a pre-processor for \textsc{QuickSpec} for prioritising
theory elements. Inspired by the use of premise selection
\cite{kuhlwein2012overview} to reduce the search space in ATP,
we select sub-sets of the given theory to explore, chosen to try and keep
together those expressions which combine in interesting ways, and to separate
those which combine in uninteresting ways.

We hypothesise that similarity-based clustering of expressions, inspired by that
of \textsc{ML4PG} \cite{journals/corr/abs-1212-3618} and related work in ACL2
\cite{heras2013proof}, is an effective method for performing this separation.
Future experiments will test this by comparing the throughput of
\textsc{QuickSpec} with and without the \textsc{ML4HS} pre-processor.

\section*{Acknowledgements}

Thank you to the \textsc{HipSpec} team at Chalmers University (Moa Johansson,
Koen Claessen, Nick Smallbone, Dan Ros{\'e}n and Irene Lobo Valbuena) for useful
discussions of these ideas.

\bibliographystyle{plain}
\bibliography{Bibtex}

\end{document}
