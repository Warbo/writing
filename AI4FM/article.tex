% This is LLNCS.DEM the demonstration file of
% the LaTeX macro package from Springer-Verlag
% for Lecture Notes in Computer Science,
% version 2.4 for LaTeX2e as of 16. April 2010
%
\documentclass{llncs}
%
\usepackage{makeidx}  % allows for indexgeneration
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{enumitem}
%\hypersetup{colorlinks=true}
%
\begin{document}
%
%\frontmatter          % for the preliminaries
%
\pagestyle{headings}  % switches on printing of running heads

\mainmatter              % start of the contributions
%
\title{Scaling Automated Theory Exploration}
%
%\titlerunning{Hamiltonian Mechanics}  % abbreviated title (for running head)
%                                     also used for the TOC unless
%                                     \toctitle is used
%
\author{Chris Warburton \and Ekaterina Komendantskaya}
%
%\authorrunning{Ivar Ekeland et al.} % abbreviated author list (for running head)
%
%%%% list of authors for the TOC (use if author list has to be modified)
% \tocauthor{Ivar Ekeland, Roger Temam, Jeffrey Dean, David Grove,
% Craig Chambers, Kim B. Bruce, and Elisa Bertino}
%
\institute{University of Dundee,\\
\texttt{http://tocai.computing.dundee.ac.uk}}

\maketitle              % typeset the title of the contribution

\begin{abstract}
We investigate the \textbf{theory exploration} (TE)
paradigm for computer-assisted Mathematics and identify limitations and
improvements for current approaches. Unlike the theorem-proving paradigm,
which requires user-provided conjectures, TE performs an open-ended
search for theorems satisfying given criteria. We see promise in TE for
identifying new abstractions and connections in libraries of software
and proofs, but realising this potential requires more scalable
algorithms than presently used.
\keywords{theory exploration, Haskell}
\end{abstract}
%
\section{Introduction}

Given a signature and a set of variables (collectively a \emph{theory}), then
\emph{theory exploration} (TE) describes any process
$(\Sigma, V) \overset{TE}{\rightarrow} \text{Terms}(\Sigma, V)$ for producing
terms of the theory which are well-formed, provable and satisfy some criterion
referred to as ``interesting''. These conditions give rise to the following
questions, which we use to characterise TE systems:
\begin{description}
\item [Q1] \label{Q1} How do we form terms?
\item [Q2] \label{Q2} How do we guarantee well-formedness?
\item [Q3] \label{Q3} How do we prove terms?
\item [Q4] \label{Q4} What is considered ``interesting''?
\end{description}

Early implementations like \textsc{Theorema} \cite{buchberger2000theory}
provided interactive environments, similar to computer algebra systems and
interactive theorem provers, to assist the user in finding theorems. In this
setting, terms are formed by the user in whichever way they find interesting,
whilst the software provides support for \textbf{Q2} and \textbf{Q3}.

Subsequent systems have investigated \emph{automated} theory exploration, for
tasks such as lemma discovery \cite{Hipster}. By removing user interaction,
\textbf{Q1} and \textbf{Q4} must be solved by algorithms. In existing
systems these are tightly coupled to improve efficiency, which makes it
difficult to try different approaches independently.

As an example, \textsc{QuickSpec} \cite{QuickSpec} discovers equations about
Haskell code, which are defined as ``interesting'' if they cannot be simplified
using previously discovered equations. The intuition for such criteria is to
avoid special cases of known theorems, such as $0 + 0 = 0$, $0 + 1 = 1$, etc.
when we already know $0 + x = x$. Whilst \textsc{Q4} is elegantly implemented
with a congruence closure relation (version 1) and a term rewriting system
(version 2), the term generation for \textsc{Q1} is performed by brute-force.

In the following, we give an overview of the state of the art in automated
theory exploration, then present potential improvements and our initial attempts
at implementation.

\section{Theory Exploration in Haskell}\label{haskell}

Automated theory exploration has been applied to libraries in Isabelle
and Haskell, although we focus on the latter as its implementations are
the most mature (demonstrated by the fact that \textsc{Hipster} explores
Isabelle by first translating it to Haskell). Haskell is interesting to target,
since its use of pure functions and algebraic datatypes causes many programs to
follow algebraic laws. However, since Haskell's type system cannot easily
encode such laws, less effort is given to finding and stating them; compared to
full theorem provers like Isabelle. Hence we imagine even a shallow exploration
of code repositories such as \textsc{Hackage} could find many interesting
theorems.

Currently, the most powerful TE system for Haskell is \textsc{HipSpec}. This
uses the earlier \textsc{QuickSpec} system to enumerate all type-correct
combinations of the terms in the theory, group them into equivalence
classes using the \textsc{QuickCheck} counterexample finder, then conjecture
equations relating the members of these classes. Off-the-shelf automated theorem
provers (ATPs) are used to prove these conjectures \cite{rosen2012proving}. This
approach works well as a lemma generation system, making \textsc{HipSpec} a
capable inductive theorem prover as well as a theory exploration system
\cite{claessen2013automating}.

\section{The \textsc{ML4HS} Framework}\label{ml4hs}

We consider the use of type systems and ATPs as satisfactory solutions to
\textbf{Q2} and \textbf{Q3}, respectively. For the other aspect, we identify
the following potential improvements:

\begin{description}
\item [Q1]
  Enumerating all type-correct terms is a brute-force solution to this question.
  Scalable alternatives to brute-force algorithms are a well-studied area of
  Artificial Intelligence and Machine Learning. In particular, there is
  potential in applying heuristic algorithms like those surveyed in
  \cite{blum2011hybrid}. We could also data-mine previous results using
  generalisation methods like anti-unification \cite{bulychev2010anti}, and
  use statistical methods to prioritise which elements of the theory we
  investigate.
\item [Q4]
  Various ``interestingness'' criteria have been proposed, for example those
  surveyed in \cite{geng2006interestingness}. Augmenting or replacing the
  criteria may be useful, for example to distinguish useful relationships from
  incidental coincidences; or to prevent surprising, insightful equations from
  being discarded simply because they are reducible.
\end{description}

We are implementing a system called \textsc{ML4HS} to investigate the use of
these ideas for a scalable automated theory exploration system for Haskell. In
its current form, we are investigating the prioritisation of theory elements by
augmenting \textsc{QuickSpec} with a pre-processor. Inspired by the use of
premise selection \cite{kuhlwein2012overview} to reduce the search space in ATP,
we select sub-sets of the given theory to explore, chosen to try and keep
together those expressions which combine in interesting ways, and to separate
those which combine in uninteresting ways.

We hypothesise that similarity-based clustering of expressions, inspired by that
of \textsc{ML4PG} \cite{journals/corr/abs-1212-3618}, is an effective method for
performing this separation. Future experiments will test this by measuring
throughput rates of \textsc{QuickSpec} with and without the \textsc{ML4HS}
pre-processor, to see how the performance changes with the size of the theory,
the elements of the theory (especially their types), and how much reduction we
performed with our pre-processor.

\section*{Acknowledgements}

Thank you to the \textsc{HipSpec} team at Chalmers University (Moa Johansson,
Koen Claessen, Nick Smallbone, Dan Ros{\'e}n and Irene Lobo Valbuena) for useful
discussions of these ideas.

\bibliographystyle{plain}
\bibliography{../Bibtex}

\end{document}
