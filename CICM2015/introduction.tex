\section{Introduction}\label{sec:introduction}


Development of Interactive Theorem Provers (ITPs) has led to the creation of big libraries and varied infrastructures for formal
mathematical proofs.
These frameworks usually involve thousands of definitions and theorems (for instance, there are approximately
4200 definitions and 15000 theorems in the formalisation of the Feit-Thompson theorem~\cite{FTT}).
Parts of  those libraries can often be re-applied in new domains; however,
it is a challenge for expert and non-expert users alike to trace them, and find re-usable concepts and proof ideas.

The ML4PG (``Machine-Learning for Proof-General'') tool~\cite{KHG13,CICM13,HK14} was created to help the user in such a situation for the particular case of the Coq system~\cite{Coq} and its SSReflect extension~\cite{SSReflect} developments. ML4PG uses statistical machine-learning algorithms to discover re-usable proof-patterns based on ``previous experience'' acquired from previous developments. A proof-pattern was defined as a correlation between the tactics and the types/shapes of subgoals resulting from the tactic applications within a few proof steps. The resulting tool could indeed find some interesting --- unexpected and yet relevant --- proof-patterns,
across different notation, types, and libraries. Our experiments spanned several subjects: basic mathematical infrastructures, Computer Algebra, Game Theory, and the certification of Java-like bytecode. The results are best summarised in~\cite{CICM13,HK14}.

That initial approach had two inherent limitations. First, the essence of a Coq/SSReflect proof is not fully expressible by a sequence of applied tactics. The definitions, types, and shapes of auxiliary lemmas used in a proof can be much more sophisticated and conceptual than a proof script calling them. Therefore, although ML4PG could find interesting, and often useful, sequences of tactics; it could not go further to recognise, for instance, similar definitions. Second, the notion of a proof-pattern being ``interesting'' or useful is left to the user's judgement.

In this paper, we present the most recent extensions to ML4PG  involving all kinds of Coq terms --- type declarations, definitions and lemma statements --- into the process of proof-pattern search. This required additional algorithms of feature extraction that reflect the mutual dependency of various proof objects in Coq\rq{}s dependently-typed setting; see Sections~\ref{sec:lemmaclustering} and~\ref{sec:reclemmaclustering}.
This major step in ML4PG development prompted other improvements. The initial ML4PG was considering features arising from the first 5 proof-steps in a proof, whereas now we treat every proof as a collection of
proof patches, each potentially
representing an interesting proof strategy. Moreover, if say 15th-20th step in one proof resembles a 115th-120th step in another, the tool is now able to detect such patterns deep down.
The feature extraction algorithms for proof features have been further refined to include the data collected from Coq terms, and now the
whole syntax of the chosen proof libraries is subject
to \emph{recurrent clustering} --- a novel technique for ML4PG.
All these extensions to proof-feature extraction are explained in Section~\ref{sec:recurrent}.

ML4PG used to show, in response to the user's call, a set of similar proofs,
with no hints of why these proofs are deemed similar. We now introduce two extensions that improve ML4PG's user-experience.
First, we have designed a method to automatically proof theorems based on ML4PG clustering methods (cf. Section~\ref{sec:evaluation}). Additionally, several visualisation tools (using automaton-shape or tree-shape representations) have been developed to show the proof-features that correlate, see Section~\ref{sec:visualisation}. This partially addresses the drawback of the subjective approach to
the pattern's ``interestingness'' --- now
the tool clearly declares correlation of which proof features defined the suggested proof pattern.
Finally, in Section~\ref{sec:relatedwork}, we compare ML4PG with other machine-learning and searching approaches available in the literature, and conclude the paper in Section~\ref{sec:conclusions}.


Examples we use throughout the paper come from several Coq and SSReflect libraries: the basic infrastructure of SSReflect~\cite{SSReflect}, a matrix library~\cite{GarillotEtAl09}, a formalisation of persistent homology~\cite{HCMS12}, the HoTT library~\cite{hottbook}, two formalisation related to Nash equilibrium~\cite{Ves06,nash}, and the formalisation about Java-like bytecode presented in~\cite{HK14}. ML4PG is a part of standard Proof General distribution; the novel features we present here are available at~\cite{HK12}.
