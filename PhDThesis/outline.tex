\title{``Interestingness'' in Mathematical Theory Exploration}
\documentclass{article}
\begin{document}
\maketitle

\begin{itemize}
\item Introduction
  \begin{itemize}
  \item Description of problem (simple examples)
  \item Motivation (education, research, formalising, verification, ...)
  \item Difficulties (ambiguity, open-endedness, large search space, ...)
  \end{itemize}

\item Contributions:
  \begin{itemize}
  \item TEBenchmark (large, unambiguous empirical measurement and comparison)
  \item MLSpec (bucketing methods, recurrent clustering, etc.)
  \end{itemize}

\item Background/Literature review
  \begin{itemize}
  \item History of automated discovery/creativity
    \begin{itemize}
    \item Theorem proving (Logic Theorist)
    \item Theory formation/exploration (AM, HR, Graffiti, IsaCoSy, IsaScheme,
      QuickSpec, Speculate, ...)
    \item Scientific discovery (Adam/Eve, invariant discovery)
    \item Artificial curiosity (model building, motor babbling, play, language invention, ...)
    \item Artistic creativity?
    \end{itemize}
  \item History of "interestingness"
    \begin{itemize}
    \item From philosophical perspective (surprising, novel, useful, Wundt
      curves, ...)
    \item From real implementations (non-redundancy, precision/recall,
      compression progress, learnability, ...)
    \end{itemize}
  \item Overview of machine learning techniques:
    \begin{itemize}
    \item Models (neural networks, generative models, probabilistic programming,
      gradient descent, kernel methods, population models, ...)
    \item Supervised (classification, reinforcement learning, ...)
    \item Unsupervised (clustering, co-evolution, adversarial, ...)
    \item Feature engineering
      \begin{itemize}
      \item Hand-crafted features (comparison with probabalistic programming?)
      \item Distributed representations
      \item Learned representations (auto-encoding, deep learning, convolutional
        neural networks, ...)
      \end{itemize}
    \item Structured representations (recurrent NNs, recursive NNs, tree
      kernels, Tree Based CNN, generative models, ...)
    \end{itemize}
  \item (Statistical) machine learning in formal systems
    \begin{itemize}
    \item Relevance filtering (Sledgehammer, Josef Urban's alternatives)
    \item Recurrent clustering
    \item Program manipulation (Learning to Execute, Tree Based CNN tasks
      (program classification, bubble-sort identification), auto-generated bug
      fixes, auto-generated compiler test cases, ...
    \end{itemize}
  \end{itemize}

\item TEBenchmark (mostly from paper)
  \begin{itemize}
    \item Methodology
    \item TIP corpus
    \item Haskell translation (specific issues, etc.)
    \item Isabelle translation (specific issues, etc.)
    \item QuickSpec analysis
    \item IsaCoSy analysis
    \item QuickSpec/IsaCoSy comparison
    \item Discussion of pros and cons
  \end{itemize}

\item Bucketing (mostly paper and transfer report)
  \begin{itemize}
  \item Justification (exponential running times, large numbers of discarded
    equations, low precision, ...)
  \item Bucketing as a solution (big-O analysis, oracles, ...)
  \item Bucketing algorithms
    \begin{itemize}
    \item Pseudorandom features (baseline)
    \item Circular convolution (language agnostic, distributed representation,
      not learned)
    \item Recurrent clustering (Haskell-specific, not distributed, hand-crafted,
      solves global name problem)
    \item Non-recurrent clustering?
    \end{itemize}
  \item Application to TEBenchmark (impact on total recall)
  \item Discussion
    \begin{itemize}
    \item Pros and cons
    \end{itemize}
  \end{itemize}

\item Other contributions (may splice into the other sections)
  \begin{itemize}
    \item Sandboxed evaluation of Haskell code (nix-eval)
    \item Haskell AST extraction and annotation (GHC plugin, standalone command)
    \item Exploration of popular Hackage packages
  \end{itemize}

\item Future Work

\item Conclusions
  \begin{itemize}
  \item Exploration is an important problem with many applications
  \item Hampered by ambiguous goals, small sample sizes, etc.
  \item Hampered by (lack of) efficiency
  \item Unambiguous benchmark is provided for comparison
  \item ``Smart'' bucketing method to improve efficiency
  \item Lots of room for future work (other corpora, other tools, other
    languages, applications of results, optimisation through profiling,
    abstraction invention through anti-unification, self-modelling, ...)
  \end{itemize}
\end{itemize}

\end{document}
