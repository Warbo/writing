\chapter{The Signature Selection Problem}
\label{sec:signatureselection}

Despite the clever search strategies employed by theory exploration tools, they
all rely on enumerating combinations of definitions in some way, which can cause
infeasible running times on larger inputs (based on results of the Theory
Exploration Benchmark in \S~\ref{sec:benchmark}, this happens above a few dozen
definitions). To avoid this, users of these systems must carefully select only
small subsets of their definitions to explore at a time.

We dub such cherry-picking the \emph{signature selection problem} for theory
exploration, and we analyse its effect on the running time of theory exploration
tools on the Theory Exploration Benchmark, and on the quality of the statements
they are able to generate. An automated solution to this signature selection
problem would accept a large number of definitions and efficiently select
sub-sets which are both small enough to reasonably explore, whilst still
enabling interesting properties to be discovered.

In this chapter we will:

\begin{enumerate}
  \item Define the \emph{signature selection problem} for theory exploration.
  \item Analyse the performance of theory exploration on the Theory Exploration
    Benchmark.
  \item Analyse the effect of signature selection on the quantity of desirable
    properties attainable by theory exploration on this problem set.
  \item Demonstrate how the signature selection problem is distinct from the
    well-known \emph{clustering problem} in machine learning, and how clustering
    algorithms cannot be directly applied to signature selection.
\end{enumerate}

\iffalse
% TODO: Split out
Some bespoke components required for these analyses and comparisons may also be
useful on their own, or re-purposed for other tasks. These include:

\begin{enumerate}
\item A novel feature extraction method for transforming Haskell expressions
  into a form amenable to off-the-shelf machine-learning algorithms, based on
  the existing \emph{recurrent clustering} algorithm from other languages.
\item An executable implementation of this feature extraction
  approach\footnote{https://github.com/warbo/ml4hsfe}.
\item End-to-end automation for exploration arbitrary, user-provided Haskell
  packages\footnote{https://github.com/warbo/haskell-te}.
\item Dynamic evaluation of Haskell code, with access to dynamically installed
  Haskell packages\footnote{\hPackage{nix-eval}}.
\item Translation of the signature selection problem to the constrain-solving domain, and
  executable oracles for optimal (and pessimal) signature selection, when the desired
  properties are already known\footnote{Part of
    https://github.com/warbo/bucketing-algorithms}.
\end{enumerate}
\fi

\section{The Signature Selection Problem}
\label{sec:sigselect}

Although complete, the enumeration approaches used by tools like \quickspec{}
are wasteful: many terms are unlikely to appear in theorems, which requires
careful choice by the user of what to include in the signature. For example, we
know that addition and multiplication are closely related, and hence obey many
algebraic laws; it would be prudent to explore these functions together. On the
other hand, functions such as HTTP parsers and spell-checkers will not be
related in many interesting ways; exploring their combinations is wasteful.

The signature selection problem is that of selecting sub-sets of a large
signature, such that:

\begin{itemize}
\item Few subsets are selected
\item Each sub-set is small
\item As many of the total interesting relationships are still findable
\end{itemize}

\section{Clustering}
\label{sec:clustering}

Our approach to scaling up \quickspec{} takes inspiration from two sources. The
first is relevance filtering, which makes expensive algorithms used in theorem
proving more practical by only considering clauses deemed ``relevant'' to the
problem \cite{meng2009lightweight}.

Relevance is determined by comparing clauses to the target theorem, but theory
exploration does not have such a distinguished term. Instead, we are interested
in relationships between \emph{all} terms in a signature, and hence we need a
different algorithm for considering the relevance of \emph{all terms} to
\emph{all other terms}.

A natural fit for this task is \emph{clustering}, which attempts to group
similar inputs together in an unsupervised way. Based on their success in
discovering relationships and patterns between expressions in Coq and ACL2 (in
the ML4PG and ACL2(ml) tools respectively), we hypothesise that clustering
methods can fulfil the role of relevance filters for theory exploration:
intelligently breaking up large signatures into smaller ones more amenable to
brute force enumeration, such that related expressions are explored together.

Due to its use by ML4PG and ACL2(ml), we use \emph{k-means} clustering,
implemented in the Weka tool \cite{Holmes.Donkin.Witten:1994} by Lloyd's
algorithm \cite{lloyd1982least}, with randomly-selected input elements as the
initial clusters. Rather than relying on the user to provide the number of
clusters $k$, we use the ``rule of thumb'' given in
\cite[pp. 365]{mardia1979multivariate} of clustering $n$ data points into
$k = \lceil \sqrt{\frac{n}{2}} \rceil$ clusters.


\section{Experiments}

% TODO: This was taken from the Background section, so probably doesn't fit here
% without some fiddling.
% TODO: Describe all of our experimental setups:
%
%  - The use of the TEBenchmark methodology for running QSpec, including the
%    sampling process
%
%  - Running our recurrent signature selection algorithm on samples from TEBenchmark,
%    including how we picked the sizes
%
%  - The definition of HashSpec and its use as control; how we ran all of the
%    same samples through it
%
%  - The use of optimal and pessimal oracles, defined via constraint
%    satisfaction. How we it was only feasible to run these up to size 10 (11?)

We follow the tradition of prior practitioners and use an existing corpus of
theorems as a \emph{ground truth} against which to compare results. To analyse
behaviour on large inputs (i.e. those for which exploration is currently
infeasible), as required to study the effects of signature selection, we have
used the Theory Exploration Benchmark of section~\ref{sec:tebenchmark}, which is
based on the Tons of Inductive Problems (TIP) problem set for theorem
provers~\cite{claessen2015tip}.

\begin{figure}
  \scalebox{0.45}{\input{images/steppedall.pgf}}
  \scalebox{0.45}{\input{images/steppednontoxic.pgf}}
  \caption{Kaplan-Meier survival plot for running \quickspec{} on inputs
    containing various numbers of definitions, sampled from TIP. The x axis
    denotes running time, which we cut short after 300 seconds. The height of
    each line shows the proportion of \quickspec{} runs which were still going at
    that time (lower is better). First plot is for all TIP definitions, second
    plot removes runs given ``toxic'' definitions.}
  \label{fig:survival}
\end{figure}

Figure~\ref{fig:survival} shows a Kaplan-Meier survival plot of \quickspec{} running
times, when given inputs containing different numbers of definitions. Many runs
finish quickly, with the remainder occupying a ``long tail'' which we cut off
after 300 seconds\footnote{Chosen based on preliminary experiments, which showed
  little difference in survival between 300 seconds and 1 hour}.

The number of definitions in the input is linearly correlated with the amount of
timeouts, except for the very smallest inputs (which are more constrained by the
sampling procedure). One explanation for this is ``toxic'' definitions, whose
presence in the input always leads to the exploration failing (with larger
inputs being more likely to have sampled a toxic definition).

\iffalse
\begin{figure}
  \scalebox{0.45}{\input{images/timeoutsall.pgf}}
  \scalebox{0.45}{\input{images/timeoutsnontoxic.pgf}}
  \caption{Proportion of samples which timed out per size, with least-squares
    linear regression. First plot is for all TIP definitions, second removes
    runs given ``toxic'' definitions.}
  \label{fig:tailsize}
\end{figure}
\fi

\begin{figure}
  \scalebox{0.45}{\input{images/proportionsall.pgf}}
  \scalebox{0.45}{\input{images/proportionsnontoxic.pgf}}
  \label{fig:proportions}
  \caption{Definitions, ordered by the ratio of successes to failures of the
    runs they appeared in. First graph contains all TIP definitions, showing
    ``toxic'' definitions which always failed. Second graph only contains runs
    without any toxic definitions.}
\end{figure}

\begin{figure}
  \begin{minted}{scheme}
    (define-fun-rec mult2 ((x Nat) (y Nat) (z Nat)) Nat
      (match x
        (case Z      z)
        (case (S x2) (mult2 x2 y (plus y z)))))
  \end{minted}

  \begin{minted}{scheme}
    (define-fun-rec qexp ((x Nat) (y Nat) (z Nat)) Nat
      (match y
        (case Z     z)
        (case (S n) (qexp x n (mult x z)))))
  \end{minted}

  \begin{minted}{scheme}
    (define-fun-rec op ((x Nat) (y Nat) (z Nat) (x2 Nat)) Nat
      (match x
        (case Z
          (match z
            (case Z      x2)
            (case (S x3) (op Z  y x3 (S x2)))))
        (case (S x4)
          (match z
            (case Z      (op x4 y y  x2))
            (case (S c ) (op x  y c  (S x2)))))))
  \end{minted}

  \iffalse
  \begin{minted}{scheme}
    (define-fun-rec mul3acc ((x Nat) (y Nat) (z Nat)) Nat
      (match x
        (case Z Z)                          ;; Base case for 0 * y * z
        (case (S x2)
          (match y
            (case Z Z)                      ;; Base case for x * 0 * z
            (case (S x3)
              (match z
                (case Z Z)                  ;; Base case for x * y * 0
                (case (S x4)
                  (match x2
                    (case Z
                      (match x3
                        (case Z
                          (match x4
                            (case Z (S Z))  ;; Base case for 1 * 1 * 1
                            (case (S x5)
                              (S (add3acc (mul3acc Z Z x4)
                                          (add3acc (mul3acc (S Z) Z x4)
                                                   (mul3acc Z (S Z) x4)
                                                   (mul3acc Z Z (S Z)))
                                          (add3acc Z Z x4))))))
                        (case (S x6)
                          (S (add3acc (mul3acc Z x3 x4)
                                      (add3acc (mul3acc (S Z) x3 x4)
                                               (mul3acc Z (S Z) x4)
                                               (mul3acc Z x3 (S Z)))
                                      (add3acc Z x3 x4))))))
                    (case (S x7)
                      (S (add3acc (mul3acc x2 x3 x4)
                                  (add3acc (mul3acc (S Z) x3 x4)
                                           (mul3acc x2 (S Z) x4)
                                           (mul3acc x2 x3 (S Z)))
                                  (add3acc x2 x3 x4))))))))))))
  \end{minted}
  \fi

  \iffalse
  \begin{minted}{scheme}
    (define-fun-rec mul3 ((x Nat) (y Nat) (z Nat)) Nat
      (match x
        (case Z Z)                          ;; Base case for 0 * y * z
        (case (S x2)
          (match y
            (case Z Z)                      ;; Base case for x * 0 * z
            (case (S x3)
              (match z
                (case Z Z)                  ;; Base case for x * y * 0
                (case (S x4)
                  (match x2
                    (case Z
                      (match x3
                        (case Z
                          (match x4
                            (case Z (S Z))  ;; Base case for 1 * 1 * 1
                            (case (S x5)
                              (S (add3 (mul3 Z Z x4)
                                       (add3 (mul3 (S Z) Z x4)
                                             (mul3 Z (S Z) x4)
                                             (mul3 Z Z (S Z)))
                                       (add3 Z Z x4))))))
                        (case (S x6)
                          (S (add3 (mul3 Z x3 x4)
                                   (add3 (mul3 (S Z) x3 x4)
                                         (mul3 Z (S Z) x4)
                                         (mul3 Z x3 (S Z)))
                                   (add3 Z x3 x4))))))
                    (case (S x7)
                      (S (add3 (mul3 x2 x3 x4)
                               (add3 (mul3 (S Z) x3 x4)
                                     (mul3 x2 (S Z) x4)
                                     (mul3 x2 x3 (S Z)))
                               (add3 x2 x3 x4))))))))))))
  \end{minted}
  \fi
  \caption{``Toxic'' definitions, which consistently cause \quickspec{} to fail. Two
    other definitions (\texttt{mul3} and \texttt{mul3acc}) are ommitted due to
    their verbosity.}
  \label{fig:faildefs}
\end{figure}

This does appear to be the case, as Figure~\ref{fig:proportions} shows that five
definitions appeared \emph{only} in failing inputs; these are named
\texttt{mul3}, \texttt{mul3acc}, \texttt{mult2}, \texttt{op} and \texttt{qexp};
their definitions appear in Figure~\ref{fig:faildefs}. All of these are
functions of Peano-encoded natural numbers (\texttt{Nat}), and they cause
exploration to time out by either exhausting the RAM with too many expressions
to explore, % TODO{2019-04-27} CAN QSPEC2 AVOID THIS?
or by generating such deeply-nested outputs that comparing them takes too long.
% TODO{2019-04-27} CAN WE PUT TIME AND MEMORY LIMITS ON EACH ATTEMPTED EVALUATION?

The \texttt{mul3} and \texttt{mul3acc} definitions are rather pathological
implementations of multiplication with an accumulator parameter, with many
(non-tail) recursive calls. The \texttt{op} function appears in files named
\texttt{weird\_nat\_op}, which assert its commutativity and associativity.
Finally, the \texttt{mult2} and \texttt{qexp} functions are standard
tail-recursive definitions of multiplication and exponentiation, respectively.
All of these functions have an extra ``accumulator'' argument, which increases
the number of possible expressions to explore compared to those without.

Exploring each of these functions on its own does not require much memory, since
Haskell generates the output lazily. However, comparing such large numbers for
equality takes a lot of CPU time as the \texttt{S} constructors are successively
unwrapped from each side, and this is why the timeout is reached. We confirmed
this hypothesis by exploring with a custom data generator which only generates
the values \texttt{Z}, \texttt{S Z} and \texttt{S (S Z)} (0, 1 and 2); this
caused the exploration to finish quickly. Other interventions, like making the
accumulator arguments strict (to prevent space leaks), did not prevent timeouts.

To assess the impact of these problematic definitions, we removed any samples
containing them and repeated our analysis.
