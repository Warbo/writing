\subsection{Theory Exploration}
\label{sec:theoryexploration}

In this work we consider the application of \emph{(automated) theory
  exploration} to generate conjectures about code. Existing tools are able to
\emph{prove} those conjectures, and hence output \emph{novel} theorems without
guidance from the user. The method of conjecture generation is a key
characteristic of any theory exploration system, although all existing
implementations rely on brute force enumeration to some degree.

We focus on \qspec{}~\cite{QuickSpec}, which conjectures equations about
Haskell code (these may be fed into another tool, such as \hspec{}, for
proving). These conjectures are arrived at through the following stages:

\iffalse TODO: Make this more formal?
 V \in Var
 F \in Fun
 T \in Term
 T ::= V | F | T1 T2

 Term ::= VAR | Const | Fun (Term)
or
 Term t ::= x | f | t t'
\fi

\begin{enumerate}
\item Given a typed signature $\Sigma$ and set of variables $V$, \qspec{}
  generates a list $terms$ containing the constants (including functions) from
  $\Sigma$, the variables from $V$ and type-correct function applications
  $f(x)$, where $f$ and $x$ are elements of $terms$ \iffalse TODO: A little
  awkward; maybe use the above notation? \fi. To ensure the list is finite,
  function applications are only nested up to a specified depth (by default, 3).
\item The elements of $terms$ are grouped into equivalence classes, based on
  their type.
\item Each variable is instantiated to a particular value, generated randomly by
  \qcheck{}.
\item For each class, the members are compared (using a pre-specified function,
  such as equality \hs{==}) to see if these instantiations have caused an
  observable difference between members. If so, the class is split up to
  separate such distinguishable members.
\item The previous steps of variable instantiation and comparison are repeated
  until the classes stabilise (i.e. no differences have been observed for some
  specified number of repetitions).
\item A set of equations are then conjectured, relating each class's members.
\end{enumerate}

Such $conjectures$ can be used in several ways: they can be simplified for
direct presentation to the user (by removing any equation which can be derived
from the others by rewriting), sent to a more rigorous system like \hspec{} or
\textsc{Hipster} for proving, or even serve as a background theory for an
automated theorem prover \cite{claessen2013automating}.

As an example, we can consider a simple signature containing the expressions
from Figure \ref{fig:haskellexample}:

\begin{align*}
  \Sigma_{\texttt{Nat}} = \{\texttt{Z}, \texttt{S}, \texttt{plus}, \texttt{mult}, \texttt{odd}, \texttt{even}\}
\end{align*}

Together with a set of variables, say $V_{\texttt{Nat}} = \{a, b, c\}$,
\qspec{}'s enumeration will resemble the following:

\begin{align*}
  terms_{\texttt{Nat}} = [& \texttt{Z},\ \texttt{S},\ \texttt{plus},\ \texttt{mult},\ \texttt{odd},\ \texttt{even},\ a,\ b,\ c,\ \texttt{S Z},\ \texttt{S}\ a,\ \texttt{S}\ b, \\
                     & \texttt{S}\ c,\ \texttt{plus Z},\ \texttt{plus}\ a,\ \dots ]
\end{align*}

Notice that functions such as \hs{plus} and \hs{mult} are valid terms, despite
not being applied to any arguments. In addition, Haskell curries functions, so
these binary functions will be treated as unary functions which return unary
functions. This is required as the construction of $terms$ applies functions to
one argument at a time.

\begin{figure}
  % To reproduce, run 'quickSpec nat' in haskell_example/src/QuickSpecExample.hs
  \begin{haskell}
                  plus a b = plus b a
                  plus a Z = a
         plus a (plus b c) = plus b (plus a c)
                  mult a b = mult b a
                  mult a Z = Z
         mult a (mult b c) = mult b (mult a c)
              plus a (S b) = S (plus a b)
              mult a (S b) = plus a (mult a b)
         mult a (plus b b) = mult b (plus a a)
                 odd (S a) = even a
            odd (plus a a) = odd Z
           odd (times a a) = odd a
                even (S a) = odd a
           even (plus a a) = even Z
          even (times a a) = even a
plus (mult a b) (mult a c) = mult a (plus b c)
  \end{haskell}
  \caption{Equations conjectured by \qspec{} for the functions in Figure \ref{fig:haskellexample}; after simplification.}
  \label{fig:qspecresult}
\end{figure}

These terms will be grouped into five classes, one each for \hs{Nat},
\hs{Nat -> Nat}, \hs{Nat -> Nat -> Nat}, \hs{Nat -> Bool} and \hs{Bool}. As the
variables $a$, $b$ and $c$ are instantiated to various randomly-generated
numbers, these equivalence classes will be divided, until eventually the
equations in Figure \ref{fig:qspecresult} are conjectured.

Although complete, this enumeration approach is wasteful: many terms are
unlikely to appear in theorems, which requires careful choice by the user of
what to include in the signature. Here we know that addition and multiplication
are closely related, and hence obey many algebraic laws.

\qspec{} (and \hspec{}) is also compatible with Haskell's existing testing
infrastructure, such that an invocation of \texttt{cabal test} can run these
tools alongside more traditional QA tools like \qcheck{}, \textsc{HUnit} and
\textsc{Criterion}.

In fact, there are similarities between the way a TE system like \qspec{} can
generalise from checking \emph{particular} properties to \emph{inventing} new
ones, and the way counterexample finders like \qcheck{} can generalise from
testing \emph{particular} expressions to \emph{inventing} expressions to
test. One of our aims is to understand the implications of this generalisation,
the lessons that each can learn from the other's approach to term generation,
and the consequences for testing and QA in general.

%%%%% THE BELOW SEEMS TO BE INTERESTINGNESS?

%\begin{description}
%\item{Interestingness} Various alternative interestingness criteria have been
%  proposed, which we survey in \S \ref{sec:relatedwork}. Augmenting or replacing
%  the criteria may be useful, for example to distinguish useful relationships
%  from incidental coincidences; or to prevent surprising, insightful equations
%  from being discarded because they can be simplified.
%\end{description}

% Theory exploration is similar to \emph{experimental mathematics}

% - Relation to Science
%  - Testable/falsifiable hypotheses are like evaluable terms (or, more generally, conjectures which can be decided, using a reasonable amount of resources).
% - Relation to AI tasks: exploring surroundings, etc.

% - Statistics is another area that's less straightforward than normal numerical computing, since there is subjectivity and judgement involved in the answering of questions.

% Theory formation: Alison? Others.
% Theory exploration: Buchberger, Moa in Isabelle, Koen in Haskell. Others?
% Theorem proving: Well-trodden: first-order ATP, higher-order ITP, functional programming
% Communication: Latex, Wikis, APIs, communicating with aliens

% \section{Exploration in Theorem Proving}
% \label{sec:examples}

% Before exploring abstract definitions of interestingness, we can first consider
% some scenarios which arise during formal proof where we are forced to generate
% conjectures. An analysis of these situations, and the subsequent theorems they
% produce, will contribute towards an empirical justification for what is
% interesting (at least from a utilitarian point of view) and inform our later
% exploration of the literature.

% \subsection{Generalisation}

% \providecommand{\coq}[1]{\lstinline[language=ML]|#1|}

% When we \emph{generalise} a statement $S$, we obtain a new statement $S'$ of
% which $S$ is a special case. Although it seems counterintuitive, a generalised
% statement can sometimes be \emph{easier} to prove than the original. This arises
% often in inductive proofs, since the specific obligations which arise in the
% proof may be incompatible with the available inductive hypotheses.

% However, we cannot blindly generalise \emph{all} obligations we encounter, since
% \emph{over-generalising} results in obligations which are so strong that they
% are unprovable, or even false. We must therefore rely on heuristics to guide the
% generation of generalised conjectures, and hence perform a kind of exploration.

% An informative example is given by Boyer and Moore of the associativity of
% multiplication in ACL2 \cite{boyer1983proof}:

% $$(x * y) * z = x * (y * z)$$

% During the course of the proof, the following obligation arises:

% \begin{equation}
%   \tag{conc3}
%   (y + (x * y)) * z = (y * z) + ((x * y) * z)
%   \label{eq:conc3}
% \end{equation}

% ACL2 automatically generalises \eqref{eq:conc3} by replacing the repeated
% sub-term $x * y$ with a fresh variable $w$:

% \begin{equation}
%   \tag{conc4}
%   (y + w) * z = (y * z) + (w * z)
%   \label{eq:conc4}
% \end{equation}

% This generalised form is clearly the distributivity law for multiplication and
% addition, which can be proved separately to the original goal of
% associativity. It would not be controversial to claim that this distributivity
% law is interesting in its own right (relative to associativity, at least), in
% addition to its usefulness in making this proof go through.

% % TODO: Describe the ACL2 heuristics

% Generalisation also occurs frequently when reasoning about \emph{tail-recursive}
% definitions \cite{kapur2003automatic}. \footnote{A tail-recursive function can
%   be executed in constant space using a loop, whereas recursion in non-tail
%   positions may require a growing number of stack frames or nested closures. See
%   \S \ref{sec:auxiliarylemmas} for example definitions of each type.}

% \subsection{Analogy}

% One way to characterise the interestingness of a statement is by \emph{analogy}
% to existing interesting statements. By finding lemmas analogous to those of a
% different theory, we may be able to re-use tactics and other forms of
% meta-programming across both.

% Existing theory exploration systems have been successfully applied to this
% problem, however the use of pure exploration misses opportunities to
% \emph{focus} the search, since we know which lemmas are used in those theories
% where a technique succeeded. If we can find an analogy to map from such solved
% problems to our unsolved goal, we can infer the approximate form of the lemmas
% we require, and target these specifically.

% The approach taken by \textsc{ACL2(ml)} is to find lemmas which may be relevant
% to solving a goal $G$ by making analogies via unsupervised clustering
% \cite{Heras.Komendantskaya.Johansson.ea:2013}. These clusters are used in two
% ways:

% \begin{itemize}
% \item First, we use the cluster $C_G$ containing $G$ to identify analogous
%   theorems.

% \item For each theorem $T \in C_G \setminus \{G\}$, we consider those symbols
%   $S_T$ which occur in $T$ but not in $G$. Our analogous lemmas are those used
%   to prove $T$, mutated such that symbols $s \in S_T$ are replaced by members of
%   the cluster $C_s$ containing $s$.
% \end{itemize}

% The running examples for demonstrating \textsc{ACL2(ml)} are equivalence
% theorems for tail-recursive and non-tail-recursive calculations, as well as the
% effect of repeating certain list operations:

% \begin{itemize}

%   \item $\forall n, \texttt{natp}(n) \rightarrow \texttt{fact-tail}(n) = \texttt{fact}(n)$ where \texttt{natp} is the predicate that $n$ is a natural number, whilst \texttt{fact-tail} and \texttt{fact} are tail-recursive and non-tail-recursive implementations of factorial, respectively.

%   \item $\forall n, \texttt{natp}(n) \rightarrow \texttt{power-tail}(n) = \texttt{power}(n)$,  where \texttt{power-tail} and \texttt{power} calculate powers of 2.

%   \item $\forall n, \texttt{natp}(n) \rightarrow \texttt{fib-tail}(n) = \texttt{fib}(n)$,  where \texttt{fib-tail} and \texttt{fib} calculate fibonacci numbers.

%   \item $\forall x, \texttt{nat-listp}(x) \rightarrow \texttt{sort}(\texttt{sort}(x)) = \texttt{sort}(x)$, for list-of-natural-numbers predicate \texttt{nat-listp} and list-sorting function \texttt{sort}.

%   \item $\forall x, \texttt{true-listp}(x) \rightarrow \texttt{rev}(\texttt{rev}(x)) = x$, where \texttt{true-listp} ensures that $x$ is a valid singly-linked list structure and \texttt{rev} is list reversal.

%   \item $\forall x, \texttt{true-listp}(x) \rightarrow \texttt{int}(x, x) = x$, where \texttt{int} is the intersection of lists (i.e. a list of elements common to each).

% \end{itemize}

% \subsection{Auxiliary Lemmas} \label{sec:auxiliarylemmas}

% One consideration when generating conjectures is the difference between
% theorems, lemmas, corollaries, etc. From a logical point of view, these are all
% equivalent, and hence most proof assistants do not distinguish between
% them. However, their \emph{intention} may be different: in a sense, theorems are
% the interesting results; whilst lemmas are useful results, required for proving
% the theorems.

% Some systems, like Coq, allow users to \emph{label} each statement as being a
% \coq{Theorem}, a \coq{Lemma}, etc. despite their internal representations being
% the same. This shows us immediately that lemmas outnumber theorems; in the Coq
% standard library there are over five times as many lemmas as theorems
% \footnote{The latest version as of writing is \texttt{coq-8.4pl6} which, when
%   excluding comments, includes 1492 occurences of \coq{Theorem} and 7594 of
%   \coq{Lemma} in its \texttt{theories/} directory.}.

% % TODO: Analyse them

% % TODO: Theory exploration as lemma generation; give example from a HipSpec paper

% We can find a need for auxiliary lemmas, once again, in the context of
% tail-recursive functions. Consider proving the (pointwise) equality of the
% following Coq functions, defined for the Peano naturals \coq{Z} and \coq{S}:

% \begin{lstlisting}[language=ML, xleftmargin=.2\textwidth, xrightmargin=.2\textwidth]
% Inductive Nat : Set := Z : Nat
%                      | S : Nat -> Nat.

% Fixpoint plus      (n m : Nat) := match n with
%                                       | Z    => m
%                                       | S n' => S (plus n' m)
%                                   end.

% Fixpoint plus_tail (n m : Nat) := match n with
%                                       | Z    => m
%                                       | S n' => plus_tail n' (S m)
%                                   end.
% \end{lstlisting}

% \begin{haskell}
% Haskell equivalent:

% plus :: Nat -> Nat -> Nat
% plus      n  Z    = n
% plus      n (S m) = S (plus n m)

% plus_tail :: Nat -> Nat -> Nat
% plus_tail n  Z    = n
% plus_tail n (S m) = plus_tail (S n) m
% \end{haskell}

% Both of these functions implement addition, but the \coq{plus_tail} variant is
% tail-recursive. However, if we want to \emph{prove} that the definitions are
% (pointwise) equal, we run into difficulties. In particular, when the inductive
% step requires us to prove \coq{plus (S n) m = plus n (S m)} (which seems
% reasonable), we cannot make this go through using another inductive argument.

% \begin{lstlisting}[language=ML, xleftmargin=.2\textwidth, xrightmargin=.2\textwidth]
% (* Solve equalities by beta-normalising both sides *)
% Ltac triv := try (simpl; reflexivity).

% (* Prove equivalence of plus and plus_tail *)
% Theorem equiv : forall n m, plus n m = plus_tail n m.
%   induction n; triv. (* Base case is trivial *)

%   (* Inductive case: plus (S n) m = plus_tail (S n) m *)
%   intro m.

%   (* Beta-reduce the right-hand-side (justification is trivial) *)
%   replace (plus_tail (S n) m) with (plus_tail n (S m)); triv.

%   (* Use induction hypothesis to replace plus_tail with plus *)
%   rewrite <- (IHn (S m)).
% \end{lstlisting}

% Specifically, the \emph{conclusion} of a second inductive hypothesis is exactly
% the equation we need:

% \begin{lstlisting}[language=ML, xleftmargin=.2\textwidth, xrightmargin=.2\textwidth]
% IHn' : (forall x, plus n' x = plus_tail n' x) -> plus (S n') m = plus n' (S m)
% \end{lstlisting}

% Yet we cannot provide it with the argument it needs, as our original induction
% hypothesis is \emph{too specific} (i.e. it has too many \coq{S} constructors):

% \begin{lstlisting}[language=ML, xleftmargin=.2\textwidth, xrightmargin=.2\textwidth]
% IHn : forall x, plus (S n') x = plus_tail (S n') x
% \end{lstlisting}

% We are forced to abandon the proof, despite such a reasonable-looking
% intermediate goal.

% In fact, if we attempt to prove that goal \emph{separately}, we can use a
% straightforward argument by induction; even though it is actually
% \emph{stronger} due to the absence of the \coq{IHn} assumption. Using this
% separate result as a lemma, the pointwise equality is proven easily.

% \begin{lstlisting}[language=ML, xleftmargin=.2\textwidth, xrightmargin=.2\textwidth]
% Lemma gen n m : plus (S n) m = plus n (S m).
%   induction n; triv. (* Base case is trivial *)

%   (* Move all S constructors outside *)
%   simpl. rewrite <- IHn. simpl.

%   (* Trivial *)
%   reflexivity.
% Defined.
% \end{lstlisting}

% \begin{lstlisting}[language=ML, xleftmargin=.2\textwidth, xrightmargin=.2\textwidth]
%   rewrite (gen n m).
%   reflexivity.
% Defined.
% \end{lstlisting}
