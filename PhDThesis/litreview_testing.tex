\section{Property Checking}

Some prominent tools for mathematical theory exploration, like \quickspec{},
were originally developed in the context of \emph{property checking} (although
for \emph{discovering} software properties, rather than checking them), and only
later applied more directly to fields like formal mathematics (e.g. via the
\hipster{} tool for Isabelle/HOL). In particular, the logical domain used by
\quickspec{} (inductive logic with higher-order functions) comes directly from
its application to Haskell; its search algorithm also makes heavy use of the
\quickcheck{} property checker. The boundary between these two fields is hence
rather fuzzy, and cross-pollination of techniques is a compelling target for
research.

Property checking attempts to establish the truth or falsity of a statement (a
``property''), usually involving components of a software system and, crucially,
which may contain free variables. \emph{Unit testing} is a common method of
software quality assurance (outside of specialised domains like those which are
life-critical), which can be characterised as proving \emph{existential}
properties: each test includes concrete values for any variables, and checking
is simply a matter of evaluating the code to get a boolean value (pass or fail).
The phrase ``property checking'' is typically reserved for \emph{universal}
properties: those which should hold \emph{for all} values of the variables.
This is a popular method of quality assurance for Haskell software, giving rise
to a number of packages which approach this challenge in different ways.

Universal properties are typically encoded in Haskell as \emph{functions},
accepting values for the free variables as arguments, and returning a boolean
value (perhaps adorned with useful metadata). If the type of the input is finite
(for example booleans), it might be feasible to check all possible
values. Typically this is not the case, especially when multiple variables are
involved, or the types have an infinite number of members (for example
lists). Property checkers avoid this by only testing a sub-set of values, in the
hope that a counterexample will be found (if one exists). They work by:

\begin{enumerate}
\item Generating suitable values for the function's arguments
\item Calling the function with these values
\item Inspecting the return value
\item Repeating until some stop condition is satisfied
\end{enumerate}

Most frameworks will test each property a fixed number of times (e.g. 100), and
stop early if the function returns a false value. The major difference between
implementations is the way they generate values to test with.

\quickcheck{}~\cite{claessen2011quickcheck} popularised the use of
property checking in Haskell, and has subsequently been ported to many other
programming languages. \quickcheck{} generates input data \emph{randomly},
either using explicit generators (via a function called \hs{forAll}), or by
choosing a default generator for types implementing its \hs{Arbitrary}
typeclass (the recent \texttt{hedgehog} package works in a similar way).

Random testing is effective at thoroughly exercising the branches of a program,
since inputs may be quite large and cover many cases, especially for functions
which recurse on each \emph{sub-}expression of their input as well. The output
of a random generator will also vary across runs, rather than checking the same
values every time. Hence every invocation of a property checker, e.g. as part of
a development or debugging workflow, allows more of the input space to be
tested. However, there are two common problems with random property checking.

Firstly we must be able to generate random values, which can be tricky for
recursive datatypes. Consider a type of binary trees, with constructors
\hs{Leaf :: Tree} and \hs{Node :: Tree -> Tree -> Tree}. We might
generate a \hs{Tree} by picking uniformly between these two constructors
and, if a \hs{Node} was picked, recursing to generate the two
sub\hs{Tree}s. Yet this simple scheme will generate \hs{Tree}s whose
expected size is \emph{unbounded}! This is due to the 50\% chance of generating
a \hs{Node}, which requires two recursive calls; hence we can expect each
call to recurse $0.5~\times~0~+~0.5~\times~2~=~1$ more time on average, and that call will also
recurse once more on average, and so on; this can easily exhaust all available
memory. Many automated data generators, such as those from Haskell's
\texttt{derive} package, suffer from this problem. It can be avoided by biasing
the generators (in the \hs{Tree} example we would produce a \hs{Leaf}
more than half of the time), but this bias compounds at each level of recursion,
limiting testing to exponentially small values. More sophisticated solutions
exist, such as the \texttt{boltzmann-sampling} package (see
\cite{duchon2004boltzmann}) and even domain-specific
languages~\cite{lampropoulos2017beginner}, but all of these add complications to
the property checking process.

The other problem with random generators is that it can be difficult to
understand \emph{why} a randomly generated value violated some property.
\quickcheck{} tackles this in two ways: generators have access to a
``size'' parameter, with the intention that this be used to decide how large the
output values should be (e.g. the expected length of a list, or number of nodes
in a tree). The value of the size parameter begins low and increases as more
tests pass, such that failures are likely to be triggered by small, more easily
understood counterexamples first. Additionally, a mechanism for ``shrinking'' is
provided: users can supply a \hs{shrink} function along with their generator,
which is given any counterexample found during testing and returns a list of
smaller values. In the above example we might shrink a \hs{Node} by returning
each sub-tree, and return an empty list when asked to shrink a \hs{Leaf}. If one
of these smaller values is also a counterexample, it too is shrunk and the
process repeats, otherwise it is discarded and the next element of the list is
tried. When a value cannot be shrunk any more, or if none of its shrunken
versions are counterexamples, that value is presented to the user in the hope
that it is simple enough to understand.

The \smallcheck{} framework takes a different approach: \emph{enumerating}
values (either using a user-provided enumeration function or using its
\hs{Serial} typeclass), rather than generating values
randomly~\cite{runciman2008smallcheck} (a similar approach is also followed by
the \texttt{testing-feat} package \iffalse \cite{}TODO} \fi). In the
\hs{Tree} example this might check \hs{Leaf}, then \hs{Node Leaf
  Leaf}, then \hs{Node (Node Leaf Leaf) Leaf}, and so on. Enumerating in
order of ``size'' ensures that counterexamples are always small, that tests are
not repeated with the same values and that memory is not exhausted (since the
stopping condition will trigger long before the enumeration reaches such large
values). The disadvantage is that large inputs (which exercise properties,
especially recursive ones, the most) may occur so late in the enumeration that
testing never reaches them.

The \lazysmallcheck{} framework is similar in spirit to
\smallcheck{}, but utilises Haskell's lazy evaluation to avoid generating
values up front~\cite{reich2013advances}. Instead, a partial value is generated
which will trigger an exception if evaluated. Since catching a Haskell exception
is an \hs{IO} action, pure properties which inspect such values will always
be aborted, handing control back to \lazysmallcheck{} which refines the
previous value and tries again. For example, a lazily generated \hs{Tree} may
initially be equivalent to $\bot$ (an undefined value). If the property
aborts, it will be run again with each possible refinement of $\bot$: in this
case inputs equivalent to \hs{Leaf} and \hs{Node}~$\bot_1$~$\bot_2$. If
the latter aborts due to inspecting $\bot_1$, then $\bot_1$ will be refined to
give inputs \hs{Node Leaf}~$\bot_2$ and
\hs{Node (Node}~$\bot_3$~$\bot_4$\hs{)}~$\bot_2$ (and likewise if $\bot_2$
had caused the exception). This refinement continues until the property no
longer aborts or until a predefined depth limit is reached. If the property
returns a true value when given such partially-defined input then it must
succeed for \emph{all} refinements of that input (since the output was
determined without evaluating the undefined sub-terms). If the property returns
a false value, the input is a \emph{minimal} counterexample, since it only
specifies those sub-terms which are required to violate the property; any
undefined sub-terms are irrelevant to the failure.

\lazysmallcheck{}'s automatic elaboration of free variables is similar in
operation to the use of search procedures in logic programming languages like
Kanren, Prolog (which has its own \quickcheck{} port) and Curry (a
functional logic language, whose \textsc{EasyCheck} framework explicitly
unifies the concepts of generators and logic
variables~\cite{christiansen2008easycheck}). The use of uninterpreted symbols
is also reminiscent of \emph{symbolic execution}~\cite{king1976symbolic}, a form
of \emph{abstract interpretation} where unknown runtime values are represented
by opaque symbols and computation proceeds to arrive at a result, which may be a
complicated expression involving many symbols.
