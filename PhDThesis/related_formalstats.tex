\section{Statistics of Formal Systems}

\iffalse
TODO: Alison: I'd like to revisit this chapter once I see the whole
thesis. At the moment it feels in parts more like a discussion of your work,
than of related work. It might help to read other people's related work sections
to get a better idea of what to include here. I think it'll be more obvious too,
once we have the intro, etc. I suspect you'll need to do a fair bit more work on
this one.
\fi

The core problem of assigning ``interestingness'' to logical formulae is the
application of statistical reasoning to the discrete, semantically-rich domain
of formal systems. This problem has been tackled from various directions for a
variety of reasons; here we summarise those contributions which are of
particular importance for theory exploration.

\subsection{Clustering}
\label{sec:clustering}

The most relevant related work for our recurrent clustering approach is
\mlforpg{}~\cite{journals/corr/abs-1212-3618}. This clusters expressions in the
Coq proof assistant, for presenting to the user (e.g. if they are stuck on a
proof, it may be useful to read ``similar'' proofs). Like our approach, this
transforms syntax trees into a matrix of values, which is then flattened into a
vector. We use the same idea of clustering referred-to definitions in order to
attain transitive similarity; however, our approach must also handle mutual
recursion (which is much more restricted in Coq, and hence unsupported by
\mlforpg{}).

The other prior work for recurrent clustering is\aclml{}~\cite{heras2013proof},
which is similar to \mlforpg{} but applies to ACL2 (Common Lisp) and is hence
untyped. The algorithm also differs, since it \emph{summarises} trees, rather
than directly encoding them to vector elements.

\subsection{Probability of Statements}

An important property of a logical formula (in general, and in particular with
regards to interestingness) is its truth value. Although we may sometimes be
able to determine truth values exactly, e.g. via deduction, for many formulae it
may only be possible (or practical) to \emph{approximate} their truth value. One
straightforward approximation is to adopt \emph{probabilities}, where we assign
probability $1$ to formulae which are known to be true (e.g. axioms), $0$ to
formulae known to be false, and intermediate values to those which are not
known~\cite{Hutter.Lloyd.Ng.ea:2013}. For example, the truth value of universal
statements (e.g. ``all ravens are black'') cannot be deduced from non-exhaustive
examples (e.g. real-world observations of raven colours), but various induction
methods may infer an (approximate) truth value~\cite{10.1093/mind/LIV.214.97}.

One difficulty with approximate truth values is maintaining consistency without
requiring \emph{logical omniscience} (knowledge of all the logical consequences
of the chosen axioms). Avoiding logical omniscience has given rise to the field
of \emph{bounded rationality}, where reasoning (deduction, induction, etc.) is
subject to some computational constraints. For example, the ``logical inductor''
of~\cite{garrabrant2016logical} avoids assigning particular probabilities to
formal statements, and instead produces a \emph{sequence} of successive
approximate probabilities, each computable with finite resources (albeit very
inefficiently), and guaranteed to be \emph{eventually consistent}.

The probability of a statement can affect its interestingness in a few ways.
Statements whose probability is very close to $0$ or $1$ may be considered
less interesting, since they are essentially known (e.g. easily derivable or
refutable via known facts). Those closer to $\frac{1}{2}$ may be considered more
interesting; although in a bounded rationality context this may simply indicate
the requirement for some routine (but lengthy) computation: for example stating
that the $n$th bit of $\pi$ is a zero, for some large $n$.

To avoid such trivially-easy and infeasibly-difficult statements (which we may
consider uninteresting) we can instead consider the \emph{variance}
(disagreement) between \emph{multiple} approximate truth values (similar to the
problem solvers of~\cite{fernando2013design1, fernando2013design2}). Those
statements which are assigned similar truth values by a variety of methods may
be considered less interesting, as they are either easy enough to infer by all
of our methods, or too hard for any of them (the stability of a single method's
prediction over time would serve a similar role). One benefit of this
application is that the approximation methods do not have to be particularly
capable; in fact choosing ``superhuman'' algorithms would be \emph{less} useful
in this context, since they would agree on the triviality of many statements we
might consider interesting.

\iffalse
\subsection{Interestingness in Concept Formation}
\label{sec:conceptformation}

% TODO:
\cite{Montano-Rivas.McCasland.Dixon.ea:2012}
\cite{Piantadosi.Tenenbaum.Goodman:2012}
\cite{Wille:2005}
\cite{colton1999automatic}
\cite{colton2000agent}
\cite{colton2012automated}
\cite{lenat1977automated}
\cite{mullerunderstanding}
\cite{Bundy.Cavallo.Dixon.ea:2015}
\cite{johansson2009isacosy}
\cite{spector2008genetic}
\cite{colton2012automated}
\cite{geng2006interestingness}
% TODO: How does https en.wikipedia.org/wiki/Discovery system relate?

% However, this search space grows exponentially in the length of the proofs,
% which is unfortunate since proof length has been proposed as an approximate
% measure of how interesting a theorem is \cite[\S~10.2.1]{colton2012automated}.

% Alan Bundy et al

% Eurisko, AM, etc.?
\fi
