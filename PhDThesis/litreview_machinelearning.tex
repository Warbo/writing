\section{Machine Learning Applications to Formal Systems}

Machine Learning (ML) applies statistical techniques to find patterns in data.
ML algorithms are numerical in nature, and often rely on assumptions such as
continuity and differentiability. In contrast, formal systems such as
mathematical formulae, formal logic and computer programs are usually discrete
and symbolic. This makes application of ML to these domains more difficult than,
say, image processing, which has a natural representation as numeric pixel
values. This difficulty is clear from attempts to train Artificial Neural
Networks (ANNs) to evaluate snippets of program code~\cite{zaremba2014learning}:
even with heavily restricted inputs (e.g. short integer calculations, with
little nesting, requiring only linear time and memory use, and evaluating with
``teacher forcing'' to prevent errors accumulating) the accuracy quickly drops
with program length. Coupled with the success of \emph{deep learning} (efficient
back-propagation/credit-assignment over many differentiable processing steps)
compared to prior hand-engineered AI solutions, it is apparent that symbolic
and statistical methods are \emph{complementary}; hence the need to identify
relevant sub-tasks for each technique when combined into some larger system.

One way to incorporate ML into a traditionally symbolic domain is to analyse
real-world measurements of a system, such as time or power taken to execute
computer programs. Since flipping a single bit can cause arbitrarily large
changes in program behaviour (if it is the scrutinee of a conditional, for
example), such programs must be very similar for statistical patterns to emerge
in their executions. In the case of \emph{auto-tuning}, many programs variants
are measured, which all perform the same task in slightly different ways (e.g.
using different compiler optimisations, or dividing work differently between
hardware components); in this case the goal is to learn a predictive model of
which variant performs best for a given input~\cite{ganapathi2009case}.

Whilst performance measurements are simple numeric values, the symbolic values
still need some conversion to become amenable to learning. This is usually
performed by a \emph{feature extraction} step, which takes various measurements
(e.g.  counting occurrences of some element, assigning indices to different
constants, etc.) and packs them into a vector for subsequent analysis. One major
advantage of deep learning systems is their ability to find structure in rather
crude representations: the first few layers effectively perform the job of
feature extraction, without the need for hand-crafting task-specific extractors.
For example, the feature extraction in~\cite{cummins2017synthesizing} represents
computer programs (after some normalisation to a consistent layout and naming
scheme) as a sequence of individual characters, with each ASCII character
replaced by a different number. Yet even this na\"ive method is enough for the
deep neural network that consumes these sequences to infer structure relevant
for deciding whether the code is better suited to running on a CPU or GPU. The
\textsc{DeepTune} system encodes slightly more domain knowledge by tokenising
language keywords, rather than requiring them to be learned, but is otherwise
similar~\cite{cummins2017end}.

Another useful class of ML systems are \emph{generative models}, which are
reversible. The \textsc{DeepSmith} system~\cite{cummins2017deepsmith} turns a
corpus of source code into a stream of (numeric) tokens, feeds them into a deep
neural network and learns to predict which token will appear next in the stream.
Once trained, realistic fragments of code can be generated by providing an
initial token as a ``seed'', then sampling from the predicted distribution
(similar to using a Markov Chain). Generated programs are suitable for e.g.
fuzz-testing compilers. Such systems are relevant to Theory Exploration, since
those systems can be viewed as a generative model of interesting statements. One
difficulty which makes it far from straightforward to implement a Theory
Exploration system along the same lines as \textsc{DeepSmith} is the lack of
ground-truth data from which to discern what is ``interesting'' and what is not
(our Theory Exploration Benchmark %TODO Section ref
provides enough for evaluation purposes, but learning (and subsequently
validating) would require orders of magnitude more). Another is the
ever-changing nature of what is interesting: sampling statements from a static
distribution would eventually run out of novelty and surprisingness, at the
least. There is, however, promise in using generative models to produce
realistic input to some separate processing step, e.g. to filter or otherwise
transform them to produce only interesting results.
