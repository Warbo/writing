\section{Contributions}
\label{sec:contributions}

\subsection{Recurrent Clustering}
\label{sec:recurrentclustering}

\iffalse TODO: Focus the section more on the problem of identifiers, and how recurrent clustering uses clustering as part of feature extraction to solve this \fi

We take the \emph{recurrent clustering} approach found in ML4PG and ACL2(ml), and implement a variant in the context of Haskell theory exploration. As a clustering algorithm, the aim of recurrent clustering is to identify similarities in a set of data points (in our case, Core expressions). Its distinguishing characteristic is to \emph{combine} feature extraction and clustering into a single recursive algorithm, to avoid problems with identifiers (described below). Here we describe our approach to recurrent clustering and compare its similarity and differences to those of ML4PG and ACL2(ml).

We consider our algorithm in two stages: the first transforms the nested structure of expressions into a flat feature vector representation; the second converts the discrete symbols of Core syntax into features (real numbers), which we will denote using the notation $\feature{}$.

\subsubsection{Expressions to Vectors}

Our recurrent clustering algorithm makes use of the k-means algorithm described in \S \ref{sec:kmeans}, which considers the elements of a feature vector to be orthogonal. Hence we must ensure that similar expressions not only give rise to similar numerical values, but crucially that these values appear \emph{at the same position} in the feature vectors. Since different patterns of nesting can alter the ``shape'' of expressions, simple traversals (breadth-first, depth-first, post-order, etc.) may cause features from equivalent sub-expressions to be mis-aligned. For example, consider the following expressions, which represent pattern-match clauses with different patterns but the same body (\hs{\vlocal{y}}):

\begin{equation*}
  \begin{array}{r@{}l@{}l@{}}
    X\ &=\ \CAlt\ (\CDataAlt\ \id{C})\ & (\vlocal{y}) \\
    Y\ &=\ \CAlt\ \CDefault\           & (\vlocal{y})
  \end{array}
\end{equation*}

If we traverse these expressions in breadth-first order, converting each token to a feature using $\feature{}$ and padding to the same length with $0$, we would get the following feature vectors:

\begin{small}
  \begin{equation*}
    \begin{array}{r@{}l@{}l@{}l@{}l@{}l@{}l@{}l}
      breadthFirst(X)\ &=\ (\feature{\CAlt},\ &\feature{\CDataAlt},\ &\feature{\CVar},\ &\feature{\id{x}},\ &\feature{\CLocal},\ &\feature{\id{y}} &) \\
      breadthFirst(Y)\ &=\ (\feature{\CAlt},\ &\feature{\CDefault},\ &\feature{\CVar},\ &\feature{\CLocal},\ &\feature{\id{y}},\ &0 &)
    \end{array}
  \end{equation*}
\end{small}

Here the features corresponding to the common sub-expression $\CLocal\ \id{y}$ are misaligned, such that only $\frac{1}{3}$ of features are guaranteed to match (others may match by coincidence, depending on $\feature{}$). These feature vectors might be deemed very dissimilar during clustering, despite the intuitive similarity of the expressions $X$ and $Y$ from which they derive.

If we were to align these feature optimally, by padding the fourth column rather than the sixth, then $\frac{2}{3}$ of features would be guaranteed to match, making the similarity of the vectors more closely match our intuition and depend less on coincidence.

The method we use to ``flatten'' expressions, described below, is a variation of breadth-first traversal which pads each level of nesting to a fixed size $c$ (for \emph{columns}). This doesn't guarantee alignment, but it does prevent mis-alignment from accumulating across different levels of nesting. For this example, our method would give the following feature vectors when $c = 2$:

\begin{small}
  \begin{equation}\label{eq:flattened}
    \begin{array}{r@{}l@{}l@{}l@{}l@{}l@{}l@{}l@{}l@{}l}
      featureVec(X)\ &=\ (\feature{\CAlt},\ &0,\ &\feature{\CDataAlt},\ &\feature{\CVar},\ &\feature{\id{x}},\  &\feature{\CLocal},\ &\feature{\id{y}},\ &0 &) \\
      featureVec(Y)\ &=\ (\feature{\CAlt},\ &0,\ &\feature{\CDefault},\ &\feature{\CVar},\ &\feature{\CLocal},\ &0,\                 &\feature{\id{y}},\ &0 &)
    \end{array}
  \end{equation}
\end{small}

Here $\frac{1}{2}$ of the original 6 features align, which is more than $breadthFirst$ but not optimal. Both vectors have also been padded by an extra 2 zeros compared to $breadthFirst$; raising their alignment to $\frac{5}{8}$.

To perform this flattening we first transform the nested tokens of an expression into a \emph{rose tree} of features, using the $toTree$ function shown in figure \ref{fig:totree}. Rose trees are defined recursively: $T$ is a rose tree if $T = (f, T_1, \dots, T_{n_T})$, where $f \in \mathbb{R}$ and $T_i$ are rose trees. $T_i$ are the \emph{sub-trees} of $T$ and $f$ is the \emph{feature at} $T$. $n_T$ may differ for each (sub-) tree; trees where $n_T = 0$ are \emph{leaves}. The results are illustrated in figure \ref{fig:rosetreeexample}.

\begin{figure}
  \begin{align*}
    toTree(e) &=
    \begin{cases}
      (\feature{\CVar},     toTree(e_1))                                 & \text{if $e = \CVar\ e_1$} \\
      (\feature{\CLit},     toTree(e_1))                                 & \text{if $e = \CLit\ e_1$} \\
      (\feature{\CApp},     toTree(e_1), toTree(e_2))                    & \text{if $e = \CApp\ e_1\ e_2$} \\
      (\feature{\CLam},     toTree(e_1))                                 & \text{if $e = \CLam\ l_1\ e_1$} \\
      (\feature{\CLet},     toTree(e_1), toTree(e_2))                    & \text{if $e = \CLet\ e_1\ e_2$} \\
      (\feature{\CCase},    toTree(e_1), toTree(a_1), \dots)             & \text{if $e = \CCase\ e_1\ l_1 a_1 \dots$} \\
      (\feature{\CType})                                                & \text{if $e = \CType$} \\
      (\feature{\CLocal},   leaf(l_1))                                  & \text{if $e = \CLocal\ l_1$} \\
      (\feature{\CGlobal},  leaf(g_1))                                  & \text{if $e = \CGlobal\ g_1$} \\
      (\feature{\CLitNum})                                              & \text{if $e = \CLitNum\ n_1$} \\
      (\feature{\CLitStr})                                              & \text{if $e = \CLitStr\ s_1$} \\
      (\feature{\CAlt},     toTree(e_1), toTree(e_2))                   & \text{if $e = \CAlt\ e_1 e_2 l_1 \dots$}  \\
      (\feature{\CDataAlt}, leaf(g_1))                                  & \text{if $e = \CDataAlt\ g_1$}  \\
      (\feature{\CLitAlt},  toTree(e_1))                                & \text{if $e = \CLitAlt\ e_1$}  \\
      (\feature{\CDefault})                                             & \text{if $e = \CDefault$}  \\
      (\feature{\CNonRec},  toTree(e_1))                                & \text{if $e = \CNonRec\ e_1$}  \\
      (\feature{\CRec},     toTree(e_1), \dots)                         & \text{if $e = \CRec\ e_1 \dots$} \\
      (\feature{\CBind},    toTree(e_1))                                & \text{if $e = \CBind\ l_1 e_1$}
    \end{cases} \\
    leaf(x) &= (\feature{x})
  \end{align*}
  \caption{Transforming Core expressions of figure \ref{fig:coresyntax} to rose trees. The recursive definition is mostly routine; each repeated element (shown as $\dots$) has an example to indicate their handling, e.g. for $\CRec$ we apply $toTree$ to each $e_i$. Also note that we ignore the value of literals, as it simplifies our later definition of $\feature{}$ and we conjecture that the effect on clustering real code is low.}
  \label{fig:totree}
\end{figure}

\begin{figure}
  \centering
  \begin{subfigure}{\textwidth}
    \begin{small}
      \Tree[ .$\feature{\CLam}$
                $\feature{\id{a}}$
                [ .$\feature{\CCase}$
                     [ .$\feature{\CVar}$
                          [ .$\feature{\CLocal}$
                               $\feature{\id{a}}$ ]]
                     $\feature{\id{b}}$
                     [ .$\feature{\CAlt}$
                          [ .$\feature{\CDataAlt}$
                               $\feature{\id{Z}}$ ]
                          [ .$\feature{\CVar}$
                               [ .$\feature{\CGlobal}$
                                    $\feature{\id{False}}$ ]]]
                     [ .$\feature{\CAlt}$
                          [ .$\feature{\CDataAlt}$
                               $\feature{\id{S}}$ ]
                          [ .$\feature{\CApp}$
                               [ .$\feature{\CVar}$
                                    [ .$\feature{\CGlobal}$
                                         $\feature{\id{even}}$ ]]
                               [ .$\feature{\CVar}$
                                    [ .$\feature{\CLocal}$
                                         $\feature{\id{n}}$ ]]]
                          $\feature{\id{n}}$ ]]]
    \end{small}
    \caption{Rose tree for the expression \hs{odd} from \ref{fig:coreexample}. Each (sub-) rose tree is rendered with its feature at the node and sub-trees beneath.}
    \label{fig:rosetreeexample}
  \end{subfigure}
  \vspace{1ex}
  \begin{subfigure}{\textwidth}
    \begin{equation*}
      \begin{bmatrix}
        \feature{\CLam}      & 0                   & 0                  & 0                   & 0               & 0                \\
        \feature{\id{a}}     & \feature{\CCase}    & 0                  & 0                   & 0               & 0                \\
        \feature{\CVar}      & \feature{\id{b}}    & \feature{\CAlt}    & \feature{\CAlt}     & 0               & 0                \\
        \feature{\CLocal}    & \feature{\CDataAlt} & \feature{\CVar}    & \feature{\CDataAlt} & \feature{\CApp} & \feature{\id{n}} \\
        \feature{\id{a}}     & \feature{\id{Z}}    & \feature{\CGlobal} & \feature{\id{S}}    & \feature{\CVar} & \feature{\CVar}  \\
        \feature{\id{False}} & \feature{\CGlobal}  & \feature{\CLocal}  & 0                   & 0               & 0                \\
        \feature{\id{even}}  & \feature{\id{n}}    & 0                  & 0                   & 0               & 0
      \end{bmatrix}
    \end{equation*}
    \caption{Matrix generated from figure \ref{fig:rosetreeexample}, padded to 6 columns. Each level of sub-trees corresponds to a row in the matrix.}
    \label{fig:matrixexample}
  \end{subfigure}
  \vspace{1ex}
  \begin{subfigure}{\textwidth}
    \begin{equation*}
      (\feature{\CLam}, 0, 0, 0, 0, 0, \feature{\id{a}}, \feature{\CCase}, 0, 0, 0, 0, \feature{\CVar}, \feature{\id{b}}, \feature{\CAlt}, \feature{\CAlt}, 0, 0, \dots
     \end{equation*}
     \caption{(Prefix of) the feature vector for \hs{odd}, constructed by concatenating the rows of \ref{fig:matrixexample}. Ignoring padding, the features are in breadth-first order.}
     \label{fig:vectorexample}
  \end{subfigure}
  \caption{Feature extraction applied to the expression \hs{odd} from figure \ref{fig:coreexample}.}
\end{figure}

These rose trees are then turned into matrices, as shown in figure \ref{fig:matrixexample}, by gathering the features of adjacent (sub-) trees at each level of nesting using the following function:

\begin{equation*}
  level(l, (f, T_1, \dots, T_{n_T})) =
    \begin{cases}
      (f) & \text{if $l = 1$} \\
      \vect{x}_1 \vect{x}_2 \dots \vect{x}_{T_n} & \text{if $l > 1$, where $\vect{x}_i = level(l - 1, T_i)$}
    \end{cases}
\end{equation*}

Given a rose tree $t$ we can define its matrix $\mathbf{M}$ by $\mathbf{M}_i = pad(level(i, t), c)$, where $pad$ either truncates or appends zeros, until the row has length $c$. We also truncate/pad the number of rows to match a fixed number $r$. This way, all expressions give rise to $r \times c$ matrices, where the left-most features at each each level are aligned.

Feature vectors are then simply the concatenation of matrix rows $(\mathbf{M}_{1,1} \mathbf{M}_{1,2} \dots \mathbf{M}_{2,1} \mathbf{M}_{2,2} \dots)$, as shown in figure \ref{fig:vectorexample}.

\subsubsection{Symbols to Features}

\iffalse TODO: Maybe present recurrent clustering in a ``naive'' way: define the conversion function ``[]'' recursively. Leave the dependency-ordering, etc. for the Algorithm section, as a way of ``building up to'' the result, which avoids the inefficiencies of recursing. \fi

We now define the algorithm for $\feature{}$, which turns terminal symbols of Core syntax into features (real numbers). For known language features, such as $\feature{\CLam}$ and $\feature{\CCase}$, we can enumerate the possibilities and assign a value to each, in a similar way to \cite{DBLP:journals/corr/HerasK14} in Coq. We use a constant $\alpha$ to separate these values from those of other tokens (e.g. identifiers), but the order is essentially arbitrary: \footnote{In \cite{DBLP:journals/corr/HerasK14}, ``similar'' Gallina tokens like \coq{fix} and \coq{cofix} are grouped together to reduce redundancy; we do not group tokens, but we do put ``similar'' tokens close together, such as \CLocal\ and \CGlobal.}

\begin{align*}
  \feature{\CAlt}     &= \alpha      &
  \feature{\CDataAlt} &= \alpha + 1  &
  \feature{\CLitAlt}  &= \alpha + 2  \\
  \feature{\CDefault} &= \alpha + 3  &
  \feature{\CNonRec}  &= \alpha + 4  &
  \feature{\CRec}     &= \alpha + 5  \\
  \feature{\CBind}    &= \alpha + 6  &
  \feature{\CLet}     &= \alpha + 7  &
  \feature{\CCase}    &= \alpha + 8  \\
  \feature{\CLocal}   &= \alpha + 9  &
  \feature{\CGlobal}  &= \alpha + 10 &
  \feature{\CVar}     &= \alpha + 11 \\
  \feature{\CLam}     &= \alpha + 12 &
  \feature{\CApp}     &= \alpha + 13 &
  \feature{\CType}    &= \alpha + 14 \\
  \feature{\CLit}     &= \alpha + 15 &
  \feature{\CLitNum}  &= \alpha + 16 &
  \feature{\CLitStr}  &= \alpha + 17
\end{align*}

To encode \emph{local} identifiers $\mathcal{L}$ we use their $de Bruijn index$, since this is a numeric value suitable for use as a feature, and it gives equal values for $\alpha$-equivalent expressions. To calculate these indices the $toTree$ function maintains a \emph{context} as it recurses through expressions (we elided this from figure \ref{fig:totree} for clarity). The context is a list of the local identifiers which are in scope, beginning with an empty list for top-level Haskell declarations and prepending identifiers as they are introduced.

For example, when calculating $toTree(\CLam\ i\ e)$ in context $c$, we make the recursive call $toTree(e)$ in the context of \emph{$c$ prepended with $i$}. Similar extensions of the context are performed in the cases of \CBind, \CCase\footnote{The $\mathcal{L}$ value in a \CCase\ expression is bound to the expression being matched against; a technical detail to preserve sharing.}, \CAlt\ (which may introduce an arbitrary number of local identifiers) and \CLet\ (where identifiers are taken from occurrences of \CBind\ in the first expression).

Since well-formed Haskell declarations do not contain free variables, if we apply $toTree$ to the corresponding Core expression we are guaranteed that $l \in \mathcal{L}$ will appear in the context whenever we encounter $\feature{l}$. \iffalse NOTE: Can we prove this, or would it just be an exercise in formalising Haskell? \fi In which case we define:

$$\feature{l} = i + 2 \alpha$$

Where $i$ is the de Bruijn index of $l$ (the index of the first occurrence of $l$ in the context), and we again use $\alpha$ to separate these features from those of other constructs.

Since the $toTree$ function discards the particular values of numerals and strings, the only remaining case is global identifiers $\mathcal{G}$. Since these are declared \emph{outside} the body of an expression, we cannot perform the same indexing trick as we did for local identifiers. We also cannot directly encode the form of the identifiers, e.g. using a scheme like G{\"o}del numbering, since this is essentially arbitrary and has no effect on their semantic meaning (referencing other expressions).

Instead, we encode global identifiers \emph{indirectly}, by looking up the expressions which they \emph{reference}. For $g \in \mathcal{G}$ we define $\feature{g}$ as the \emph{index of the cluster which $g$ appears in}. This is where the recurrent nature of the algorithm appears, since we perform k-means clustering \emph{during} feature extraction, and that clustering step, in turn, requires that we perform feature extraction.

For this recursive process to be well-founded, we impose a topological ordering on declarations based on their dependencies (the expressions they reference). This is slightly complicated in Haskell (compared to Coq, for example), since general recursion is permitted and several mutually-recursive expressions may appear at the same level in the ordering. Rather than following such cyclic references forever, references which point to the same level in the ordering (including self-references) get a constant feature value $r$.

By working through a list of declarations $d$ in dependency order, storing the features of each top-level expression as they are calculated, our algorithm can be computed \emph{iteratively} rather than recursively, as shown in figure . Any global identifier which has not been encountered yet must be a mutual- or self-reference.


\begin{algorithm}
  \begin{algorithmic}[1]
    \Require List $d$ of (identifier, expression) pairs, in dependency order
    \Procedure{RecurrentCluster}{}
      \State $C  \gets []$
      \State $DB \gets \varnothing$
      \ForAll{$(i, e)$ \textbf{in} $d$}
        \State $DB \gets DB \cup \{(i, featureVec(e))\}$
        \State $C  \gets kMeans(DB)$
      \EndFor
      \Return $C$
    \EndProcedure
  \end{algorithmic}
  \caption{Recurrent clustering of Core expressions. $d$, $C$ and $DB$ are lists.}\label{alg:recurrent}
\end{algorithm}

For example, from their definitions in figure \ref{fig:coreexample} we might consider \hs{odd} to be more similar to \hs{even} than to \hs{plus}, and hence for $\feature{\id{odd}}$ to be more similar to $\feature{\id{even}}$ than to $\feature{\id{plus}}$. In this sense, exact equality will under-estimate the similarity of $\feature{\id{odd}}$ and $\feature{\id{even}}$, whilst ignoring all differences between identifiers will over-estimate the similarity of $\feature{\id{odd}}$ and $\feature{\id{plus}}$.


\iffalse TODO: the code should go in the implementation section rather than here \fi
\iffalse TODO: maybe focus on the ``interesting cases'', and defer the nitty-gritty of extending the environment, etc. to the implementation section? \fi
\iffalse TODO: Split into three parts: expressions to rose trees of features; rose trees to matrices to vectors; k-means clustering \fi
\iffalse TODO: highlight the recurrent nature of the algorithm \fi
\iffalse TODO: I would probably just restructure:
 - then k-means
obviously, they are mutually recursive...
\fi

Our algorithm proceeds in several stages. At the top level, we send named expressions to \hs{recurrentCluster}, topologically sorted: if an element contains multiple \hs{(Global, Expr)} pairs, they are mutually-recursive:

\begin{haskell}
recurrentCluster :: [[(Global, Expr)]] -> [[Global]]
recurrentCluster = go ([],[])
  where go (fs, db) []       = db
        go (fs, db) (es:ess) = let fs' = fs ++ map (extract db) es
                                   db' = kMeans fs'
                                in go (fs', db') ess
        extract db (i, e) = (i, rt db e)
\end{haskell}

The overall result of the \hs{recurrentCluster} function is a list of clusters, containing the IDs of their elements. These are obtained by interleaving clustering (the \hs{kMeans} function) and feature extraction (the \hs{rt} function).

The feature extraction itself contains two parts: first, syntax trees matching the grammar in figure \ref{fig:coresyntax} are converted into \hs{RoseTree}s with features (\hs{Float}s) on their \hs{Node}s:

\begin{haskell}
data RoseTree = Node Feature [RoseTree]

eRT :: [Local] -> [[Global]] -> Expr -> RoseTree
eRT env db e = case e of
  ...
\end{haskell}

The easiest branches to handle are literals and types, which we represent using particular feature values (\hs{sLITNUM}, \hs{sLITSTR} and \hs{sTYPE}):

\begin{haskell}
  Lit (LitNum _) -> Node sLITNUM []
  Lit (LitStr _) -> Node sLITSTR []
  Type           -> Node sTYPE   []
\end{haskell}

Function application simply recurses into both sub-expressions:

\begin{haskell}
  App e1 e2 -> Node sAPP [eRT env db e1,
                          eRT env db e2]
\end{haskell}

To look up variables locally and globally, we use the \hs{lookupL} and \hs{lookupG} functions, respectively. These return the index containing their argument, if found. In the case of \hs{lookupL}, this acts as a de Bruijn index to give alpha-equivalent terms equal feature vectors. For \hs{lookupG}, this is the ID of the cluster it appears in; this ensures that references to similar expressions result in similar features:

\begin{haskell}
  Var (Global i) -> Node (lookupG db  i) []
  Var (Local  i) -> Node (lookupL env i) []
\end{haskell}

Finally, when we traverse binders we must extend the environment \hs{env}:

\begin{haskell}
  Lam  i  e     -> Node sLAM [eRT (i:env) db e]
  Let  bs e     -> Node sLET (map (bRT (ids bs:env) db) bs ++
                                   eRT (ids bs:env) db  e
  Case e i alts -> Node sCASE (eRT    env  db  e :
                          map (aRT (i:env) db) alts)
\end{haskell}

Patterns and bindings are handled in a similar way:

\begin{haskell}
aRT :: [Local] -> [[Global]] -> Alt -> RoseTree
aRT env db alt = case alt of
  (DataAlt _, vs, e) -> eRT (vs ++ env) db e
  (LitAlt  _, _,  e) -> eRT env db e
  (Default,   _,  e) -> eRT env db e

bRT :: [Local] -> [[Global]] -> Bind -> RoseTree
bRT env db b = case b of
  NonRec i e -> eRT env db e
  Rec es     -> Node sREC (map (eRT env db . snd) es)
\end{haskell}

The result of \hs{eRT} is a \hs{RoseTree} whose branching structure mimics that of our original expression. We next need to convert this to a \emph{matrix} of features, which we do by converting each level of the \hs{RoseTree} into a row of the matrix (using \hs{pad} to ensure a consistent size). Finally we turn the matrix into a \emph{feature vector} by concatenating the rows:

\begin{haskell}
level :: Int -> RoseTree -> [Feature]
level 0 (Node x xs) = [x]
level n (Node x xs) = concatMap (level (n-1)) xs

rt :: [[Global]] -> Expr -> [Feature]
rt db e = concat (pad cols (map (`level` eRT [] db e) [0..rows]))
\end{haskell}

Notice that this algorithm contains several parameters, including \hs{rows} and \hs{cols} which determine how to truncate the matrices (defaults are 30). The \hs{kMeans} function also contains a parameter for the cluster number; we set this as $\sqrt{n}$ where $n$ is the number of feature vectors being clustered.

\subsubsection{Comparison}

Our algorithm is most similar to that of ML4PG, as our transformation maps each element in a tree to a distinct cell in its matrix. In contrast, the matrices produced by ACL2(ml) \emph{summarise} the tree elements: providing, for each level of the tree, the number of variables, nullary symbols, unary symbols, etc.

There are two major differences between our algorithm and that of ML4PG: mutual-recursion and types.

The special handling required for mutual recursion is discussed above (namely, topological sorting of expressions and the \hs{sUNKNOWN} sentinel). Such handling is not present in ML4PG, since the Coq code it analyses must, by virtue of the language, be written in dependency order to begin with. Coq \emph{does} have limited support for mutually-recursive functions, of the following form:

\begin{coqblock}
Fixpoint even n := match n with
                       | O   => true
                       | S m => odd m
                   end
    with odd  n := match n with
                       | O   => false
                       | S m => even m
                   end.
\end{coqblock}

However, this is relatively uncommon and unsupported by ML4PG.

The more interesting differences come from our handling (or lack thereof) for types. Coq and ACL2 are at opposite ends of the typing spectrum, with the former treating types as first class entities of the language whilst the latter is untyped (or \emph{unityped}). In both cases, we have a \emph{single} language to analyse, by ML4PG and ACL2(ml) respectively.\footnote{ML4PG can also analyse Coq's \textsc{Ltac} meta-language. Haskell has its own meta-language, Template Haskell, but here we only consider the regular Haskell which it generates.}

The situation is different for Haskell, where the type level is distinct from the value level, and there are strict rules for how they can influence each other. In particular, Haskell values can depend on types (via the type class mechanism) but types cannot depend on values.

In our initial approach, we restrict ourselves to the value level. This has several consequences:

\begin{itemize}
  \item Although they are values, we cannot distinguish between data constructors, other than using exact equality.
  \item Since Core uses a single \texttt{Lam} abstraction for both value- and type-level parameters, we cannot always distinguish between them. This can cause a function's Core arity to be greater than its Haskell arity.
\end{itemize}

There is certainly promise in including types in our analysis, by pairing every term with its type as in ML4PG. This will allow fine-grained distinction of expressions which are otherwise identical, especially data constructors.
