\section{Contributions}
\label{sec:contributions}

\subsection{Recurrent Clustering}
\label{sec:recurrentclustering}

We take the \emph{recurrent clustering} approach found in ML4PG and ACL2(ml), and implement a variant in the context of Haskell theory exploration. Here we give a brief description of recurrent clustering, describe our algorithm, and compare its similarity and differences to ML4PG and ACL2(ml).

\subsubsection{Overview}

The purpose of recurrent clustering, as with other clustering algorithms, is to identify similarities between a set of inputs. In our case, we want compare the abstract syntax trees of Core expressions, which presents a difficulty for clustering: many leaves are \emph{references}, containing identifiers for other expressions. For example, consider the following expressions which are identical except for an identifier:\footnote{The \texttt{(\&\&)} function is boolean AND, \texttt{(++)} appends lists and \texttt{map} applies a function to the elements of a list.}

\begin{equation*}
  \begin{split}
    X =\ & \texttt{App}\ (\texttt{Var}\ (\texttt{Local}\ \texttt{"f"}))\ (\texttt{Var}\ (\texttt{Global}\ \texttt{"base:Prelude.(\&\&)"})) \\
    Y =\ & \texttt{App}\ (\texttt{Var}\ (\texttt{Local}\ \texttt{"f"}))\ (\texttt{Var}\ (\texttt{Global}\ \texttt{"base:Prelude.(++)"})) \\
    Z =\ & \texttt{App}\ (\texttt{Var}\ (\texttt{Local}\ \texttt{"f"}))\ (\texttt{Var}\ (\texttt{Global}\ \texttt{"base:Prelude.map"}))
  \end{split}
\end{equation*}

Two simple methods for comparison are to ignore identifiers completely, or to compare them for equality. Neither is completely satisfactory, as the former will \emph{over-estimate} similarity (considering $X$, $Y$ and $Z$ to be the same), whilst the latter will \emph{under-estimate} similarity (considering $X$, $Y$ and $Z$ to be equidistant).

Ideally we would like something in between these two extremes, which requires a more sophisticated notion of similarity for identifiers. In the above example, we may intuitively consider \texttt{(\&\&)} and \texttt{(++)} to be closer to each other than to \texttt{map}; both in terms of \emph{definition} (e.g. only the former can be specified by pattern-matching on their first argument), and by their \emph{properties} (e.g. only the former can form monoids).

Recurrent clustering tackles this problem in a straightforward way: we look up the expressions \emph{referenced by} each identifier, and use \emph{their} similarity in place of the identifiers'. This gives rise to a recursive process, where feature extraction is interleaved with multiple rounds of clustering. For this recursive process to be well-founded, we impose a topological ordering on expressions based on their dependencies (the expressions they reference). This is slightly complicated in Haskell (compared to Coq, for example), since general recursion is permitted and several mutually-recursive expressions may appear at the same level.

\subsubsection{Algorithm}
\label{sec:algorithm}

\begin{figure}
  \begin{lstlisting}[language=Haskell, xleftmargin=.1\textwidth, xrightmargin=.1\textwidth]
    data RoseTree a = Node a [RoseTree a]

    eRT :: [Local] -> [[Global]] -> Expr -> RoseTree Feature
    eRT env db e = case e of
      Var (Global i) -> Node (lookupG db  i) []
      Var (Local  i) -> Node (lookupL env i) []
      Lit (LitNum _) -> Node sLITNUM []
      Lit (LitStr _) -> Node sLITSTR []
      Lam  i  e      -> Node sLAM [eRT (i:env) db e]
      App  e1 e2     -> Node sAPP [eRT    env  db e1,
                                   eRT    env  db e2]
      Let  bs e      -> Node sLET (map (bRT (ids bs:env) db) bs ++
                                        eRT (ids bs:env) db  e
      Case e i alts  -> Node sCASE (eRT    env  db  e :
                               map (aRT (i:env) db) alts)

    aRT :: [Local] -> [[Global]] -> Alt -> RoseTree Feature
    aRT env db alt = case alt of
      (DataAlt _, vs, e) -> eRT (vs ++ env) db e
      (LitAlt  _, _,  e) -> eRT env db e
      (Default,   _,  e) -> eRT env db e

    bRT :: [Local] -> [[Global]] -> Bind -> RoseTree Feature
    bRT env db b = case b of
      NonRec i e -> eRT env db e
      Rec es     -> Node sREC (map (eRT env db . snd) es)

    level :: Int -> RoseTree Feature -> [Feature]
    level 0 (Node x xs) = [x]
    level n (Node x xs) = concatMap (level (n-1)) xs

    rt :: [[Global]] -> Expr -> [Feature]
    rt db e = concat (pad cols (map (`level` eRT [] db e) [0..rows]))

    recurrentCluster :: [[(Global, Expr)]] -> [[Global]]
    recurrentCluster = go ([],[])
      where go (fs, db) []       = db
            go (fs, db) (es:ess) = let fs' = fs ++ map (extract db) es
                                       db' = kMeans fs'
                                    in go (fs', db') ess
            extract db (i, e) = (i, rt db e)
  \end{lstlisting}
  \caption{Feature extraction for Haskell Core. We send named expressions to \hs{recurrentCluster}, topologically sorted: if an element contains multiple \hs{(Global, Expr)} pairs, they are mutually-recursive. Syntax trees are first converted into \hs{RoseTree}s of \hs{Feature}s, these trees are converted to matrices, then flattened into feature vectors, then \hs{kMeans} clusters the feature vectors. The result is a list of clusters, naming their elements. More details are given in \S \ref{sec:algorithm}.}
  \label{fig:featureextractionalgorithm}
\end{figure}

Our feature extraction algorithm is given in figure \ref{fig:featureextractionalgorithm}. Here we highlight some key features:

\begin{itemize}
  \item Since they are comparatively rare, we ignore the particular value of each literal.
  \item Since we are currently focused on expressions, we ignore particular data constructors and types.
  \item The \hs{lookupL} and \hs{lookupG} functions return the index containing their argument, if found. In the case of \hs{lookupL}, this acts as a de Bruijn index to give alpha-equivalent terms equal feature vectors. For \hs{lookupG}, this is the ID of the cluster it appears in; this ensures that references to similar expressions result in similar features.
  \item \hs{lookupL} and \hs{lookupG} return a sentinel value \hs{sUNKNOWN} if the given ID is not found. In practice, this only occurs for global, mutually-recursive references, since the toplogical sort will populate the \hs{db} with all other global identifiers, and local identifiers which don't occur in the environment would be rejected as invalid Haskell before the translation to Core.
  \item The \hs{Feature} type is abstract, but in practice it will be \hs{Float}.
  \item Our algorithm contains several parameters, including \hs{rows} and \hs{cols} which determine how to truncate the matrices (defaults are 30). The \hs{kMeans} function also contains a parameter for the cluster number; we set this as $\sqrt{n}$ where $n$ is the number of feature vectors being clustered.
\end{itemize}

\subsubsection{Comparison}

Our algorithm is most similar to that of ML4PG, as our transformation maps each element in a tree to a distinct cell in its matrix. In contrast, the matrices produced by ACL2(ml) \emph{summarise} the tree elements: providing, for each level of the tree, the number of variables, nullary symbols, unary symbols, etc.

There are two major differences between our algorithm and that of ML4PG: mutual-recursion and types.

The special handling required for mutual recursion is discussed above (namely, topological sorting of expressions and the \hs{sUNKNOWN} sentinel). Such handling is not present in ML4PG, since the Coq code it analyses must, by virtue of the language, be written in dependency order to begin with. Coq \emph{does} have limited support for mutually-recursive functions, of the following form:

\begin{coqblock}
Fixpoint even n := match n with
                       | O   => true
                       | S m => odd m
                   end
    with odd  n := match n with
                       | O   => false
                       | S m => even m
                   end.
\end{coqblock}

However, this is relatively uncommon and unsupported by ML4PG.

The more interesting differences come from our handling (or lack thereof) for types. Coq and ACL2 are at opposite ends of the typing spectrum, with the former treating types as first class entities of the language whilst the latter is untyped (or \emph{unityped}). In both cases, we have a \emph{single} language to analyse, by ML4PG and ACL2(ml) respectively.\footnote{ML4PG can also analyse Coq's \textsc{Ltac} meta-language. Haskell has its own meta-language, Template Haskell, but here we only consider the regular Haskell which it generates.}

The situation is different for Haskell, where the type level is distinct from the value level, and there are strict rules for how they can influence each other. In particular, Haskell values can depend on types (via the type class mechanism) but types cannot depend on values.

In our initial approach, we restrict ourselves to the value level. This has several consequences:

\begin{itemize}
  \item Although they are values, we cannot distinguish between data constructors, other than using exact equality.
  \item Since Core uses a single \texttt{Lam} abstraction for both value- and type-level parameters, we cannot completely erase type-level parameters unless they are fully applied. This can cause a function's Core arity to be greater than its Haskell arity.
\end{itemize}

There is certainly promise in including types in our analysis, by pairing every term with its type as in ML4PG. This will allow fine-grained distinction of expressions which are otherwise identical, especially data constructors.
