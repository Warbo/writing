% This file is iccc.tex.  It contains the formatting instructions for and acts as a template for submissions to ICCC.  It borrows liberally from the AAAI and IJCAI formats and instructions.  It uses the files iccc.sty, iccc.bst and iccc.bib, the first two of which also borrow liberally from the same sources.


\documentclass[letterpaper]{article}
\usepackage{iccc}


\usepackage{times}
\usepackage{helvet}
\usepackage{courier}
\pdfinfo{
/Title (Applying CC to scientific domains)
/Subject (Proceedings of ICCC)
/Author (ICCC)}
% The file iccc.sty is the style file for ICCC proceedings.
%
\title{The importance of applying computational creativity\\ to
  scientific and mathematical domains\\
Position Paper}
%\author{Alison Pease, Simon Colton, Chris Warburton, Athanasios Nathanail, Irina Preda, \\
%  Daniel Arnold, Daniel Winterstein, Mike Cook}

\setcounter{secnumdepth}{0}

\begin{document}
\maketitle
\begin{abstract}
\begin{quote}
  Science and mathematics are currently vastly under-represented in
  the computational creativity (CC) community. This is at best a
  wasted opportunity, and at worst a significant problem for
  computational creativity. We discuss why the CC community should
  apply their work to scientific and mathematical domains, and argue
  that this would be mutually beneficial for the domains in question,
  demonstrating our position throughout the paper by reference to
  mathematics and geology. We propose a research programme for
  building closer relationships between CC and the scientific
  community, focusing on understandability of science and the role
  that AI is currently playing in scientific research.
\end{quote}
\end{abstract}

\section{Introduction}

Despite the best efforts of successive ICCC organising committees and
the computational creativity (CC) community, CC has always attracted
substantially more interest from researchers in artistic than
scientific and mathematical domains. In their 2017 study of
application domains in CC, \cite{loughran17} found that, of 16
categories, papers on Maths, Science and Logic accounted for only 3\%
of the 353 papers on CC across 12 years. Of course, some work is
domain independent, or at least not easily assigned to an academic
discipline, such as the body of work on CC and curiosity (for instance
\cite{grace}). Even taking this into account, it is clear that science
and mathematics are vastly under-represented in our community.

There are potentially many reasons why this may be the case. Firstly,
AI researchers in scientific domains may well be doing
creativity-related work in other contexts but not engaging with the CC
community. Automated reasoning and automated scientific discovery are
both thriving subfields of AI, with internationally recognised
journals as outlets for publication and engagement; certainly these
will contain work relevant to our field but couched in different
terminology with different methodologies. Secondly, it may be that
other, practical, priorities in scientific domains have led to a focus
on techniques such as search, data-mining and automated
deduction. Since these generate results of interest to domain experts,
the more difficult, fluid and tenuous concept of creativity may be
seen as unnecessary, risky or simply not a priority. This may
particularly be the case given the various ``AI winters'' in the
twentieth century (the second of which ended in 1993, just six years
before the first workshop on CC), and the need for AI to ``prove
itself''. Thirdly, CC researchers may consider that even if generation
is possible within scientific domains, evaluation is too
difficult. How we should evaluate our work and our systems has always
been a contentious -- albeit important -- issue in CC, with few
proposed evaluation metrics and the majority of researchers still
arguing for value along the lines of ``we/people liked the system's
output'' or ``we/people couldn't distinguish the system's output from
human produced work''. It might be the case that in science, the main
evaluation metric -- ``is it true?'', or ``does it work?'' -- is
considered simply too expensive or difficult to demonstrate.

We argue here that neglecting scientific and mathematics domains in CC
is at best a wasted opportunity, and at worst a significant problem
for CC. While computationally-produced work in the arts is currently
novel, this {\em may} have a limited lifespan. We call this the {\em
  Saturation Problem}. In ten or twenty years, people may ask
themselves whether we still want more computer-generated paintings or
poems. There may or may not be a good answer to this. The question as
to whether we still want more computer-generated science or
mathematics, however, seems less likely to be asked: we {\em always}
want more science and mathematics. We believe that it is essential to
the health of our field that we reach out as a community at this
stage, both to domain experts in science and maths and to those in
related AI areas. The benefits of doing so will go both ways. As AI is
used more and more in science, there is greater dependence on blackbox
machine learning systems. While providing greater predictive power,
this often comes at the cost of understanding. We call this the {\em
  Understandability Problem} and argue that it will become a big issue
in science, which we will have to address.  Twenty years of thinking
about computational creativity has provided us with valuable tools for
thinking about these problems. This paper is a call to arms to CC
researchers to apply their work to science, thus solving both the
saturation problem and the understandability problem.

Loughran and O'Neill argue that ``tackling scientific, logical or
realistic issues could help bring the reputation of CC away from a
purely aesthetic domain towards developing solutions for real world
problems.'' \cite[p.7]{loughran17} and that ``It is imperative that
the field remains balanced as it grows and that we remember to reflect
on all areas of growth.'' [{\em Ibid.}]. In this paper we support and
present further arguments for this position, alongside practical
recommendations for doing so.


% We start by looking at work in related fields, arguing that in fact CC
% research {\em is} being carried out in science and maths, but under
% different umbrellas, with different terminologies and priorities.  We
% then argue both that it is imperative for the CC community to apply
% their work to scientific and mathematical domains, and that this would
% be beneficial for the domains in question. We conclude by proposing a
% research programme for doing so, using examples from mathematics and
% geology throughout. We conclude by proposing a research programme for
% doing so, using examples from mathematics and geology throughout.


\section{What is science?}\label{science}
%\subsection{what is science?}
The concept of science is not a straightforward one. The division of
the origins of learning and systematic production of new knowledge
into disciplines as we know them tends to takes into account at least
some of the following: methodologies, objects of study (which can be
shared with other disciplines), a body of accumulated knowledge (which
is generally not shared with other disciplines), theories and
concepts, terminology and an institutional manifesto (so that it can
reproduce itself) \cite[p9]{krishnan2009academic}. Sciences include
{\em Natural sciences}, which are subdivided into {\em physical
  sciences} (chemistry, physics, astronomy), {\em life sciences}, or
biology (zoology, botany, ecology, genetics) and {\em earth science}
(geology, oceanography, meteorology, palaeontology); {\em Social
  sciences} (psychology, sociology, economics, law, political
science); {\em Formal sciences} (mathematics, logic, theoretical
computer science, statistics); and {\em Applied sciences}, which are
subdivided into {\em engineering} (computer science, civil
engineering, electrical engineering, mechanical engineering); {\em
  health sciences} (medicine, dentistry, pharmacy) and {\em
  agriculture}. The number and variety of sciences makes
generalisations difficult, and core values vary accordingly.  However,
values commonly associated in particular with the (rather unhelpfully
named) ``hard sciences'' include repeatability, reproducibility,
predictability, generality and understandability. This last value is
particularly cherished: for instance, Roger G. Newton sums it up as
``The primary aim of most physical scientists is to understand and
explain the workings of Nature.''  \cite[p. 4]{newton:2000}.


%\subsection{What are the arts?}

The arts are just as difficult to define.  These are sometimes divided
into the ``seven arts'': Architecture, Sculpture, Painting,
Literature, Music, Performing, and Film.\footnote{A visualisation of
  the fields of knowledge based on Wikipedia's list of academic
  disciplines and sub-disciplines can be found here:
  http://www.thingsmadethinkable.com/item/fields\_of\_knowledge.php}
Julie Van Camp, writing in the context of United States Congressional
policy on arts education, provides the following extensional
definition:

\begin{quote}
  The term `the arts' includes, but is not limited to, music
  (instrumental and vocal), dance, drama, folk art, creative writing,
  architecture and allied fields, painting, sculpture, photography,
  graphic and craft arts, industrial design, costume and fashion
  design, motion pictures, television, radio, film, video, tape and
  sound recording, the arts related to the presentation, performance,
  execution, and exhibition of such major art forms, all those
  traditional arts practiced by the diverse peoples of this
  country. ({\em sic}) and the study and application of the arts to
  the human
  environment.\footnote{http://web.csulb.edu/~jvancamp/361\_r8.html}
\end{quote}


%\subsection{Connection between the sciences and the arts}

%\subsection{Traditional boundaries might not serve us}

\begin{table}
\begin{center}
 \begin{tabular}{||l c c ||}
 \hline
 & {\bf Science} & {\bf Arts} \\[0.5ex]
 \hline\hline
{\em Aesthetic:} & truth & beauty \\ \hline

{\em Approach:} & problem-driven & artefact-driven \\ \hline

{\em Task:} & analytic & generative \\ \hline

{\em Terminology:} & discover & create \\ \hline

{\em Status:} & objective & subjective \\ \hline

{\em Goal:} & knowledge & self-expression \\ \hline

 \end{tabular} \caption{Possible differences between the sciences and the arts}
\end{center}
\label{Table:differences}
\end{table}

As a starting point -- generalising (and controversially) -- we could
suggest some of the differences between the sciences and the arts as
shown in Table 1. Of course, the real-world everyday lived experience
of {\em doing} science or {\em doing} art is far more complex than
Table 1 would suggest. Studies of interpretations of seismic data in
geology, for instance, show the large number of different expert
interpretations of the same seismic section, highlighting the
subjectivity involved \cite{bond}. These interpretations are used to
analyse subsurface geology, and form the basis for many exploration
and extraction decisions. Even in cases where interpreters report that
an interpretation is relatively straightforward, there are significant
differences in interpretation, leading to significantly different
predictions, for instance about gross pore volume in a pool or gross
rock volume \cite{rankey}. While clearly objectivity is the goal here,
such studies may suggest that this aspect of geological practice is
closer to visual art interpretation than it is to some other
scientific domains. Similarly, studies of the back stage production of
mathematics show that beauty is often a guiding value
\cite{inglis:15}; there is a high level of disagreement amongst
experts about the validity of certain proofs \cite{inglis}; and proofs
and theories are often considered to be constructed rather than
discovered \cite{lakatos}. Less structured knowledge such as our
ability to reason logically has been shown to be highly context
dependent (for instance, participants in the Wason Selection Task were
unable to solve a problem at an abstract level but could solve it
correctly when it was framed in a familiar context \cite{wason});
constructing grounding metaphors to the physical world and abstract
linking metaphors found to be fundamental to our understanding and
construction of mathematical knowledge \cite{Lak00}; and even the
language in which reasoning occurs affecting our preconceptions,
perceptions and assumptions \cite{dehaene,barton}.

Dibbets expresses the relationship between arts and sciences well:
\begin{quote}
  But in the end, we all do very much of the same. All scientists,
  artists, composers and writers are intensively occupied imagining
  something that does not yet exist. They find themselves at the
  borders of areas where up to then hardly anyone found himself,
  trying to solve problems that are incomprehensible to others, trying
  to answer questions no one has ever asked. Here, they share a vision
  on things that are not yet real. \cite[p. 1]{dibbets}
\end{quote}
Some of these interdisciplinary features are recognised in curriculum
design and teaching featuring transferable skills, in which one skill
may be learned within a scientific context and developed or employed
in an arts context, or vice versa (see for instance \cite{gaff}).
Indeed, the STEM to STEAM movement (expanding the acronym Science,
Technology, Engineering, and Mathematical disciplines to include Art)
explores the role of arts integration, collaboration, and experience
centered learning in knowledge creation \cite{ghanbari}. Of course,
the need for so many interdisciplinary initiatives (and related
concepts such as transdisciplinarity, pluridisciplinarity, and
multidisciplinarity) may suggest that some traditional discipline
boundaries are no longer drawn in a helpful way. The evolving role and
functionality of AI systems further complicates things. The focus of
AI researchers, particularly in machine learning, is often on the
skills they hope to simulate rather than a particular domain in which
they are usually employed. This may be more a more productive approach
than the typical CC focus on domain over skill.


%1-3, programme chairs should design the call for papers with these in
%mind, collaborators in scientific domains should be invited as keynote
%speakers, workshops on science should be co-located with
%ICCC.... programmes should be themed around skill rather than domain,
%[ Common themes include linguistic, music, visual arts, etc,
%creativity, with science/mathematical creativity lumped into a single
%theme if that.  ]




\section{The Saturation Problem in Computational Creativity}

The saturation problem in CC is potentially an identity problem for
us. Recent developments in other areas of AI -- principally machine
learning (ML) -- have led to astonishingly rapid progress in
generative processes.  Research in Constructive Machine Learning has
led to impressive generative results in both the arts and sciences,
including painting, music, poetry, gaming, drug design, and gene
design -- usually in collaboration with domain experts. Our concern is
that the sheer size and combined resources of the ML community may
render generative work in CC untenable.

CC has long been seen as more than ``mere generation''\footnote{The
  slogan at the 2012 ICCC conference was ``scoffing at mere generation
  for more than a decade.'' - although this has been challenged, for
  instance by \cite{ventura})}, with many other aspects of the
creative act modelled, in particular aesthetic judgements, but also
(more controversially) the importance of framing information and
meta-level processes. As generative results in other areas of AI
become more sophisticated, we may need to focus on these other aspects
of the creative act. However, even with this in mind, we are concerned
that the arts domains {\em may} reach a saturation point for CC: as
the novelty and backstory of computer-generated art grows old, society
may question whether and why we want more computer-produced artistic
artefacts. In order to keep the field alive, we propose that as well
as focusing on other aspects of creativity, we find other application
domains.


\section{The Understandability Problem in Science}
Roger Newton's quote above about the primary aim of physical
scientists being to understand and explain nature is uncontroversial,
but difficult to unpack. Ever since the entirety of our collective
scientific knowledge became too big for a single polymath to
comprehend, we have had to outsource our understanding to others. The
institutionalised ways in which trust of others' understanding and
progress is handled started with the early universities, and developed
with the invention of the printing press, academic journals, the peer
review process and so on. Knowledge and understanding is a social
process, as argued in \cite{martin:2013}, but even in the human-only
case this gets complicated. The longest proof in history, of the
Classification of finite simple groups, is over 10,000 pages, spread
across 500 or so journal articles, by over 100 different authors from
around the world, and took 110 years to complete. What does
understanding mean here? Perhaps a handful of people understand the
proof in its entirety, and when they die it is not obvious that any
single person will ever again understand the entire proof (in part
because it may be replaced with a simpler proof).

Shinichi Mochizuki's 500-page proof in 2012 of the abc conjecture
provides another perspective on the importance of understanding in
mathematics. The abc conjecture, proposed in 1985, on relationships
between prime numbers, is considered to be one of the most important
conjectures in number theory (more significant than Fermat’s Last
Theorem -- in fact Fermat’s Last Theorem would be a corollary of the
proof). A proof would be ``one of the most astounding achievements of
mathematics of the twenty-first century.''  [Goldfeld, in
\cite{ball:12}]. Mochizuki has a good track record as a
mathematician, having proved ``extremely deep'' theorems in the past
[Conrad in \cite{ball:12}]. The problem is that the techniques and
mathematical objects which Mochizuki has developed to use in his proof
are so strange and new that it would take a reviewer or mathematical
colleague most of their career to understand them, before they were
able to understand and verify the proof. Despite some efforts from
Mochizuki and a handful of his followers to make his work accessible,
currently his proof is neither published nor accepted by mainstream
mathematicians, for the simple reason that they don't understand
it.


Crowd-sourced mathematics, in which open conjectures are solved
collaboratively via online fora (amongst other things), has been used
for around ten years now by a subset of the mathematical community as
a new way of producing mathematics through collaboration and sharing
\cite{massively-collaborative}. Neilsen argues that this has resulted
in ``amplifying collective intelligence'' in his book {\em Reinventing
  Discovery} \cite{nielsen}. It has certainly resulted in some
original and significant new proofs. Here it is perfectly possible (in
fact it would be surprising if it were not the case) for a person to
be a co-author but not fully understand the proof in their
paper.

Adding computers to the social process, to form a combination of
people, computers, and mathematical archives to create and apply
mathematics -- a ``mathematics social machine'' \cite{martin:2013} --
further complicates matters. Take \emph{automated theorem proving}, the
task of deciding whether a given formal statement follows from a given
set of premises ~\cite{sutcliffe2001evaluating}.  The least
informative approaches, algorithms based on the \emph{resolution}
rule~\cite{robinson1965machine}, produce merely a ``yes'', ``no'' or
``unknown'' response. Not only is this devoid of \emph{explanation},
but it also hides the effects of any bugs; requiring the user to
either trust the results, or verify the implementation.

This can be mitigated by having the system instead
generate a \emph{proof object}: a formal argument for \emph{why} a
given statement follows or does not follow. Once generated, a proof
object's validity can be checked without requiring any knowledge of
how it was created, thus avoiding the need to trust or verify the
(potentially complicated) search and generation procedures. Theorem provers
which produce proof objects that are trivial to check by independent
\emph{proof checker} programs (which are themselves
easily verified, due to their simplicity) satisfy the
\emph{de Bruijn criterion}~\cite{barendregt2005challenge}; examples are
Coq~\cite{barras1997coq} and Isabelle/HOL~\cite{nipkow2002isabelle}.

Proof objects are not a complete solution to understandability, since
they can still be quite inscrutable to human users. This often depends
on how closely the chosen formal system is able to encode the user's
ideas: for example, the formal proof of the Kepler Conjecture was
performed using a system of Higher Order Logic
(HOL)~\cite{hales2015formal} whose proof objects (natural-deduction
style derivations), whilst tedious, are in principle understandable to
a user experienced with both the software and problem domain. The same
cannot be said of the Boolean Pythagorean Triples problem, a statement
of Ramsey theory involving the structure of the natural
numbers. Rather than taking a high-level approach like HOL, the
authors of~\cite{heule2016solving} analysed sets $\{0..n\}$ for larger
and larger $n$, encoding these restricted versions of the problem into
the language of boolean satisfiability (SAT), and found that the
problem is unsatisfiable for $n= 7825$, and hence for the natural
numbers as a whole. In this case, the proof object demonstrates this
unsatisfiability using 200 terabytes of propositional logic clauses
(compressable to 68 gigabytes).  Not only is this far too much for any
human to comprehend, but the concepts used in the proof (boolean
formulae) are several layers removed from the actual problem statement
(natural numbers, subsets and pythagorean triples).

Whilst ``low level'' formalisms like SAT are less understandable or
explanatory for users, they are far more amenable to automation than
more expressive logics.  Despite the proof for the Boolean Pythagorean
Triples problem being many orders of magnitude larger than that of the
Kepler Conjecture, the latter is well beyond the ability of today's
automated theorem provers due to its encoding in HOL. Instead, it took
22 collaborators 9 years just to formalise the proof (Hales had
previously produced a less formal proof, hundreds of pages long and
accompanied by unverified software; yet another reminder that
human-generated artefacts are not necessarily understandable either).

The situation is even worse in automated scientific discovery. The
widespread use of \emph{machine learning} (ML) to find patterns in
scientific data has been criticised by Genevera Allen in her recent
talk at the 2019 Annual Meeting of the American Association for the
Advancement of Science
(AAAS)\footnote{https://eurekalert.org/pub\_releases/2019-02/ru-cwt021119.php}. She
highlighted accuracy and reproducibility issues with scientific
discoveries made by machine-learning techniques. Understandability is
another huge problem with such discoveries; often with a tradeoff
between the generality of an approach and how easily its resulting
behaviour can be understood. The understandability problem concerns
this last issue.


\section{Proposed solutions}
Here we propose three different approaches that the CC community can
take to address the understandability problem.  Each approach, at the
same time, would solve the saturation problem, by focusing on
science. We end each subsection with a concrete recommendation towards
a new Research Programme in CC.

\subsection{The ``human-like computing'' approach}

{\em Human-like computing} research is a research programme developed
for a UK funding initiative by the Engineering and Physical Sciences
Research Council. This programme ``aims to endow machines with
human-like perceptual, reasoning and learning abilities, which support
collaboration and communication with human beings.'', with one of the
stated motivations to ``inspire new forms of computation based on
human cognition, especially on tasks where humans currently exhibit
superior
abilities.''\footnote{https://epsrc.ukri.org/newsevents/pubs/human-like-computing-strategy-roadmap/}

We believe that a focus on more human-like computing would result in
systems whose output more closely resembled human produced work. If
this were the case, then we hypothesise that there would be greater
understandability.  In the context of science and mathematics, there
is much theoretical work on how people work in these domains and how
knowledge is constructed. For instance, the philosophy of informal
mathematics and the study of mathematical practice and cultures are
thriving communities with annual research events and a good number of
published books and papers. We can build on this work by building
human-like computing systems which model theoretical findings.

The CC community is particularly well equipped to work in this
research programme. The FACE evaluation model \cite{colton11} is
based on the multiple aspects involved in the human creative act,
including aesthetic judgements, concept development, framing
information and meta-level processes which can generate, for instance,
the means by which an artefact is generated. This might be reflected
in automated theory formation approaches to Automated Reasoning, which
consider a far wider view of mathematical knowledge production than
the traditional narrow focus of Automated Theorem Proving, including
the automatic generation and evaluation of new conjectures, concepts,
examples explanations, and so on (see \cite{atf-the-next-generation}
for an example). In some ways, given the closeness of some (aspects of
some) sciences to artistic domains, this may be low hanging fruit for
system developers to apply their systems to scientific and
mathematical domains.

%in our own work, we follow this ....

\begin{quote}
%\noindent\fbox{%
 % \parbox{\textwidth}{%
    {\bf Recommendation 1:} Apply your system to scientific domains.

%}%
%}
\end{quote}

\subsection{The ``Framing '' approach}
Enhancing software with explanatory functionality would also help to
mitigate the understandability problem. The ``F'' from the FACE model
stands for {\em Framing}, and we advocate a dual-approach of software
generating framing information alongside an artefact, problem solution
or new data pattern (proof objects can be seen as a limited form of framing
information). We foresee this being an increasingly important area of
research in CC, with an increasing level of sophistication:
from explanation to justification to argument and dialogue with a user
about the value, method of production, motivation etc behind
output. How framing information should be developed is a research programme in
its own right. For now, we discuss greater and lesser understandability in
terms of describing the processes underlying the generative act and consider
these for ML approaches.

Many ML approaches can be characterised as constructing a computer
program (or ``model'') consisting of two parts: an overall structure
or \emph{architecture}, which remains fixed; and a set of adjustable
\emph{parameters}, which are inferred or ``learned'' from data
(e.g. \emph{training data} of desired input/output examples). One
particularly simple architecture is the \emph{decision tree}: nested
boolean queries of the input, often used for
\emph{classification}~\cite{safavian1991survey}. These queries are
parameters, and are chosen based on how efficiently they separate the
classes given in the training data.  Decision trees perform poorly compared to
other ML algorithms, but are nominally understandable since their behaviour on a
given input traces a single path through these queries, which could be turned
into framing information such as ``Class {\em x} was chosen because {\em y} was
greater than {\em z}...''.  The \emph{random forest} approach gives better
performance by combining many decision trees and having them vote on the overall
outcome~\cite{randomforests}, although such ensemble behaviour is more
difficult to reason about than that of a single tree, and is hence harder to
frame in an understandable way. One approach might be to find patterns in the
votes, such as ``Class {\em x} was chosen because most trees looking at features
{\em y} and {\em z} voted for it''.

Recent research has focused on highly expressive classes of models such as
\emph{differentiable programming}~\cite{wang2018demystifying}, whose
architectures output not only a (numerical) answer, but also partial derivatives
with respect to the parameters; and \emph{probabilistic programming}, which
samples from a \emph{distribution} conditioned on the training data. Both
frameworks allow arbitrary architectures, specified via Turing-complete
languages, and provide efficient, composable methods for optimising the
parameters (e.g. Stochastic Gradient Descent and Markov Chain Monte Carlo,
respectively) to minimise arbitrary loss functions (e.g. output error for the
training data).

With such expressive formalisms, the conflict between the generality
of a model and its understandability becomes clear. Task-specific
architectures require fewer parameters than general-purpose approaches, perform
well with little training data, and are amenable to descriptive framing
information. For example, hand-written characters can be classified based on a
single example if we allow our model to assume the given images are generated by
pen strokes~\cite{lake2015human}, and these models may allow descriptions such
as ``Character {\em c} was chosen because there appear to be {\em x} long
strokes, {\em y} curved strokes, etc''. Likewise the parameters of a 3D scene
(such as object position and lighting) can be inferred from images if a
ray-tracer is embedded in the model~\cite{li2018differentiable}; embedding a
physics engine enables predictions about these scenes, which are useful e.g. for
robot controllers~\cite{degrave2016differentiable}. Whilst more complicated than
the previous examples, such a controller could (in principle) justify its
actions based on interpretations of the model, such as ``The motor was engaged
because the pendulum appeared to be falling to the left''.

However, the specificity that makes these implementations understandable also
makes them unsuitable for any other task. The choice of such high-level,
task-specific components is performed by the user, and encodes some of their
domain knowledge into the structure of the solution, such that it doesn't have
to be learned. This is similar to how high-level logics can represent relevant
domain concepts (like natural numbers and sets), yet proof methods making use of
this have limited reusability due to the difficulty of automating such
high-level reasoning.

At the other end of the spectrum are general purpose architectures, like
\emph{neural networks} (differentiable programs capable of universal function
approximation~\cite{funahashi1989approximate}). These are compositions of a
large number of identical sub-expressions (``neurons''), whose parameters
(``weights'') scale their input values, and hence the contribution of each
sub-expression to the whole. Such architectures encode essentially no domain
knowledge, requiring much larger training sets than task-specific algorithms in
order to ``learn'' these details.  So much of these general purpose models'
behaviour comes from tuning their (many) parameters, that understanding or
describing their high-level behaviour is difficult; indeed they are often
treated as inscrutable ``black boxes'', akin to the large (un)SAT proof
described above.

Understanding exactly how such programs make their decisions is an
active area of research, known as \emph{explainable artificial
  intelligence}
(XAI)~\cite{dovsilovic2018explainable,doshi2017towards,molnar2018interpretable}.
Saliency maps are a popular form of framing information~\cite{simonyan2013deep},
which reverse-engineer the factors which lead to a model's decisions (for
example judging the saliency of input pixels by how strongly they each effect
the output prediction if adjusted). These methods appear intuitive, e.g.
producing visualisations highlighting a particular object in a scene as the
reason for its classification; yet this can obscure the difficulty of
interpreting such high-dimensional decision boundaries. In particular,
reasonable justifications (such as classifying an image as a butterfly, with
high saliency given to those pixels which show the butterfly) can be
fundamentally altered by imperceptible adjustments to the
input~\cite{ghorbani2017interpretation} (in this case choosing butterfly based
only on the background vegetation). Similar adjustments can also change a
model's output, leading to the field of \emph{adversarial machine
  learning}~\cite{goodfellow2014explaining}; adjustments to even a single pixel
can not only cause a system to mislabel an input, but to give high confidence to
its erroneous result~\cite{su2019one}. Whilst much attention has been focused on
making the outputs of ML systems more accurate and robust, there is also a need
for framing information which explains more, is more understandable to users and
less prone to misinterpretation.

\begin{quote}
%\noindent\fbox{%
%    \parbox{\textwidth}{%
{\bf Recommendation 2:} Enhance your system with framing capabilities.

%}%
%}
\end{quote}


\subsection{The ``forgoing understandability'' approach}
It may be the case that, given the increase in power, generality and
predictiveness that ML approaches give, we decide to forgo
understandability in science. As a community we would be in a unique
position to develop thinking on this, and to answer questions such as
whether we should try to replace understandability with something
else. Previous work such as \cite{colton:2015} identifies stakeholder
groups in CC research and practice: this can be extended to scientists
and mathematicians to ensure that we develop in directions which will
be fruitful and useful to society.


\begin{quote}
%\noindent\fbox{%
 %   \parbox{\textwidth}{%

  {\bf Recommendation 3:} Produce philosophical work on what
  computational creativity should mean, and what science done with
  computers should entail.

%}%
%}
\end{quote}

\section{Concluding Remarks}

%\subsection{shakeup - we have to do more than generation}
%[move]
Deep learning and ML are making inroads everywhere: generative arts,
processors, windfarms, Go, machine vision, and so on, and we need to
consider as a community where this leaves us. Our suggestion in this
paper is to focus on science and mathematics, where we have much to
contribute.

%\subsection{science is actually a more natural domain for cc than the
 % arts}
%AI is a good idea in this domain

Of course, both science and CC are fluid disciplines and will evolve
as technology and culture change. One possible solution to the
problems described here would be to adapt our view of what is
valuable, and what is an artefact. For instance, could a neural
network itself be considered to be a scientific discovery?  It may be
that AI systems become objects of study in the same way as the human
brain is currently an object of study, with methods and approaches
from neural science, psychology, cognitive science and so on employed
to understand an AI system and its behaviour and interactions.

People are not naturally good at science. The history of science and
scientific methodology, the length of time it takes to train a
scientist and the high number of published research findings in
science which are considered to be false or
sub-standard\footnote{Meta-scientific studies suggest that 85\% of
  biomedical research efforts are wasted \cite{macleod} and 90\% of
  respondents to a recent survey in Nature agreed that there is a
  `reproducibility crisis' \cite{baker} (see \cite{munafo,ioannidis}
  for further details).} all hint at the difficulty of the scientific
enterprise. This is partially due to political and institutional
factors such as pressure to publish, conflicts of interest and a
culture which is often more competitive than collaborative; but also
partially due to the constant battle to avoid the large number of
cognitive biases that adversely affect our reasoning and judgements
\cite{haselton,sutherland}. On the other hand, the arts -- while also
difficult to do well -- do not usually go against our natural way of
thinking, and can be seen as a celebration of our humanity.  In many
ways science should be an obvious application domain for computational
creativity.  This paper is a call to arms for the whole CC community,
to apply their systems to scientific and mathematical domains, to
enhance their systems with framing functionality, and to produce
philosophical work on new directions in our field.

%The psychology of AI.

%\subsection{The psychology of AI}



% Our hope is that we as a community design a research space which is
% friendly and welcoming and positively encouraging of applications to
% science and mathematics.

\bibliographystyle{iccc}
\bibliography{biblio}
\end{document}






***




where statistical methods are used to
make predictions or decisions about data, often without human
involvement~\cite{alpaydin2014introduction}.


In particular there is a


A similar problem of understandability has emerged in the field of

*******

Automated reasoning ....



****************
The problem of making machine-generated artefacts more understandable
to human users is quite clear in the field of





***********








**


bit from Chris.





***

 Crisis in science work.

 Are we in the last throes where humans understand science? Right now
 we have to chose between understandability and power,
 understandability and generality, understandability and predictive
 accuracy. ...

I need to do/know/predict X. I don't need to understand it.

phil of science here.











Part three focuses upon specific academic disciplines including; arts
and science, humanities, natural sciences and mathematics, social
sciences, the arts, professional and occupational education. Part four
describes directions for reform including; teaching across the
curriculum, interdisciplinary studies, internationalizing the
curriculum, transforming the curriculum through diversity, creating
learning communities and using technology.


Eisner, E., & Powell, K. (2002). Special Series on Arts-Based Educational Research: Art In
Science?. Curriculum Inquiry, 32(2), 131-159.


questioned the notion that art and science belong in different worlds, and noted synergies
across the different disciplines.

social scientists who were fellows at the Center for Advanced Study in the Behavioral Sciences to secure insight into the role that artistry might play in the course of their work.


Maeda, J. (2013). STEM + Art = STEAM. STEAM Journal, 1(1).
